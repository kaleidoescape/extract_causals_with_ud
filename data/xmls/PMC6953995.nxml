<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Int J Comput Vis</journal-id><journal-id journal-id-type="iso-abbrev">Int J Comput Vis</journal-id><journal-title-group><journal-title>International Journal of Computer Vision</journal-title></journal-title-group><issn pub-type="ppub">0920-5691</issn><publisher><publisher-name>Springer US</publisher-name><publisher-loc>New York</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">31983806</article-id><article-id pub-id-type="pmc">6953995</article-id><article-id pub-id-type="publisher-id">1009</article-id><article-id pub-id-type="doi">10.1007/s11263-017-1009-7</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Large Scale 3D Morphable Models</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2114-9595</contrib-id><name><surname>Booth</surname><given-names>James</given-names></name><address><email>james.booth@imperial.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Roussos</surname><given-names>Anastasios</given-names></name><address><email>troussos@imperial.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Ponniah</surname><given-names>Allan</given-names></name><address><email>aponniah@gmail.com</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Dunaway</surname><given-names>David</given-names></name><address><email>david.dunaway@gosh.nhs.uk</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Zafeiriou</surname><given-names>Stefanos</given-names></name><address><email>s.zafeiriou@imperial.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2113 8111</institution-id><institution-id institution-id-type="GRID">grid.7445.2</institution-id><institution>Imperial College London, </institution></institution-wrap>London, UK </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.420468.c</institution-id><institution>Great Ormond Street Hospital, </institution></institution-wrap>London, UK </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 8024</institution-id><institution-id institution-id-type="GRID">grid.8391.3</institution-id><institution>University of Exeter, </institution></institution-wrap>Exeter, UK </aff></contrib-group><author-notes><fn fn-type="com"><p>Communicated by Edmond Boyer, Cordelia Schmid.</p></fn></author-notes><pub-date pub-type="epub"><day>8</day><month>4</month><year>2017</year></pub-date><pub-date pub-type="pmc-release"><day>8</day><month>4</month><year>2017</year></pub-date><pub-date pub-type="ppub"><year>2018</year></pub-date><volume>126</volume><issue>2</issue><fpage>233</fpage><lpage>254</lpage><history><date date-type="received"><day>15</day><month>3</month><year>2016</year></date><date date-type="accepted"><day>24</day><month>3</month><year>2017</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2017</copyright-statement><license license-type="OpenAccess"><license-p>
<bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0">http://creativecommons.org/licenses/by/4.0</ext-link>/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">We present large scale facial model (LSFM)&#x02014;a 3D Morphable Model (3DMM) automatically constructed from 9663 distinct facial identities. To the best of our knowledge LSFM is the largest-scale Morphable Model ever constructed, containing statistical information from a huge variety of the human population. To build such a large model we introduce a novel fully automated and robust Morphable Model construction pipeline, informed by an evaluation of state-of-the-art dense correspondence techniques. The dataset that LSFM is trained on includes rich demographic information about each subject, allowing for the construction of not only a global 3DMM model but also models tailored for specific age, gender or ethnicity groups. We utilize the proposed model to perform age classification from 3D shape alone and to reconstruct noisy out-of-sample data in the low-dimensional model space. Furthermore, we perform a systematic analysis of the constructed 3DMM models that showcases their quality and descriptive power. The presented extensive qualitative and quantitative evaluations reveal that the proposed 3DMM achieves state-of-the-art results, outperforming existing models by a large margin. Finally, for the benefit of the research community, we make publicly available the source code of the proposed automatic 3DMM construction pipeline, as well as the constructed global 3DMM and a variety of bespoke models tailored by age, gender and ethnicity.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>3D morphable models</kwd><kwd>Dense correspondence</kwd><kwd>Demographic-specific models</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000266</institution-id><institution>Engineering and Physical Sciences Research Council</institution></institution-wrap></funding-source><award-id>EP/J017787/1</award-id><award-id>EP/N007743/1</award-id><principal-award-recipient><name><surname>Roussos</surname><given-names>Anastasios</given-names></name><name><surname>Zafeiriou</surname><given-names>Stefanos</given-names></name></principal-award-recipient></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000266</institution-id><institution>Engineering and Physical Sciences Research Council</institution></institution-wrap></funding-source><award-id>DTA</award-id><principal-award-recipient><name><surname>Booth</surname><given-names>James</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Science+Business Media, LLC, part of Springer Nature 2018</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">3D Morphable Models (3DMMs) are powerful 3D statistical models of the shape and texture of the human face.<xref ref-type="fn" rid="Fn1">1</xref> In the original formulation, as presented by the seminal work of &#x000a0;Blanz and Vetter (<xref ref-type="bibr" rid="CR8">1999</xref>), a 3DMM used in an analysis-by-synthesis framework was shown to be capable of inferring a full 3D facial surface from a single image of a person. 3DMMs have since been widely applied in numerous areas in computer vision, human behavioral analysis, computer graphics, craniofacial surgery and large-scale facial phenotyping&#x000a0;(Blanz and Vetter <xref ref-type="bibr" rid="CR9">2003</xref>,&#x000a0;Amberg et&#x000a0;al. <xref ref-type="bibr" rid="CR4">2008</xref>,&#x000a0;Aldrian and Smith <xref ref-type="bibr" rid="CR3">2013</xref>,&#x000a0;Staal et&#x000a0;al. <xref ref-type="bibr" rid="CR35">2015</xref>,&#x000a0;Hammond and Suttie <xref ref-type="bibr" rid="CR24">2012</xref>) (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>).</p><p id="Par4">A 3DMM is constructed by performing some form of dimensionality reduction, typically principal component analysis (PCA), on a training set of facial meshes. This is feasible if and only if each mesh is first re-parametrised into a consistent form where the number of vertices, the triangulation, and the anatomical meaning of each vertex are made consistent across all meshes. For example, if the vertex with index <italic>i</italic> in one mesh corresponds to the nose tip it is required that the vertex with the same index in every mesh correspond to the nose tip too. Meshes satisfying the above properties are said to be in dense correspondence with one another. Whilst this correspondence problem is easy to state, it is challenging to solve accurately and robustly between highly variable facial meshes. Worst still, the very definition of anatomical meaning can be challenging to define for smooth regions of the face like the forehead or cheek, making objective measurement of correspondence quality difficult.<fig id="Fig1"><label>Fig. 1</label><caption><p>The sheer number of facial meshes used in training LSFM produces a 3D Morphable Model with an unprecedented range of human identity in a compact linear model</p></caption><graphic xlink:href="11263_2017_1009_Fig1_HTML" id="MO31"/></fig>
<fig id="Fig2"><label>Fig. 2</label><caption><p>There are two techniques used to establish dense correspondence in 3DMMs. <italic>Top</italic>&#x000a0;correspondence is established in a UV space&#x02014;typically a cylindrical projection of the mesh shape and texture information. The UV image of each mesh is registered to a template UV image, and subsequent sampling produces a mesh in correspondence with the template. <italic>Bottom</italic>&#x000a0;non-rigid iterative closest point (NICP), guided by sparse annotations, can be employed to iteratively deform a 3D template to match each mesh, avoiding the UV space entirely</p></caption><graphic xlink:href="11263_2017_1009_Fig2_HTML" id="MO32"/></fig>
</p><p id="Par5">Once built, 3DMMs provide two functions. Firstly, 3DMMs are powerful priors on 3D face shape and texture that can be leveraged in fitting algorithms to reconstruct accurate and complete 3D representations of faces from data deficient sources like in-the-wild 2D images or noisy 3D depth scan data. Secondly, 3DMMs provide a mechanism to encode any 3D face in a low dimensional feature space, a compact representation that makes tractable many 3D facial analysis problems.</p><sec id="Sec2"><title>A Note on Terminology</title><p id="Par6">For the sake of clarity, we note that here we explicitly define a <italic>3D Morphable Model</italic> as a statistical basis of shape and texture. A 3DMM is a data structure&#x02014;a flexible representation of the 3D human face that can be persisted to disk and reused in a number of different contexts, both 2D and 3D in nature. We make this note as there is some flexibility in the literature as to whether a 3DMM refers to a statistical model, (a data structure, the view we take), or an <italic>algorithm</italic> for performing 3D reconstruction from a single image.</p><p id="Par7">This confusion arrises from the fact that, as previously mentioned, the initial application of such models was in this one narrow application. However the usages of these models have expanded massively into new fields over the last 15&#x000a0;years. With emerging applications such as virtual reality (VR), autonomous vehicles, and depth-camera equipped consumer robotics, it is not hard to image a future where 3D applications of 3DMMs are more obvious and widespread than the initial application to 2D images. With this forward looking view, in this paper we are concerned with constructing a reusable statistical models that may be used in a myriad of applications.</p></sec><sec id="Sec3"><title>The Challenges of Large-Scale 3DMMs</title><p id="Par8">In this paper we revisit 3DMMs under a new context&#x02014;that we have access to a database of around 10,000 high quality 3D facial scans, with a wide variation of age, gender, and ethnicity represented amongst the subjects. Furthermore, for each individual we have detailed demographics including the subject&#x02019;s age, gender, and ethnic background. Our goal is to leverage this data in order to build an anatomically accurate 3D Morphable Model that can be used in a wide variety of applications. This context brings with it a number of new challenges for 3DMM construction.</p><p id="Par9">Firstly, the sheer scale of the data takes into uncharted territory. As we will motivate in Sect.&#x000a0;<xref rid="Sec5" ref-type="sec">2</xref>, previous works have only worked with smaller datasets (generally two orders of magnitude smaller), where it is tractable to perform manual work in preprocessing meshes as part of the construction process. Furthermore, construction algorithms in the past have only been proven on datasets containing small variation in age and ethnicity (typically, dominated by adult caucasian subjects).</p><p id="Par10">Secondly, we maintain a tight focus on producing an <italic>anatomically accurate</italic> 3D Morphable Model&#x02014;by this we mean that the dense correspondence we seek to establish should optimally reflect the underlying anatomical structure of the human face. This means we actively avoid any alignment based on &#x02018;skin-deep&#x02019; facial features, perhaps the most obvious of which would be eyebrows, as aligning such features would disrupt the alignment of the underlying facial structure. This is a subtle but important distinction. Perusing this goal opens up the use of 3DMM in applications where an accurate model of the underlying facial structure is key like craniofacial surgery planning and assessment.</p><p id="Par11">Finally, we have wholly additional per-subject information in the form of detailed demographics, which opens up many new avenues of possibilities in both the construction and fitting of 3DMMs. Indeed, we will show for the first time clear evidence that the manifold of plausible faces is naturally clustered by demographics like age and ethnicity, and use this insight to devise new approaches to 3DMM construction and fitting that advance on the state of art. We further demonstrate for the first time that a large scale model coupled with accurate demographics enables accurate age classification from 3D shape data alone (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>).</p></sec><sec id="Sec4"><title>Paper Structure</title><p id="Par12">The remainder of the paper is structured as follows. In Sect.&#x000a0;<xref rid="Sec5" ref-type="sec">2</xref> an overview of the Morphable Model construction literature will be given, whilst Sect.&#x000a0;<xref rid="Sec6" ref-type="sec">3</xref> will provide an overview of the contributions this paper makes to the field. Section&#x000a0;<xref rid="Sec7" ref-type="sec">4</xref> provides a mathematical framework for 3DMM construction. The most challenging and varied component of construction, establishing dense correspondence, will get its own treatment in Sect.&#x000a0;<xref rid="Sec13" ref-type="sec">5</xref>, where we will describe and analyze in detail three popular approaches to solving this problem in our specific context.</p><p id="Par13">Informed from this work, Sect.&#x000a0;<xref rid="Sec17" ref-type="sec">6</xref> will put forward our novel pipeline for automated anatomically accurate 3D Morphable Model construction. In Sect.&#x000a0;<xref rid="Sec21" ref-type="sec">7</xref> we will evaluate this pipeline by applying it to the newly-introduced MeIn3D dataset, to construct large scale facial model (LSFM). We examine in detail the properties of this unique model, and test its performance in a range of applications including age prediction and 3D model fitting. Finally, Sect.&#x000a0;<xref rid="Sec34" ref-type="sec">8</xref> will provide some conclusions and ideas for future work in this area.</p></sec></sec><sec id="Sec5"><title>Previous Work</title><p id="Par14">The construction of a 3DMM usually consists of two main steps&#x02014;establishing group-wise dense correspondence between a training set of facial meshes, and then performing some kind of statistical analysis on the registered data to produce a low-dimensional model.</p><p id="Par15">In the original formulation,&#x000a0;Blanz and Vetter (<xref ref-type="bibr" rid="CR8">1999</xref>) solved the dense correspondence problem by representing each facial mesh in a cylindrical &#x02018;UV&#x02019; map, flattening each 3D surface down into a 2D space. This reduced establishing correspondence to a well-understood image registration problem, which was solved with a regularized form of optical flow. Blanz and Vetter employed PCA to construct their model, and showed that in their framework, model performance was improved by segmenting the facial surface into regions (eyes, nose, mouth, other), building individual models per-component, before blending resulting segments back together. Amberg et&#x000a0;al. (<xref ref-type="bibr" rid="CR4">2008</xref>) extended this approach to emotive facial shapes by adopting an additional PCA modeling of the offsets from the neutral pose. This resulted to a single linear model of both identity and expression variation of 3D facial shape.</p><p id="Par16">Blanz and Vetter&#x02019;s correspondence technique was only used to align the facial meshes of 200 subjects of a similar ethnicity and age&#x000a0;(Blanz and Vetter <xref ref-type="bibr" rid="CR8">1999</xref>). This approach was effective in such a constrained setting, but it is fragile to large variance in facial identity. To overcome this limitation, Patel and Smith (<xref ref-type="bibr" rid="CR29">2009</xref>) proposed to manually annotate the cylindrical face projections with a set of sparse annotations, employing a thin plate splines (TPS) warp&#x000a0;(Bookstein <xref ref-type="bibr" rid="CR13">1989</xref>) to register the UV images of the meshes into a common reference frame. Cosker et&#x000a0;al. (<xref ref-type="bibr" rid="CR19">2011</xref>) automated the procedure of landmark annotations required for the TPS warp, for the special case of temporal sequences of a single identity displaying emotions. Several facial landmarks on a handful of meshes for a given temporal sequence were manually annotated and used to build a person-specific active appearance model (AAM)&#x000a0;(Cootes et&#x000a0;al. <xref ref-type="bibr" rid="CR18">2001</xref>) that was then used to automatically find sparse annotations for each frame in the data set.</p><p id="Par17">As an alternative to performing alignment in a UV space, Paysan et&#x000a0;al. (<xref ref-type="bibr" rid="CR30">2009a</xref>) built the basel face model (BFM) by using an optimal step nonrigid ICP algorithm&#x000a0;(Amberg et&#x000a0;al. <xref ref-type="bibr" rid="CR5">2007</xref>) (NICP) to directly align scans of 200 subjects with a template. This native 3D approach was guided by manually placed landmarks to ensure good convergence.</p><p id="Par18">
Brunton et&#x000a0;al. (<xref ref-type="bibr" rid="CR16">2011</xref>) adopt wavelet bases to model independent prior distributions at multiple scales for the 3D facial shape. This offers a natural way to represent and combine localized shape variations in different facial areas.</p><p id="Par19">
Vlasic et&#x000a0;al. (<xref ref-type="bibr" rid="CR38">2005</xref>) modeled the combined effect of identity and expression variation on the facial shape by using a multilinear model. More recently, Bolkart and Wuhrer (<xref ref-type="bibr" rid="CR12">2015</xref>) show how such a multilinear model can be estimated directly from the training 3D scans by a joint optimization over the model parameters and the groupwise registration of the 3D scans.</p><p id="Par20">For the case where a temporal sequence of meshes is available, Bolkart and Wuhrer (<xref ref-type="bibr" rid="CR11">2015</xref>) fit a multilinear model and estimate a 4D sequence parametrization. This can be used to animate a single 3D scan with a specific facial expression. Another alternative to modeling emotive faces is the blendshape model, which was used by Salazar et&#x000a0;al. (<xref ref-type="bibr" rid="CR34">2014</xref>) to place into correspondence emotive faces in a fully automated way. For more details on 3D facial shape modeling, we refer the interested reader to the recent extensive review article of Brunton et&#x000a0;al. (<xref ref-type="bibr" rid="CR17">2014b</xref>) and the references therein.</p><p id="Par21">Due to the costly manual effort currently required to construct 3DMMs from 3D data, recent efforts in the field have also focused on trying to build models from other data sources.&#x000a0;Kemelmacher-Shlizerman (<xref ref-type="bibr" rid="CR28">2013</xref>) recently presented a technique that attempts to learn a full 3D facial model automatically from thousands of images. Whilst impressive given the input data, such techniques cannot currently hope to produce models comparable in resolution and detail to techniques that natively process 3D input data.</p><p id="Par22">All the aforementioned works do not use more than 300 training facial scans. In this paper we show that such a size of training set is far from adequate to describe the full variability of human faces. On top of that, all existing works use training sets with a very limited diversity in the ethnic origin (mostly European/Caucasian) as well as in the age (mostly young and middle adulthood) of the subjects.</p><p id="Par23">Due to this kind of limitations of the training sets adopted, no existing work so far, to the best of our knowledge, has developed demographically-specific 3DMM models, i.e.&#x000a0;3DMM models tailored for specific age, gender or ethnicity groups. The above issues pose severe limitations in the descriptive power of the resultant Morphable Models.</p><p id="Par24">At the same time, there is strong experimental evidence that the 3D facial shapes of disparate gender and ethnicity are significantly separable. Toderici et&#x000a0;al. (<xref ref-type="bibr" rid="CR36">2010</xref>) perform an accurate estimation of gender and ethnicity based purely on the 3D facial shapes, without using any associated texture or photographic information. Their proposed method achieves around 99% accuracy for race and 94% for gender recognition.</p><p id="Par25">It is also evident from the prior art that demographically-specific modelling is able to achieve substantial improvements on 3D face recognition performance. Heo and Savvides (<xref ref-type="bibr" rid="CR25">2012</xref>) use demographically-specific models in the case of generic elastic modelling (GEM), which is a much coarser modelling of 3D shape variation than 3DMMs. The authors are solely based on 2D training images and a depth-based representation of facial variation. In their extensive experimental evaluation, they show that the demographically-specific models achieve significantly better 3D reconstruction as well as face recognition performance across different views, as compared to the corresponding global models.</p><p id="Par26">There currently exists only three publicly available 3D Morphable Models. Firstly, a University of Basel website provides the BFM model&#x000a0;(Paysan et&#x000a0;al. <xref ref-type="bibr" rid="CR30">2009a</xref>).<xref ref-type="fn" rid="Fn2">2</xref> Secondly, Bolkart, Brunton, Salazar and Wuhrer have a website where they provide 3DMMs constructed by their recent works, modelling 3D face shapes of different subjects in neutral expression&#x000a0;(Brunton et&#x000a0;al. <xref ref-type="bibr" rid="CR17">2014b</xref>) as well as 3D shapes of different subjects in different expressions&#x000a0;(Brunton et&#x000a0;al. <xref ref-type="bibr" rid="CR15">2014a</xref>,&#x000a0;Bolkart and Wuhrer <xref ref-type="bibr" rid="CR11">2015</xref>).<xref ref-type="fn" rid="Fn3">3</xref> Finally, a University of Surrey website provides a range of 3D facial shape models of varying resolutions&#x000a0;(Huber et&#x000a0;al. <xref ref-type="bibr" rid="CR26">2016</xref>).<xref ref-type="fn" rid="Fn4">4</xref>
</p></sec><sec id="Sec6"><title>Contributions</title><p id="Par30">Our goal is to make it trivial to build 3D Morphable Models automatically from large collections of 3D scans. We believe that our automated pipeline significantly lowers the barrier to entry for facial Morphable Model construction, to the point where there is no need to choose a trade off between automation and model quality. We are able to do this by capitalising on the powerful, person independent, facial landmark localisation frameworks that have been recently introduced&#x000a0;(Alabort-i Medina et&#x000a0;al. <xref ref-type="bibr" rid="CR2">2014</xref>).</p><p id="Par31">Our contributions in this paper are three fold.</p><p id="Par32">Firstly, we quantitatively compare the three most popular techniques for establishing dense correspondence in 3DMM construction&#x02014;NICP, and two UV based interpolations, UV-TPS and UV-optical flow (UV-OF). We perform this analysis in the context of automatic model construction, the first time such an comparison has been presented to the community.</p><p id="Par33">Secondly, informed by our in-depth comparison of dense correspondence methods, we introduce a novel robust pipeline for 3DMM construction that is completely automated. More precisely, we develop a novel and robust approach to 3D landmark localization, followed by dense correspondence estimation using the NICP algorithm. Then, we propose an approach to automatically detect and exclude the relatively few cases of failures of dense correspondence, followed by PCA to construct the deformation basis. We pay particular attention to the efficiency and scalability of all the aforementioned steps. We make the source code of this pipeline publicly available, for the benefit of the community.<xref ref-type="fn" rid="Fn5">5</xref>
</p><p id="Par35">Finally, we use our pipeline on a 3D facial database of 9663 subjects to construct LSFM, the largest and most information-rich 3DMM of face shapes in neutral expression produced to date.</p><p id="Par36">LSFM is built from two orders of magnitude more identity variation than current state-of-the-art models. We conduct extensive experimental evaluations that show that this additional training data leads to significant improvements in the characteristics of our 3D Morphable Model, and demonstrate that LSFM outperforms existing models by a wide margin. We also present experiments that study the effect of using larger datasets and more varied demographics in model construction. These experiments provide for the first time a comprehensive answer to the question of how much training data is needed for 3DMMs before effects of diminishing returns set in.</p><p id="Par37">Apart from building LSFM using the commonly-used global PCA, we also build a collection of PCA models tailored by age, gender and ethnicity, capitalizing on the rich demographic information of the used database. We present quantitative experimental evidence of why and when such tailored models should be preferred over the global PCA.</p><p id="Par38">Using the demographic information, we are also able to analyze for the first time the distribution of faces on the low-dimensional manifold produced by the global PCA. We visualize the manifold of faces using t-distributed stochastic neighbor embedding (t-SNE)&#x000a0;(Maaten and Hinton <xref ref-type="bibr" rid="CR1">2008</xref>), and report on clear age and ethnic clustering that can be observed. As an application example, we utilize the proposed model to perform age classification, achieving particularly accurate results.</p><p id="Par39">The global LSFM model as well as the models broken down by demographics will be made publicly available from this work.<xref ref-type="fn" rid="Fn6">6</xref> It is worth mentioning that current progress in computer vision would not be possible without the collection of large and comprehensive datasets e.g.&#x000a0;Everingham et&#x000a0;al. (<xref ref-type="bibr" rid="CR23">2010</xref>),&#x000a0;Sagonas et&#x000a0;al. (<xref ref-type="bibr" rid="CR33">2013</xref>),&#x000a0;Jain and Learned-Miller (<xref ref-type="bibr" rid="CR27">2010</xref>),&#x000a0;Deng et&#x000a0;al. (<xref ref-type="bibr" rid="CR21">2009</xref>), and we believe that our publicly available models contributes towards this effort.</p></sec><sec id="Sec7"><title>Background</title><sec id="Sec8"><title>Data Representation</title><p id="Par41">The geometry of a 3D facial mesh is defined by the vector <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {X}= {[\mathbf {x}_1^T,\mathbf {x}_2^T,\ldots ,\mathbf {x}_n^T]}^T \in \mathbb {R}^{3n}$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mn>2</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>n</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq1.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M4"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq2.gif"/></alternatives></inline-formula> is the number of vertices and <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {x}_i = {[x_x^i,x_y^i,x_z^i]}^T \in \mathbb {R}^3$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq3.gif"/></alternatives></inline-formula> describes the X,Y and Z coordinates of the <italic>i</italic>-th vertex.</p><p id="Par42">The topology of a mesh is encoded in a triangle list <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {T}= [\mathbf {t}_1^T,\mathbf {t}_2^T,\ldots ,\mathbf {t}_m^T]\in \mathbb {R}^{3\times m}$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mi mathvariant="bold">T</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi mathvariant="bold">t</mml:mi><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold">t</mml:mi><mml:mn>2</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold">t</mml:mi><mml:mi>m</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq4.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m$$\end{document}</tex-math><mml:math id="M10"><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq5.gif"/></alternatives></inline-formula> is the number of triangles and <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {t}_i = [t_1^i,t_2^i,t_3^i]$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:msub><mml:mi mathvariant="bold">t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mn>3</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq6.gif"/></alternatives></inline-formula> is the index triplet that defines the <italic>i</italic>-th triangle. Note that the indices <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\;t_j^i \in \{\mathbb {Z^+}\; | \; t_j^i \le n\}$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mspace width="0.277778em"/><mml:msubsup><mml:mi>t</mml:mi><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msup><mml:mi mathvariant="double-struck">Z</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mspace width="0.277778em"/><mml:mo stretchy="false">|</mml:mo><mml:mspace width="0.277778em"/><mml:msubsup><mml:mi>t</mml:mi><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>&#x02264;</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq7.gif"/></alternatives></inline-formula> correspond to vertices of the mesh.</p><p id="Par43">Texture information is given as a per-vertex color vector <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {C}= {[c_1^T, c_2^T, \ldots , c_n^T]}^T$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mn>2</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mi>n</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq8.gif"/></alternatives></inline-formula> where <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c_i = [R_i, G_i, B_i] \in \mathbb {R}^3$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq9.gif"/></alternatives></inline-formula>.</p><p id="Par44">A triangle mesh <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {M}= \{\mathbf {X}, \mathbf {T}\}$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mi mathvariant="bold">M</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">T</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq10.gif"/></alternatives></inline-formula> is thus comprised of <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M22"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq11.gif"/></alternatives></inline-formula> vertices and <inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m$$\end{document}</tex-math><mml:math id="M24"><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq12.gif"/></alternatives></inline-formula> triangles. If the mesh is textured, the definition is augmented to include the per vertex color information: <inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {M_t}= \{\mathbf {X}, \mathbf {T}, \mathbf {C}\}$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:msub><mml:mi mathvariant="bold">M</mml:mi><mml:mi mathvariant="bold">t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">T</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">C</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq13.gif"/></alternatives></inline-formula>.<fig id="Fig3"><label>Fig. 3</label><caption><p>Visualisation of the shape model of LSFM-global: mean shape (<inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M28"><mml:mi mathvariant="italic">&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq14.gif"/></alternatives></inline-formula>) and first five principal components, each visualized as additions and subtractions away from the mean shape. In more detail, the <italic>top</italic> (<italic>bottom</italic>) row corresponds to deviating from <inline-formula id="IEq15"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M30"><mml:mi mathvariant="italic">&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq15.gif"/></alternatives></inline-formula> in the direction of the corresponding shape eigenvector, with a weight of 3<inline-formula id="IEq16"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _i$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mi mathvariant="italic">&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq16.gif"/></alternatives></inline-formula> (<inline-formula id="IEq17"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$-3\sigma _i$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn><mml:msub><mml:mi mathvariant="italic">&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq17.gif"/></alternatives></inline-formula>), where <inline-formula id="IEq18"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _i$$\end{document}</tex-math><mml:math id="M36"><mml:msub><mml:mi mathvariant="italic">&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq18.gif"/></alternatives></inline-formula> is the standard deviation of the corresponding component</p></caption><graphic xlink:href="11263_2017_1009_Fig3_HTML" id="MO33"/></fig>
</p></sec><sec id="Sec9"><title>3D Face Database Overview</title><p id="Par45">The collected database, which we refer to as <italic>MeIn3D</italic>, contains approximately 12,000 3D facial scans captured over a period of 4 months. A 3dMD&#x02122;&#x000a0;photometric stereo capture device was utilized, creating a 3D triangular surface for each subject composed of approximately 60,000 vertices joined into approximately 120,000 triangles, along with a high resolution texture map. Furthermore, 9663 subjects also provided metadata about themselves, including their gender, age and ethnicity. This information allows for the construction of models for targeted populations, such as within a defined age range or from a particular ethnic background. The dataset covers a wide variety of age (see Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>), gender (<inline-formula id="IEq19"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$48\%$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:mn>48</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq19.gif"/></alternatives></inline-formula> male, <inline-formula id="IEq20"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$52\%$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:mn>52</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq20.gif"/></alternatives></inline-formula> female), and ethnicity (<inline-formula id="IEq21"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$82\%$$\end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:mn>82</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq21.gif"/></alternatives></inline-formula> White, <inline-formula id="IEq22"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$9\%$$\end{document}</tex-math><mml:math id="M44"><mml:mrow><mml:mn>9</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq22.gif"/></alternatives></inline-formula> Asian, <inline-formula id="IEq23"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$5\%$$\end{document}</tex-math><mml:math id="M46"><mml:mrow><mml:mn>5</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq23.gif"/></alternatives></inline-formula> mixed heritage, <inline-formula id="IEq24"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$3\%$$\end{document}</tex-math><mml:math id="M48"><mml:mrow><mml:mn>3</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq24.gif"/></alternatives></inline-formula> Black and <inline-formula id="IEq25"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1\%$$\end{document}</tex-math><mml:math id="M50"><mml:mrow><mml:mn>1</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq25.gif"/></alternatives></inline-formula> other) (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>).</p></sec><sec id="Sec10"><title>3DMM Construction</title><p id="Par46">The input to a 3DMM construction algorithm is a set of <inline-formula id="IEq26"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M52"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq26.gif"/></alternatives></inline-formula> meshes <inline-formula id="IEq27"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\{\mathbf {M}_1,\mathbf {M}_2,\ldots ,\mathbf {M}_k\}$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi mathvariant="bold">M</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">M</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">M</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq27.gif"/></alternatives></inline-formula>. Each input mesh has its own number of vertices and triangles, and a particular ordering to its topology.</p><p id="Par47">The construction of a 3DMM happens in two distinct stages. First, a state of dense correspondence needs to be established between the training set meshes. Following this, a statistical analysis step on the correspondng meshes yields linear models of shape and texture.</p><sec id="Sec11"><title>Dense Correspondence</title><p id="Par48">In this procedure, a collection of meshes are re-parameterized into a form where each mesh has the same number of vertices joined into a triangulation that is shared across all meshes. Furthermore, the semantic or anatomical meaning of each vertex is shared across the collection. Meshes satisfying the above conditions are said to be in dense correspondence with one another. Given such a collection of meshes, the dense correspondences among them are typically found through the registration of every mesh with a template. Landmark annotations are used as additional priors that guide the registration process in the corresponding sparse locations. Dense correspondence can be seen as a generalization of non-rigid image registration to triangular meshes.</p><p id="Par49">Of particular interest to us in 3DMM construction is the case where multiple meshes share the same topology <inline-formula id="IEq28"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {T}$$\end{document}</tex-math><mml:math id="M56"><mml:mi mathvariant="bold">T</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq28.gif"/></alternatives></inline-formula>, which as we will see is a necessary consequence of meshes being in dense correspondence. In such cases we can dispense with concerning ourselves with the mathematically clumsy definition of <inline-formula id="IEq29"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {M}$$\end{document}</tex-math><mml:math id="M58"><mml:mi mathvariant="bold">M</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq29.gif"/></alternatives></inline-formula> and directly work with the vectors of shape <inline-formula id="IEq30"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {X}$$\end{document}</tex-math><mml:math id="M60"><mml:mi mathvariant="bold">X</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq30.gif"/></alternatives></inline-formula> and texture <inline-formula id="IEq31"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {C}$$\end{document}</tex-math><mml:math id="M62"><mml:mi mathvariant="bold">C</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq31.gif"/></alternatives></inline-formula>, bearing in mind that we assume an implicit shared triangulation <inline-formula id="IEq32"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {T}$$\end{document}</tex-math><mml:math id="M64"><mml:mi mathvariant="bold">T</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq32.gif"/></alternatives></inline-formula>.</p><p id="Par50">Note that we will explore mechanisms for establishing dense correspondence in some depth in Sect.&#x000a0;<xref rid="Sec13" ref-type="sec">5</xref>.</p></sec><sec id="Sec12"><title>Similarity Alignment and Statistical Modelling</title><p id="Par51">Given a set of meshes in dense correspondence, we now wish to build a statistical model of shape and texture.</p><p id="Par52">The collection of meshes in dense correspondence are subjected to Procrustes Analysis to remove similarity effects, leaving only shape information. The processed meshes are statistically analysed, typically with principal component analysis&#x000a0;(Davies et&#x000a0;al. <xref ref-type="bibr" rid="CR20">2008</xref>), generating a 3D deformable model as a linear basis of shapes. This allows for the generation of novel shape instances:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \mathbf {X}^{*} = \bar{\mathbf {X}} + \sum _{i=1}^{k_{\varvec{\alpha }}} \varvec{\alpha }_i \mathbf {U}_i = \bar{\mathbf {X}} + \mathbf {U}\mathbf {\varvec{\alpha }} \end{aligned}$$\end{document}</tex-math><mml:math id="M66" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover><mml:mo>+</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow></mml:msub></mml:munderover><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold">U</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover><mml:mo>+</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11263_2017_1009_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq33"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{\mathbf {X}} \in \mathbb {R}^{3n}$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq33.gif"/></alternatives></inline-formula> is the mean shape and <inline-formula id="IEq34"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {U}=[\varvec{U}_1 \ldots \varvec{U}_d]\in \mathbb {R}^{3n\times d}$$\end{document}</tex-math><mml:math id="M70"><mml:mrow><mml:mi mathvariant="bold">U</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">U</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x02026;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">U</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq34.gif"/></alternatives></inline-formula> is the orthonormal basis matrix whose columns contain the shape eigenvectors <inline-formula id="IEq35"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{U}_i$$\end{document}</tex-math><mml:math id="M72"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">U</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq35.gif"/></alternatives></inline-formula>. Also, <inline-formula id="IEq36"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\alpha }=[\alpha _1,\ldots ,\alpha _d]\in \mathbb {R}^{d}$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="italic">&#x003b1;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="italic">&#x003b1;</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq36.gif"/></alternatives></inline-formula> is the shape vector that contains the parameters (coefficients) <inline-formula id="IEq37"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha _d$$\end{document}</tex-math><mml:math id="M76"><mml:msub><mml:mi mathvariant="italic">&#x003b1;</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq37.gif"/></alternatives></inline-formula> that define a specific shape instance under the given deformable model. The degrees of freedom of this model are given by the number of principal components <italic>d</italic>, which is much smaller than the dimensionality 3<italic>n</italic> of the original space of 3D shapes. Note that this model is combined with the fixed triangle topology that was yielded from the stage of dense correspondences estimation.</p><p id="Par53">Interpolating color values from nearby vertices with a barycentric weighting allows for the construction of a orthonormal texture model with the same formulation as above:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \mathbf {C}^* = \bar{\mathbf {C}} + \sum _{i=1}^{k_\beta } \beta _i \mathbf {C}_i = \bar{\mathbf {C}} + \mathbf {V}\mathbf {\beta } \end{aligned}$$\end{document}</tex-math><mml:math id="M78" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>&#x02217;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover><mml:mo>+</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi mathvariant="italic">&#x003b2;</mml:mi></mml:msub></mml:munderover><mml:msub><mml:mi mathvariant="italic">&#x003b2;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover><mml:mo>+</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mi mathvariant="italic">&#x003b2;</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11263_2017_1009_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq38"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{\mathbf {C}} \in \mathbb {R}^{3n}$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq38.gif"/></alternatives></inline-formula> is the mean texture sample and <inline-formula id="IEq39"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {V}=[\varvec{V}_1 \ldots \varvec{V}_d]\in \mathbb {R}^{3n\times d}$$\end{document}</tex-math><mml:math id="M82"><mml:mrow><mml:mi mathvariant="bold">V</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x02026;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq39.gif"/></alternatives></inline-formula> is the orthonormal basis matrix whose columns contain the texture eigenvectors <inline-formula id="IEq40"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{V}_i$$\end{document}</tex-math><mml:math id="M84"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq40.gif"/></alternatives></inline-formula>. Also, <inline-formula id="IEq41"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\beta }=[\beta _1,\ldots ,\beta _d]\in \mathbb {R}^{d}$$\end{document}</tex-math><mml:math id="M86"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b2;</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="italic">&#x003b2;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="italic">&#x003b2;</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq41.gif"/></alternatives></inline-formula>
<fig id="Fig4"><label>Fig. 4</label><caption><p>Visualisation of the texture model of LSFM-global: mean texture (<inline-formula id="IEq42"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M88"><mml:mi mathvariant="italic">&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq42.gif"/></alternatives></inline-formula>) and first five principal components, each visualized as additions and subtractions away from the mean texture. In more detail, the <italic>top</italic> (<italic>bottom</italic>) row corresponds to deviating from <inline-formula id="IEq43"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M90"><mml:mi mathvariant="italic">&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq43.gif"/></alternatives></inline-formula> in the direction of the corresponding texture eigenvector, with a weight of 3<inline-formula id="IEq44"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _i$$\end{document}</tex-math><mml:math id="M92"><mml:msub><mml:mi mathvariant="italic">&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq44.gif"/></alternatives></inline-formula> (<inline-formula id="IEq45"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$-3\sigma _i$$\end{document}</tex-math><mml:math id="M94"><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn><mml:msub><mml:mi mathvariant="italic">&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq45.gif"/></alternatives></inline-formula>), where <inline-formula id="IEq46"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _i$$\end{document}</tex-math><mml:math id="M96"><mml:msub><mml:mi mathvariant="italic">&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq46.gif"/></alternatives></inline-formula> is the standard deviation of the corresponding component. All textures are visualized on the mean 3D shape</p></caption><graphic xlink:href="11263_2017_1009_Fig4_HTML" id="MO34"/></fig>
</p><p id="Par54">Any input 3D mesh <inline-formula id="IEq47"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {X}$$\end{document}</tex-math><mml:math id="M98"><mml:mi mathvariant="bold">X</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq47.gif"/></alternatives></inline-formula> can be projected on the model subspace by finding the shape vector <inline-formula id="IEq48"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\alpha }$$\end{document}</tex-math><mml:math id="M100"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq48.gif"/></alternatives></inline-formula> that generates a shape instance Eq.&#x000a0;(<xref rid="Equ1" ref-type="">1</xref>) that is as close as possible to <inline-formula id="IEq49"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {X}$$\end{document}</tex-math><mml:math id="M102"><mml:mi mathvariant="bold">X</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq49.gif"/></alternatives></inline-formula>. The optimum shape vector and the corresponding projection <inline-formula id="IEq50"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P(\mathbf {X})$$\end{document}</tex-math><mml:math id="M104"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq50.gif"/></alternatives></inline-formula> on the model subspace are given by&#x000a0;Davies et&#x000a0;al. (<xref ref-type="bibr" rid="CR20">2008</xref>):<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \varvec{\alpha } = \mathbf {U}^T (\mathbf {X}- \bar{\mathbf {X}}),\quad P(\mathbf {X}) = \bar{\mathbf {X}} + \mathbf {U}\mathbf {U}^T (\mathbf {X}- \bar{\mathbf {X}}) \end{aligned}$$\end{document}</tex-math><mml:math id="M106" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover><mml:mo>+</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mrow></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11263_2017_1009_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>
</p></sec></sec></sec><sec id="Sec13"><title>Dense Correspondence Approaches</title><p id="Par55">Having now considered an overview of how 3D Morphable Models are constructed we focus in on the most challenging and variable aspect of the procedure&#x02014;establishing dense correspondence.</p><p id="Par56">All dense correspondence algorithms typically take as input a template and a target mesh that have been landmarked with sparse annotations. Establishing dense correspondence can thus be thought of as an interpolation problem; a known correspondence for a small subset of vertices needs to be extended to all vertices in the template. In Sect.&#x000a0;<xref rid="Sec18" ref-type="sec">6.1</xref> we explain our novel approach for automatically finding annotations, for now we assume landmarks can be reliably found and examine the dense correspondence methods in isolation.</p><sec id="Sec14"><title>UV-Space-Based Dense Correspondences</title><p id="Par57">The first technique proposed for establishing dense correspondence in 3DMM construction defined a 2D &#x02018;UV&#x02019; space for each mesh&#x02014;a contiguous flattened atlas in which the 3D surface of the face can be embedded (see top of Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>). Such a UV space is associated with its corresponding 3D surface through a bijective mapping, and so it follows that establishing dense correspondence between two UV images implicitly establishes a 3D-to-3D correspondence for the mapped mesh. The key assumption in this case is that it is possible to create UV mappings that accurately represent the 3D facial surfaces. This technique is popular as it reduces the challenging 3D correspondence problem to a well-studied 2D image non-rigid alignment one. It also may be seen as the most natural way to register laser scanned 3D meshes as it takes place in the native domain of the scanning device. For other 3D capture devices, Booth and Zafeiriou (<xref ref-type="bibr" rid="CR14">2014</xref>) outlined how a UV style space can be synthetically created from the raw capture data through simple spherical or cylindrical projections of the data. Each UV map is an image&#x02014;each pixel encoding both spatial information (X, Y, Z) and texture information (R, G, B).</p><p id="Par58">UV-space-based dense correspondence techniques apply a non-rigid image alignment between all UV maps of the meshes and a reference UV map, registering all UV maps into a consistent reference space. A consistent sampling of each aligned UV space is then performed. At each sampling site, a vertex is created by sampling from the corresponding spatial information. Texture information can either be extracted densely per-pixel, (so a single RGB colour value is assigned per vertex) or a texture coordinate into the texture UV map can be assigned (so the texture mapping can be of a much higher density than the spatial mapping). In our treatment we will always use the simpler per-vertex color sampling, but we note it is trivial to change this, with the benefit of allowing shape and texture models to be of differing resolutions.</p><p id="Par59">Since the UV space representation is effectively a 2D image representation, each UV map of the database can be aligned with the reference UV map by applying an image registration algorithm. Usually, one of the following two approaches are adopted for this task:<list list-type="bullet"><list-item><p id="Par60">Thin plate splines (TPS) interpolation, as e.g.&#x000a0;done in&#x000a0;Patel and Smith (<xref ref-type="bibr" rid="CR29">2009</xref>).</p></list-item><list-item><p id="Par61">Optical flow (OF) estimation, as e.g.&#x000a0;done in&#x000a0;Blanz and Vetter (<xref ref-type="bibr" rid="CR8">1999</xref>).</p></list-item></list>We refer to the corresponding dense correspondence techniques as UV-TPS and UV-OF respectively.</p><p id="Par62">In UV-TPS, a dense mapping between the UV maps is estimated via a TPS interpolation of the correspondences that are established by the sparse landmark annotations. In UV-OF, each pair of UV maps is registered by applying optical flow on the multichannel image data defined on the UV space by the texture and the 3D cylindrical coordinates of the face points.</p></sec><sec id="Sec15"><title>Non-Rigid Iterative Closest Point (NICP)</title><p id="Par63">In contrast to the UV-space-based approaches, Amberg et&#x000a0;al. (<xref ref-type="bibr" rid="CR5">2007</xref>) propose a natively 3D algorithm, which directly establishes 3D-to-3D correspondences. The algorithm of&#x000a0;Amberg et&#x000a0;al. (<xref ref-type="bibr" rid="CR5">2007</xref>) extends the (rigid) ICP approaches to nonrigid deformations while retaining tractable convergence properties. It is based on a locally affine representation of the deformations and adopts an adjustable stiffness parameter.</p><p id="Par64">In more detail, let <inline-formula id="IEq51"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {S}$$\end{document}</tex-math><mml:math id="M108"><mml:mi mathvariant="bold">S</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq51.gif"/></alternatives></inline-formula> be the 3D shape of any of the 3D scans of the considered database. Note that each scan could have a different, arbitrary number of vertices. Also, let <inline-formula id="IEq52"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {V} \in \mathbb {R}^{3n}$$\end{document}</tex-math><mml:math id="M110"><mml:mrow><mml:mi mathvariant="bold">V</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq52.gif"/></alternatives></inline-formula> be the 3D mesh of the adopted facial template, where <inline-formula id="IEq53"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M112"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq53.gif"/></alternatives></inline-formula> being the number of vertices of this template. The NICP method of Amberg et&#x000a0;al. (<xref ref-type="bibr" rid="CR5">2007</xref>) non-rigidly deforms the template <inline-formula id="IEq54"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {V}$$\end{document}</tex-math><mml:math id="M114"><mml:mi mathvariant="bold">V</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq54.gif"/></alternatives></inline-formula> in order to match with the input 3D scan <inline-formula id="IEq55"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {S}$$\end{document}</tex-math><mml:math id="M116"><mml:mi mathvariant="bold">S</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq55.gif"/></alternatives></inline-formula> as accurately as possible. This deformation is over-parametrised with a collection <inline-formula id="IEq56"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {A} = \{ \mathbf {A}_1,\ldots ,\mathbf {A}_n\}$$\end{document}</tex-math><mml:math id="M118"><mml:mrow><mml:mi mathvariant="bold">A</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq56.gif"/></alternatives></inline-formula> of affine transformations, one for each vertex of the template. Each <inline-formula id="IEq57"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {A}_i$$\end{document}</tex-math><mml:math id="M120"><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq57.gif"/></alternatives></inline-formula> is a 3<inline-formula id="IEq58"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times $$\end{document}</tex-math><mml:math id="M122"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq58.gif"/></alternatives></inline-formula>4 affine transformation matrix that is applied on the <italic>i</italic>-th vertex of the template <inline-formula id="IEq59"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_i\in \mathbb {R}^3$$\end{document}</tex-math><mml:math id="M124"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq59.gif"/></alternatives></inline-formula>, resulting to the location of the vertex after the nonrigid deformation: <inline-formula id="IEq60"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{\varvec{v}}_i = \mathbf {A}_i (\varvec{v}_i^T , 1)^T$$\end{document}</tex-math><mml:math id="M126"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq60.gif"/></alternatives></inline-formula>.</p><p id="Par65">The deformation of <inline-formula id="IEq61"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {V}$$\end{document}</tex-math><mml:math id="M128"><mml:mi mathvariant="bold">V</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq61.gif"/></alternatives></inline-formula> is based on the minimisation of the following energy:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} E(\mathbf {A}) = E_d( \mathbf {A}) + \alpha E_s(\mathbf {A}) + \beta E_{\ell }(\mathbf {A}) \end{aligned}$$\end{document}</tex-math><mml:math id="M130" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="italic">&#x003b1;</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="italic">&#x003b2;</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mi>&#x02113;</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11263_2017_1009_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq62"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha $$\end{document}</tex-math><mml:math id="M132"><mml:mi mathvariant="italic">&#x003b1;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq62.gif"/></alternatives></inline-formula> and <inline-formula id="IEq63"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta $$\end{document}</tex-math><mml:math id="M134"><mml:mi mathvariant="italic">&#x003b2;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq63.gif"/></alternatives></inline-formula> are positive weights that balance the importance of the different terms (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>).</p><p id="Par66">
<inline-formula id="IEq64"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$E_d( \mathbf {A})$$\end{document}</tex-math><mml:math id="M136"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq64.gif"/></alternatives></inline-formula> is a data term that penalises the distance between the deformed version of the template and the 3D scan <inline-formula id="IEq65"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {S}$$\end{document}</tex-math><mml:math id="M138"><mml:mi mathvariant="bold">S</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq65.gif"/></alternatives></inline-formula>:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} E_d(\mathbf {A}) = \sum _{i=1}^{N_F} \texttt {dist}^2(\mathbf {A}_i (\varvec{v}_i^T , 1)^T , \mathbf {S}) \end{aligned}$$\end{document}</tex-math><mml:math id="M140" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>F</mml:mi></mml:msub></mml:munderover><mml:msup><mml:mi mathvariant="monospace">dist</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="bold">S</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11263_2017_1009_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq66"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\texttt {dist}(\hat{\varvec{v}}_i,\mathbf {S})$$\end{document}</tex-math><mml:math id="M142"><mml:mrow><mml:mi mathvariant="monospace">dist</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">S</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq66.gif"/></alternatives></inline-formula> is the distance between the point <inline-formula id="IEq67"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{\varvec{v}}_i$$\end{document}</tex-math><mml:math id="M144"><mml:msub><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq67.gif"/></alternatives></inline-formula> and the mesh <inline-formula id="IEq68"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {S}$$\end{document}</tex-math><mml:math id="M146"><mml:mi mathvariant="bold">S</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq68.gif"/></alternatives></inline-formula> (with this mesh being considered as a triangulated surface to effectively compute the point-to-mesh distance).</p><p id="Par67">
<inline-formula id="IEq69"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$E_s(\mathbf {A})$$\end{document}</tex-math><mml:math id="M148"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq69.gif"/></alternatives></inline-formula> is a stiffness term that acts as a spatial regularisation of the deformed surface, favoring spatially smooth deformations. It penalises the differences between affine transformations that are neighbours in the mesh structure:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} E_s(\mathbf {A}) = \sum _{(i,j)\in \mathcal {E}} \Vert (\mathbf {A}_i - \mathbf {A}_j) G \Vert _F^2 \end{aligned}$$\end{document}</tex-math><mml:math id="M150" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">E</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mo stretchy="false">&#x02016;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>G</mml:mi><mml:mo stretchy="false">&#x02016;</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11263_2017_1009_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq70"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathcal {E}$$\end{document}</tex-math><mml:math id="M152"><mml:mi mathvariant="script">E</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq70.gif"/></alternatives></inline-formula> is the set of edges of the template and <inline-formula id="IEq71"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Vert \cdot \Vert _F$$\end{document}</tex-math><mml:math id="M154"><mml:msub><mml:mrow><mml:mo stretchy="false">&#x02016;</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo stretchy="false">&#x02016;</mml:mo></mml:mrow><mml:mi>F</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq71.gif"/></alternatives></inline-formula> denotes the Frobenius norm. Also, <inline-formula id="IEq72"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G=\texttt {diag}(1,1,1,\gamma )$$\end{document}</tex-math><mml:math id="M156"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="monospace">diag</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="italic">&#x003b3;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq72.gif"/></alternatives></inline-formula> is a weighting matrix that makes this cost function be a weighted sum of squared differences, where <inline-formula id="IEq73"><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma $$\end{document}</tex-math><mml:math id="M158"><mml:mi mathvariant="italic">&#x003b3;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq73.gif"/></alternatives></inline-formula> balances the importance between differences in the translational part of the deformations (last column of <inline-formula id="IEq74"><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {A}_i$$\end{document}</tex-math><mml:math id="M160"><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq74.gif"/></alternatives></inline-formula>) and differences in their rotational and skew part (first 3 columns of <inline-formula id="IEq75"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {A}_i$$\end{document}</tex-math><mml:math id="M162"><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq75.gif"/></alternatives></inline-formula>).</p><p id="Par68">Finally, <inline-formula id="IEq76"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$E_{\ell }(\mathbf {A})$$\end{document}</tex-math><mml:math id="M164"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>&#x02113;</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq76.gif"/></alternatives></inline-formula> is a sparse landmarks term that ensures that the deformed template is in accordance with the landmark information on the 3D scan <inline-formula id="IEq77"><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {S}$$\end{document}</tex-math><mml:math id="M166"><mml:mi mathvariant="bold">S</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq77.gif"/></alternatives></inline-formula>:<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} E_\ell (\mathbf {A}) = \sum _{i=1}^L \Vert \mathbf {A}_{k_i} (\varvec{v}_{k_i}^T , 1)^T - \varvec{\ell }_i \Vert ^2 \end{aligned}$$\end{document}</tex-math><mml:math id="M168" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>&#x02113;</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo stretchy="false">&#x02016;</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">&#x02113;</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">&#x02016;</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11263_2017_1009_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where <italic>L</italic> is the number of landmarks and <inline-formula id="IEq78"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\ell }_i\in \mathbb {R}^3$$\end{document}</tex-math><mml:math id="M170"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">&#x02113;</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq78.gif"/></alternatives></inline-formula> is the location of the <italic>i</italic>-th landmark in the 3D scan <inline-formula id="IEq79"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {S}$$\end{document}</tex-math><mml:math id="M172"><mml:mi mathvariant="bold">S</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq79.gif"/></alternatives></inline-formula>. Finally, <inline-formula id="IEq80"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k_i$$\end{document}</tex-math><mml:math id="M174"><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq80.gif"/></alternatives></inline-formula> is the vertex index of the <italic>i</italic>-th landmark, with respect to the mesh of the template.</p><p id="Par69">The method of&#x000a0;Amberg et&#x000a0;al. (<xref ref-type="bibr" rid="CR5">2007</xref>) proposes an efficient and accurate minimisation of the energy&#x000a0;(<xref rid="Equ4" ref-type="">4</xref>)&#x02014;we invite the interested reader to explore this paper for more details.<fig id="Fig5"><label>Fig. 5</label><caption><p>Example dense correspondence results from three techniques. NICP is better able to deal with parts of the face that don&#x02019;t project to a cylindrical UV space well like the interior of the nose and mouth, and is less prone to drift effects</p></caption><graphic xlink:href="11263_2017_1009_Fig5_HTML" id="MO35"/></fig>
</p></sec><sec id="Sec16"><title>Comparison of Dense Correspondence Approaches</title><p id="Par70">Having described the two popular families of dense correspondence techniques, we now compare their traits, and motivate from a theoretical standpoint why we use NICP in our proposed pipeline. Empirical evidence supporting these thoughts will be provided in Sect.&#x000a0;<xref rid="Sec27" ref-type="sec">7.6</xref>, where we will see how the different dense correspondence techniques impact the quality of the 3DMM we are able to construct from the MeIn3D dataset.</p><p id="Par71">UV-based correspondence approaches are powerful in allowing for the simple reuse of image registration techniques, and are computationally efficient. As noted, they may also operate in the native domain for some 3D capture devices. However they are not without some disadvantages. Principally, a UV map can preclude the mapping of intricate details of face shape like the interior of the nostrils and the interior of the mouth. Furthermore, the UV space, which is typically a cylindrical projection of the 3D facial surface, introduces non-linearities into the dense correspondence process. For example, a uniform sampling in the UV space would lead to evenly sized triangles and evenly spaced vertices only in the case of a perfect cylinder. In areas of the face that differ greatly from this (such as the sides of the nose) the sampling will be no longer uniform. Furthermore, registering such cylindrical projections together can also introduce errors due to this same effect. In essence, we are relying on every face to share the same non-linearities to &#x02018;cancel out&#x02019; each other to have a successful registration. When this is not the case (for instance there is a huge variation in nose shape) our registration must in some way be compromised by such issues (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>).</p><p id="Par72">Finally, UV maps simply complicate the pipeline for 3DMM construction, in the sense that they require a rasterizing of the UV image and a subsequent sampling of the space to rebuild a mesh.</p><p id="Par73">On the other hand, NICP is a principled energy minimization problem that avoids a number of these pitfalls. An argument against NICP would be that is an entirely geometry and topology-driven technique. The UV shape can in general admit shape and texture information, which can be used in driving the correspondence calculation (for instance, aligning similar skin pigment regions together). However, in our particular context, this behavior becomes somewhat of a liability for two reasons. Firstly, we again are seeking to find an anatomically relevant statistical model of the human face. Any texture information included my bias the dense correspondence calculation, compromising the quality of the model. Secondly, we again point out that MeIn3D contains a huge variety of ethnicity variation, which one could reasonably expect would affect the ability for techniques like optical flow to find good correspondences.<fig id="Fig6"><label>Fig. 6</label><caption><p>Our fully automated pipeline for constructing large scale 3DMMs. (1) Automatic landmarking based on synthetically rendered views. The rendered views have per-pixel shape information registered with them, and so the 2D landmarks can be projected reliably back to the 3D surface. (2) Guided by the automatic landmarks, the 3D template is iteratively deformed to exactly match every 3D facial mesh of the dataset. (3) A initial global PCA is constructed, and (4) erroneous correspondences are automatically removed. (5) LSFM models are constructed from the remaining clean data</p></caption><graphic xlink:href="11263_2017_1009_Fig6_HTML" id="MO36"/></fig>
</p></sec></sec><sec id="Sec17"><title>Proposed Pipeline</title><p id="Par74">Let us consider the scenario that, as with MeIn3D database, one has a large-scale database of 3D facial scans and wants to apply a technique to construct a high-quality 3DMM. Such a large database raises some unique scalability challenges. We believe that it is highly beneficial to have a fully automated technique that would not require any kind of manual annotation. It is also very important that this technique is efficient in terms of both runtimes and memory requirements.</p><p id="Par75">We introduce a 3DMM construction pipeline that meets all the aforementioned specifications, see Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>. It starts with a novel and robust approach to 3D landmark localization. The 3D landmarks are then employed as soft constraints in NICP to place all meshes in correspondence with a template facial surface. With such a large cohort of data, there will be some convergence failures from either landmarking error or NICP. We propose a refinement post-processing step that weeds out problematic subjects automatically, guaranteeing that the LSFM models are only constructed from training data for which we have a high confidence of successful processing.</p><sec id="Sec18"><title>Automatic Annotation</title><p id="Par76">Image landmark localization is a well studied field. Our proposed technique allows us to bring to bear the huge expertise developed in image landmark localization to 3D landmark localization, allowing us to leverage the extensive datasets and state of the art techniques that are now readily available in this domain&#x000a0;(Alabort-i Medina et&#x000a0;al. <xref ref-type="bibr" rid="CR2">2014</xref>). This approach is similar to the work of&#x000a0;Cosker et&#x000a0;al. (<xref ref-type="bibr" rid="CR19">2011</xref>) which was shown to be successful for temporal person-specific sequences, but here we pay particular attention to mesh sets with highly variable identity.</p><p id="Par77">We do this by rendering each mesh from a number of virtual cameras positioned around the subject. Each virtual camera, which has a realistic perspective projection camera matrix, records an RGB texture image and an XYZ shape image. The texture view is a typical image of a face with a known pose, and so we are able to use a HOG active appearance model, a state-of-the-art image landmark localization technique&#x000a0;(Antonakos et&#x000a0;al. <xref ref-type="bibr" rid="CR6">2014</xref>), initialized from a state-of-the-art face detector&#x000a0;(King <xref ref-type="bibr" rid="CR37">2009</xref>, Alabort-i Medina et&#x000a0;al. <xref ref-type="bibr" rid="CR2">2014</xref>), in order to robustly locate a set of 68 sparse annotations in the view. The HOG AAM was trained on the diverse labelled face parts in the wild (LFPW) dataset&#x000a0;(Belhumeur et&#x000a0;al. <xref ref-type="bibr" rid="CR7">2011</xref>), and so is highly robust to pose, ethnicity, and emotive variation.</p><p id="Par78">We train pose-specific landmark localization models for each view rendered, and use the shape images to project the fitting to the 3D surface, compositing the resulting 3D landmarks found into a master annotation set. Figure&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>a graphically shows our landmark localisation technique.</p></sec><sec id="Sec19"><title>Dense Correspondences</title><p id="Par79">Following the analysis in Sect.&#x000a0;<xref rid="Sec16" ref-type="sec">5.3</xref>, and motivated by the empirical evidence we will put forward in Sect.&#x000a0;<xref rid="Sec27" ref-type="sec">7.6</xref>, we choose to adopt the most effective correspondence approach, namely the NICP method. This method needs the specification of a template mesh and our choice is the mean face of the BFM model&#x000a0;(Paysan et&#x000a0;al. <xref ref-type="bibr" rid="CR30">2009a</xref>).</p><p id="Par80">Each mesh is individually placed in correspondence with the template mesh. In more detail, we first use the automatically extracted landmarks to perform an optimal similarity alignment between the mesh in question and the (annotated) template, adopting Procrustes analysis. We then use NICP to deform the template so that it takes the shape of the input mesh, with the automatic landmarks acting as a soft constraint. The resulting deformed templates are re-parameterized versions of each subject which are correspondence with one another.</p></sec><sec id="Sec20"><title>Automatic Error Pruning</title><p id="Par81">With such a large number of subjects there will be some failure cases at this stage. This is an unavoidable byproduct of the fact that both landmark localization and NICP are non-convex optimization problems that are sensitive to initialization. Our approach embraces this, seeking to weed out the small number of failure cases given the huge amount of data available for processing.</p><p id="Par82">To remove outliers, we first construct an initial global PCA from all fittings. This PCA model of shape variation is expressed by Eq.&#x000a0;(<xref rid="Equ1" ref-type="">1</xref>). Adopting a commonly-used probabilistic interpretation of this model, we assume that the shape parameters <inline-formula id="IEq81"><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha _1,\ldots ,\alpha _d$$\end{document}</tex-math><mml:math id="M176"><mml:mrow><mml:msub><mml:mi mathvariant="italic">&#x003b1;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="italic">&#x003b1;</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq81.gif"/></alternatives></inline-formula> are independent random variables and that each <inline-formula id="IEq82"><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha _i$$\end{document}</tex-math><mml:math id="M178"><mml:msub><mml:mi mathvariant="italic">&#x003b1;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq82.gif"/></alternatives></inline-formula> follows a Gaussian distribution with zero mean and variance <inline-formula id="IEq83"><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda _i$$\end{document}</tex-math><mml:math id="M180"><mml:msub><mml:mi mathvariant="italic">&#x003bb;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq83.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq84"><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda _i$$\end{document}</tex-math><mml:math id="M182"><mml:msub><mml:mi mathvariant="italic">&#x003bb;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq84.gif"/></alternatives></inline-formula> is the <italic>i</italic>-th PCA eigenvalue (i.e.&#x000a0;the <italic>i</italic>-th eigenvalue of the training data covariance matrix) (Davies et&#x000a0;al. <xref ref-type="bibr" rid="CR20">2008</xref>).</p><p id="Par83">Therefore, the normalized shape parameters <inline-formula id="IEq85"><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{\alpha _1}{\sqrt{\lambda _1}},\ldots ,\frac{\alpha _d}{\sqrt{\lambda _d}}$$\end{document}</tex-math><mml:math id="M184"><mml:mrow><mml:mfrac><mml:msub><mml:mi mathvariant="italic">&#x003b1;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msqrt><mml:msub><mml:mi mathvariant="italic">&#x003bb;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msqrt></mml:mfrac><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mfrac><mml:msub><mml:mi mathvariant="italic">&#x003b1;</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:msqrt><mml:msub><mml:mi mathvariant="italic">&#x003bb;</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq85.gif"/></alternatives></inline-formula> are independent and identically distributed following a zero-mean and unit-variance Gaussian distribution and their squared sum, which can be written as:<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} F(\varvec{\alpha }) = \sum _{i=1}^{d} \frac{\alpha _i^2}{\lambda _d} \end{aligned}$$\end{document}</tex-math><mml:math id="M186" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>d</mml:mi></mml:munderover><mml:mfrac><mml:msubsup><mml:mi mathvariant="italic">&#x003b1;</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi mathvariant="italic">&#x003bb;</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11263_2017_1009_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>follows a chi-square distribution with <italic>d</italic> degrees of freedom (Patel and Smith <xref ref-type="bibr" rid="CR29">2009</xref>). The above sum is actually a weighted norm of the shape vector <inline-formula id="IEq86"><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\alpha }$$\end{document}</tex-math><mml:math id="M188"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq86.gif"/></alternatives></inline-formula> and yields a squared Mahalanobis distance between the current shape and the mean shape. This can be used as a measure of plausibility of the shape with shape parameters <inline-formula id="IEq87"><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\alpha }$$\end{document}</tex-math><mml:math id="M190"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq87.gif"/></alternatives></inline-formula>, under the current PCA model (Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>).</p><p id="Par84">Based on the aforementioned remarks, for every training face mesh that has been put in correspondence using NICP and afterwards subjected in Procrustes alignment, we find its shape parameters <inline-formula id="IEq88"><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\alpha }$$\end{document}</tex-math><mml:math id="M192"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq88.gif"/></alternatives></inline-formula> by projecting on the initial global PCA model. Then, we use the squared norm <inline-formula id="IEq89"><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F(\varvec{\alpha })$$\end{document}</tex-math><mml:math id="M194"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq89.gif"/></alternatives></inline-formula> as the criterion to detect failures of the dense correspondence estimation. This is due to the fact that these failures behave as outliers of the Gaussian distribution.</p><p id="Par85">We classify as outliers all shape vectors <inline-formula id="IEq90"><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\alpha }$$\end{document}</tex-math><mml:math id="M196"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq90.gif"/></alternatives></inline-formula> with a squared norm <inline-formula id="IEq91"><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F(\varvec{\alpha })$$\end{document}</tex-math><mml:math id="M198"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq91.gif"/></alternatives></inline-formula> above a threshold <inline-formula id="IEq92"><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\theta _f$$\end{document}</tex-math><mml:math id="M200"><mml:msub><mml:mi mathvariant="italic">&#x003b8;</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq92.gif"/></alternatives></inline-formula>. This threshold is selected so that <inline-formula id="IEq93"><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F(\varvec{\alpha })$$\end{document}</tex-math><mml:math id="M202"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq93.gif"/></alternatives></inline-formula> is expected to be less than <inline-formula id="IEq94"><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\theta _f$$\end{document}</tex-math><mml:math id="M204"><mml:msub><mml:mi mathvariant="italic">&#x003b8;</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq94.gif"/></alternatives></inline-formula> with a very high probability <inline-formula id="IEq95"><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_f$$\end{document}</tex-math><mml:math id="M206"><mml:msub><mml:mi>p</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq95.gif"/></alternatives></inline-formula> (e.g.&#x000a0;99%), under the assumed Gaussian distribution. Consequently, <inline-formula id="IEq96"><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\theta _f$$\end{document}</tex-math><mml:math id="M208"><mml:msub><mml:mi mathvariant="italic">&#x003b8;</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq96.gif"/></alternatives></inline-formula> is specified by the evaluation of the chi-square inverse cumulative distribution function at the probability <inline-formula id="IEq97"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_f$$\end{document}</tex-math><mml:math id="M210"><mml:msub><mml:mi>p</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq97.gif"/></alternatives></inline-formula>. Note that the set of shape vectors <inline-formula id="IEq98"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha $$\end{document}</tex-math><mml:math id="M212"><mml:mi mathvariant="italic">&#x003b1;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq98.gif"/></alternatives></inline-formula> with <inline-formula id="IEq99"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F(\varvec{\alpha })&#x0003c;\theta _f$$\end{document}</tex-math><mml:math id="M214"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi mathvariant="italic">&#x003b8;</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq99.gif"/></alternatives></inline-formula> corresponds to a hyper-ellipse in the <italic>d</italic>-dimensional space of shape parameters. Following the aforementioned procedure, we find that less than 1% of the training meshes are classified as outliers.</p><p id="Par86">Finally, we derive the LSFM models by applying PCA again on the corresponding training sets, after excluding the shape vectors that have been classified as outliers.</p></sec></sec><sec id="Sec21"><title>Experiments</title><p id="Par87">In this section we will analyze in detail the pipeline put forward in Sect.&#x000a0;<xref rid="Sec17" ref-type="sec">6</xref>. We will be applying the methodology to the newly introduced MeIn3D database, and reporting on the performance of the resultant 3DMM against three state of the art 3DMMs (Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref>)<fig id="Fig7"><label>Fig. 7</label><caption><p>Distribution of ages of subjects included in the MeIn3D dataset</p></caption><graphic xlink:href="11263_2017_1009_Fig7_HTML" id="MO37"/></fig>
</p><sec id="Sec22"><title>Global LSFM Model</title><p id="Par88">We derive our global LSFM model (hereafter referred to as <italic>LSFM-global</italic>) by applying the proposed construction pipeline on the MeIn3D dataset. Figure&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> visualizes the shape component of LSFM-global by showing the mean shape along with the top five principal components of shape variation. We observe that the principal modes of variation capture trends of facial shape deformation due to gender, age, ethnicity and other variability in a particularly plausible way, yielding high-quality 3D facial shapes. Similarly, Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> visualizes LSFM-global by showing the mean texture along with the top five principal components of texture variation, all visualized on the mean shape and again clear variations in ethnicity, gender and age are visible. We observe that the textures corresponding to the mean texture and the principal components are highly-detailed and correspond to a plausible representation of texture in human faces.</p><p id="Par89">An additional visualization of LSFM-global is provided by Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>, which shows synthetic facial shapes generated by the model. More precisely, the shapes are synthesized using Eq.&#x000a0;(<xref rid="Equ1" ref-type="">1</xref>) with shape parameters <inline-formula id="IEq100"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha _i$$\end{document}</tex-math><mml:math id="M216"><mml:msub><mml:mi mathvariant="italic">&#x003b1;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq100.gif"/></alternatives></inline-formula> that are randomly sampled, assuming statistical independence and zero-mean gaussian distribution for each parameter, with variance given by the corresponding PCA eigenvalue. It can be seen that all synthetic faces exhibit a high degree of realism, including fine details in the facial structures. Furthermore, we observe that the statistical distribution of LSFM-global succeeds in capturing a plethora of demographic characteristics (age, gender and ethnicity).<fig id="Fig8"><label>Fig. 8</label><caption><p>t-SNE embedding of the high dimensional face manifold in two dimensions. <italic>Left</italic> a clear trend of increasing age can be seen. <italic>Right</italic> the two smaller structures are explained largely as ethnic variations</p></caption><graphic xlink:href="11263_2017_1009_Fig8_HTML" id="MO38"/></fig>
</p></sec><sec id="Sec23"><title>LSFM-Global Facial Manifold Visualisation</title><p id="Par90">Here, we explore the properties of the LSFM-global manifold. After establishing dense correspondences with our pipeline and excluding the outliers, every retained training sample <inline-formula id="IEq101"><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {X}$$\end{document}</tex-math><mml:math id="M218"><mml:mi mathvariant="bold">X</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq101.gif"/></alternatives></inline-formula> is projected on the LSFM-global model and represented by the vector of shape parameters <inline-formula id="IEq102"><alternatives><tex-math id="M219">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha $$\end{document}</tex-math><mml:math id="M220"><mml:mi mathvariant="italic">&#x003b1;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq102.gif"/></alternatives></inline-formula> that yields the closest shape within the model subspace, see Eq.&#x000a0;(<xref rid="Equ3" ref-type="">3</xref>). We then apply t-SNE&#x000a0;(Maaten and Hinton <xref ref-type="bibr" rid="CR1">2008</xref>) to the shape vectors from all training samples to visualize the manifold of training shapes, as represented in the <italic>d</italic>-dimensional model subspace. Leveraging the per-subject demographic data we have, we are able to label samples in this space by their age, see Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref> (left). Interestingly, a clear trend of increasing age across the bulk of the manifold can be seen, suggesting that the facial manifold has age-related structure.</p><p id="Par91">Furthermore, we visualize the space by ethnicity, Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref> (right). Note that we chose three ethnic groups for which the number of samples in the used dataset was sufficient for our analysis. We observe that t-SNE has produced a nonlinear 2D embedding that dedicates the largest area for the White ethnic group, which is not surprising, given the fact that this ethnic group is over-represented in the MeIn3D database (<inline-formula id="IEq103"><alternatives><tex-math id="M221">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$82\%$$\end{document}</tex-math><mml:math id="M222"><mml:mrow><mml:mn>82</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq103.gif"/></alternatives></inline-formula> of the samples). What is particularly interesting is the fact that the clusters that are clearly separable from the main manifold are actually specific ethnic groups.</p></sec><sec id="Sec24"><title>Bespoke Demographic Models</title><p id="Par92">These visualizations provide insight into how different regions of the high-dimensional space of human face shape and texture are naturally related to different demographic characteristics. We use this insight to define specific <italic>bespoke models</italic> that are trained on dedicated subsets of the full MeIn3D training population. Taking also into account the demographics of the training data available (see Sect.&#x000a0;<xref rid="Sec9" ref-type="sec">4.2</xref>), we define the following groups: <bold>Black</bold> (all ages), <bold>Chinese</bold> (all ages) and White ethnic group, which due to large availability of training samples, is further clustered into four age groups: under 7 years old (<bold>White-under 7</bold>), 7&#x02013;18 years old (<bold>White-7 to 18</bold>), 18&#x02013;50 years old (<bold>White-18 to 50</bold>) and over 50 years old (<bold>White-over 50</bold>). The mean and most significant 5 shape components of the 6 demographic-specific models are given in Fig.&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref>. Likewise, Fig.&#x000a0;<xref rid="Fig10" ref-type="fig">10</xref> shows the mean and most significant 5 texture components of the six demographic-specific models visualized on the mean shape.<fig id="Fig9"><label>Fig. 9</label><caption><p>Bespoke shape models produced for specific subsets of the <italic>MeIn3D</italic> dataset. For each bespoke model, the figure shows the mean shape <inline-formula id="IEq104"><alternatives><tex-math id="M223">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M224"><mml:mi mathvariant="italic">&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq104.gif"/></alternatives></inline-formula> as well as the first five shape eigenvectors, each visualized as additions and subtractions away from the mean. In more detail, the <italic>top</italic> (<italic>bottom</italic>) row corresponds to deviating from <inline-formula id="IEq105"><alternatives><tex-math id="M225">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M226"><mml:mi mathvariant="italic">&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq105.gif"/></alternatives></inline-formula> in the direction of the corresponding shape eigenvector, with a weight of 3<inline-formula id="IEq106"><alternatives><tex-math id="M227">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _i$$\end{document}</tex-math><mml:math id="M228"><mml:msub><mml:mi mathvariant="italic">&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq106.gif"/></alternatives></inline-formula> (<inline-formula id="IEq107"><alternatives><tex-math id="M229">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$-3\sigma _i$$\end{document}</tex-math><mml:math id="M230"><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn><mml:msub><mml:mi mathvariant="italic">&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq107.gif"/></alternatives></inline-formula>), where <inline-formula id="IEq108"><alternatives><tex-math id="M231">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _i$$\end{document}</tex-math><mml:math id="M232"><mml:msub><mml:mi mathvariant="italic">&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq108.gif"/></alternatives></inline-formula> is the standard deviation of the corresponding component</p></caption><graphic xlink:href="11263_2017_1009_Fig9_HTML" id="MO39"/></fig>
<fig id="Fig10"><label>Fig. 10</label><caption><p>Bespoke texture models produced for specific subsets of the <italic>MeIn3D</italic> dataset. For each bespoke model, the figure shows the mean texture <inline-formula id="IEq109"><alternatives><tex-math id="M233">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M234"><mml:mi mathvariant="italic">&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq109.gif"/></alternatives></inline-formula> as well as the first five texture eigenvectors, each visualized as additions and subtractions away from the mean. In more detail, the <italic>top</italic> (<italic>bottom</italic>) row corresponds to deviating from <inline-formula id="IEq110"><alternatives><tex-math id="M235">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M236"><mml:mi mathvariant="italic">&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq110.gif"/></alternatives></inline-formula> in the direction of the corresponding texture eigenvector, with a weight of 3<inline-formula id="IEq111"><alternatives><tex-math id="M237">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _i$$\end{document}</tex-math><mml:math id="M238"><mml:msub><mml:mi mathvariant="italic">&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq111.gif"/></alternatives></inline-formula> (<inline-formula id="IEq112"><alternatives><tex-math id="M239">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$-3\sigma _i$$\end{document}</tex-math><mml:math id="M240"><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn><mml:msub><mml:mi mathvariant="italic">&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq112.gif"/></alternatives></inline-formula>), where <inline-formula id="IEq113"><alternatives><tex-math id="M241">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma _i$$\end{document}</tex-math><mml:math id="M242"><mml:msub><mml:mi mathvariant="italic">&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq113.gif"/></alternatives></inline-formula> is the standard deviation of the corresponding component. All textures are visualized on the mean 3D shape</p></caption><graphic xlink:href="11263_2017_1009_Fig10_HTML" id="MO40"/></fig>
</p><p id="Par93">We combine these bespoke models in a large mixture model, which we call LSFM-bespoke. The intrinsic characteristics of both LSFM-global and LSFM-bespoke will be evaluated in the next section.</p></sec><sec id="Sec25"><title>Training and Test Sets</title><p id="Par94">For all the subsequent experiments, MeIn3D dataset was split into a training set and a test set. In more detail, a set of 400 meshes of MeIn3D was excluded from the original training set to form a test set. This test set was randomly chosen within demographic constraints to ensure a gender, ethnic and age diversity. Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> shows the makeup of the test set. Despite the fact that this test set does not capture the full range of diversity present in the demographics of humans, its diversity is still a huge step up from existing datasets used in testing 3DMMs. Note that for the sake of fairness of the following evaluations, LSFM-global and LSFM-bespoke models were re-trained using the resultant training set. This is slightly smaller than the original training set, which included the whole MeIn3D.</p></sec><sec id="Sec26"><title>Intrinsic Evaluation of LSFM Models</title><p id="Par95">Following common practice in the literature of statistical shape models, we evaluate the intrinsic characteristics of LSFM-global and LSFM-bespoke using <italic>compactness</italic>, <italic>generalization</italic> and <italic>specificity</italic>, see e.g.&#x000a0;Davies et&#x000a0;al. (<xref ref-type="bibr" rid="CR20">2008</xref>),&#x000a0;Brunton et&#x000a0;al. (<xref ref-type="bibr" rid="CR17">2014b</xref>),&#x000a0;Bolkart and Wuhrer (<xref ref-type="bibr" rid="CR12">2015</xref>). We consider the 3D shapes of MeIn3D dataset after establishing dense correspondences, using our pipeline.</p><p id="Par96">Figure&#x000a0;<xref rid="Fig11" ref-type="fig">11</xref> shows the <bold>compactness</bold> plots for the LSFM models. Compactness measures the percentage of variance of the training data that is explained by a model when certain number of principal components are retained. Note that in the case of the bespoke models, the training samples of the corresponding demographic group are only considered, which means that the total variance is different for every model. We observe that all trained models exhibit similar traits in the variance captured, although this naturally varies with the size of the training set in each case of the tailored models. Both global and bespoke LSFM models can be considered sufficiently compact; for example for all the models, as few as 40 principal components are able to explain more than 90% of the variance in the training set.</p><p id="Par97">Figure&#x000a0;<xref rid="Fig12" ref-type="fig">12</xref> presents plots of model <bold>generalization</bold>, which measures the ability of a model to represent novel instances of face shapes that are unseen during training. To compute the generalization error of a model for a given number of principal components retained, we compute the per-vertex Euclidean distance between every sample of the test set <inline-formula id="IEq114"><alternatives><tex-math id="M243">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {X}$$\end{document}</tex-math><mml:math id="M244"><mml:mi mathvariant="bold">X</mml:mi></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq114.gif"/></alternatives></inline-formula> and its corresponding model projection <inline-formula id="IEq115"><alternatives><tex-math id="M245">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P(\mathbf {X})$$\end{document}</tex-math><mml:math id="M246"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq115.gif"/></alternatives></inline-formula>, Eq.&#x000a0;(<xref rid="Equ3" ref-type="">3</xref>), and then take the average value over all vertices and all test samples. In order to derive an overall generalization measure for LSFM-bespoke, for every test sample we use its demographic information and project on the subspace of the corresponding bespoke model and then compute an overall average error. The number of components retained in the case of the LSFM-bespoke model is the number of components retained for the demographically-matching bespoke model for a given training sample. We plot the generalization errors with respect to both the number of principal components (Fig.&#x000a0;<xref rid="Fig12" ref-type="fig">12</xref>a) and percentage of total variance retained (Fig.&#x000a0;<xref rid="Fig12" ref-type="fig">12</xref>b). We observe that both LSFM-global and LSFM-bespoke are able to generalize well, since for even low number of components and total variance retained, they yield particularly low generalization errors. Interestingly, we see in Fig.&#x000a0;<xref rid="Fig12" ref-type="fig">12</xref>a that LSFM-bespoke achieves superior generalization measures when compared to LSFM-global for an equivalent number of components for fewer than 60 components. After this stage the global model starts to outperform the specific models, which might attributed to the fact that many of the specific models are built from smaller cohorts of training data, and so run out of interesting statistical variance at an earlier stage. When changing the visualization to one based on retained variance (Fig.&#x000a0;<xref rid="Fig12" ref-type="fig">12</xref>b), we observe that the demographic-specific LSFM-bespoke model achieves better generalization performance for the vast majority of values of retained variance.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Proportions of each demographic group represented in the MeIn3D test set</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Demographic</th><th align="left">Count</th></tr></thead><tbody><tr><td align="left">Black</td><td align="left">40 (20 male and 20 female)</td></tr><tr><td align="left">Chinese</td><td align="left">40 (20 male and 20 female)</td></tr><tr><td align="left">White-under 7</td><td align="left">80 (40 male and 40 female)</td></tr><tr><td align="left">White-7 to 18</td><td align="left">80 (40 male and 40 female)</td></tr><tr><td align="left">White-18 to 50</td><td align="left">80 (40 male and 40 female)</td></tr><tr><td align="left">White-over 50</td><td align="left">80 (40 male and 40 female)</td></tr></tbody></table></table-wrap>
</p><p id="Par98">
<fig id="Fig11"><label>Fig. 11</label><caption><p>Compactness of the LSFM models. <bold>a</bold> LSFM-global. <bold>b</bold> LSFM-bespoke</p></caption><graphic xlink:href="11263_2017_1009_Fig11_HTML" id="MO41"/></fig>
<fig id="Fig12"><label>Fig. 12</label><caption><p>Generalization of the LSFM models</p></caption><graphic xlink:href="11263_2017_1009_Fig12_HTML" id="MO42"/></fig>
</p><p id="Par99">Figure&#x000a0;<xref rid="Fig13" ref-type="fig">13</xref> presents the <bold>specificity</bold> of the introduced models, which evaluate the validity of synthetic faces generated by a model. To measure this, we randomly synthesize 10,000 faces from each model for a fixed number of components and measure how close they are to the real faces of the test set. More precisely, for every random synthetic face, we find its nearest neighbor in the test set, in terms of minimum (over all samples of the test set) of the average (over all vertices) per-vertex distance. We record the mean of this distance over all samples as the specificity error. Figure&#x000a0;<xref rid="Fig13" ref-type="fig">13</xref>a contains the specificity plot for LSFM-global (mean value as well as standard deviation bars), whereas Figure&#x000a0;<xref rid="Fig13" ref-type="fig">13</xref>b contains the specificity plots for all models of LSFM-bespoke (mean values only; the standard deviation bars have been omitted for the sake of visualization clarity). We observe that in all the cases, the specificity errors attain particularly low values, in the range of 1&#x02013;1.6 mm, even for a relatively large number of principal components. This is a quantitative evidence that the synthetic faces generated by both global and bespoke LSFM models are realistic, which complements the qualitative observations of Sect.&#x000a0;<xref rid="Sec22" ref-type="sec">7.1</xref>. Interestingly, Fig.&#x000a0;<xref rid="Fig13" ref-type="fig">13</xref>b suggests that specificity error is larger for models trained from smaller populations, as e.g.&#x000a0;in the case of Black model. Apart from the lack of sufficient representative training data, this might also be attributed to the fact that the space of such models is more sparsely populated by training samples, so the nearest neighbor error tends to be larger, as compared to other models with more training data. Furthermore, it can be seen that the lowest specificity error comes from the White-7 to 18 model, which is trained on a large number of samples that lie on a smaller cluster of the space, leading to a highly specific model.<fig id="Fig13"><label>Fig. 13</label><caption><p>Specificity for each of the tailored models. <bold>a</bold> specificity and standard deviation for global model. <bold>b</bold> specificity for the tailored models</p></caption><graphic xlink:href="11263_2017_1009_Fig13_HTML" id="MO43"/></fig>
</p></sec><sec id="Sec27"><title>Comparison of Dense Correspondence Methods</title><p id="Par100">We now repeat select studies from the previous sections (using the same parameters as before), only now we vary the dense correspondence algorithm employed (all models are built using data from the global MeIn3D dataset). With this work, we will empirically motivate our choice of NICP for providing dense correspondences in our method over the alternatives (UV-OF, UV-TPS).</p><p id="Par101">Note that for UV-OF, we used the Improved TV-L1 algorithm&#x000a0;(Wedel et&#x000a0;al. <xref ref-type="bibr" rid="CR39">2009</xref>), which is a relatively recent state-of-the-art optical flow algorithm. This algorithm demonstrates improved robustness and accuracy, as compared to traditional optical flow methods.</p><p id="Par102">Figure&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref> shows an example dense correspondence result for NICP, UV-TPS and UV-OF. Most striking is that NICP is better able to deal with a larger region of the facial surface. The UV-based techniques cannot interpolate well for broader regions of the head as areas like the underside of the chin and the interior of the mouth are not well mapped onto a cylinder. Furthermore, NICP has some hole filling capability, where the natural result of the optimization problem leads to missing regions of the target being replaced by interpolated values drawn from the corresponding part of the template (we refer the interested reader to&#x000a0;Amberg et&#x000a0;al. (<xref ref-type="bibr" rid="CR5">2007</xref>) for details). In this example this infilling can be seen to successfully recover the chin region, which is entirely missing in the original scan.</p><p id="Par103">Figure&#x000a0;<xref rid="Fig14" ref-type="fig">14</xref>a shows how NICP-based correspondences generate a model with a superior compactness quality. Figure&#x000a0;<xref rid="Fig14" ref-type="fig">14</xref>b reports the mean dense reconstruction error for out-of-sample BU3D-FE faces with the different dense correspondence techniques for varying retained parameters. This is perhaps the most direct measure we have presented so far of 3DMM performance, and in this experiment we see that NICP has produced a far more useful basis in our particular context.<fig id="Fig14"><label>Fig. 14</label><caption><p>
<bold>a</bold> Compactness for LSFM models built with differing dense correspondence methods. <bold>b</bold> Mean dense point-to-point reconstruction error when reconstructing out-of-sample faces (drawn from BU3D-FE) in the LSFM shape models</p></caption><graphic xlink:href="11263_2017_1009_Fig14_HTML" id="MO44"/></fig>
</p></sec><sec id="Sec28"><title>Fitting Application</title><p id="Par104">In order to gauge the quality of the LSFM-global model in comparison with the state-of-the-art, we evaluate the performance of the models in a real-world fitting scenario. We compare with three publicly available Morphable Models of human faces in neutral expression, namely the <italic>BFM model</italic>&#x000a0;(Paysan et&#x000a0;al. <xref ref-type="bibr" rid="CR30">2009a</xref>,&#x000a0;Paysan et&#x000a0;al. <xref ref-type="bibr" rid="CR31">2009b</xref>), the PCA model of&#x000a0;Brunton et&#x000a0;al. (<xref ref-type="bibr" rid="CR17">2014b</xref>),&#x000a0;Bolkart et&#x000a0;al. (<xref ref-type="bibr" rid="CR10">2013</xref>), which will be hereafter referred to as <italic>Brunton et al.&#x000a0;model</italic>, and the Surrey face model&#x000a0;(Huber et&#x000a0;al. <xref ref-type="bibr" rid="CR26">2016</xref>). Note that for the sake of fairness towards the existing models, we do not consider the bespoke LSFM models in the fitting experiment, since these models use additional information related to demographics.<fig id="Fig15"><label>Fig. 15</label><caption><p>Four examples of reconstructions performed using the LSFM-global model on individuals from the BU3D-FE database. For each individual, <bold>a</bold> is the original scan, and <bold>b</bold> is the reconstruction attained</p></caption><graphic xlink:href="11263_2017_1009_Fig15_HTML" id="MO45"/></fig>
</p><p id="Par105">Note that for all versions of LSFM-global evaluated hereafter, we choose the number of principal components, so as to explain <inline-formula id="IEq116"><alternatives><tex-math id="M247">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$99.5\%$$\end{document}</tex-math><mml:math id="M248"><mml:mrow><mml:mn>99.5</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq116.gif"/></alternatives></inline-formula> of the training set variance. For BFM, Brunton et al. and Surrey models, we use all the principal components, as given by the publicly available versions of these models.</p><p id="Par106">To evaluate the fitting performance of every tested model, every mesh in the adopted test set is automatically annotated with facial landmarks using our technique outlined in Sect.&#x000a0;<xref rid="Sec18" ref-type="sec">6.1</xref>. The same set of landmarks is manually placed on the mean faces of every model, and subsequently used to similarity-align them with every mesh of the test set. Similarly to&#x000a0;Brunton et&#x000a0;al. (<xref ref-type="bibr" rid="CR17">2014b</xref>),&#x000a0;Zulqarnain Gilani et&#x000a0;al. (<xref ref-type="bibr" rid="CR40">2015</xref>), a simple model fitting is employed, which consists of<list list-type="order"><list-item><p id="Par107">Search for the nearest vertex in the test mesh to establish correspondences between that mesh and the model</p></list-item><list-item><p id="Par108">Project the test mesh onto the model using Eq.&#x000a0;(<xref rid="Equ3" ref-type="">3</xref>).</p></list-item></list>The per-vertex fitting error is then computed as the distance between every vertex of the test mesh and the nearest-neighbor vertex of the corresponding model-based fitting. Note that we use a simple fitting strategy to provide an appropriate mechanism to benchmark models against one another fairly&#x02014;the fitting algorithm itself is not under test here, but rather the models themselves.</p><p id="Par109">We evaluate a dense surface error for vertices of the raw MeIn3D scans of the test set, to remain fair across the different model densities. Furthermore we only consider the vertices within a central region of the face, which is certainly present in all models under evaluation. This means that any differences present between different models (throat, ears, inner mouth) do not come into play. Given that we evaluate on raw scans without considering any dense correspondence estimation, we lack the dense semantic understanding of the face. In the absence of this, we chose the vertices that we evaluate on by using a fixed radial distance from the (annotated) nosetip of each MeIn3D scan in the test set. Only vertices within this region, which is a tight crop of the inner facial features, are considered in our error metric.</p><p id="Par110">Figure&#x000a0;<xref rid="Fig16" ref-type="fig">16</xref> compares the fitting performance of LSFM-global against BFM, Brunton et al. and Surrey models, in terms of cumulative error distribution (CED) curves of per-vertex fitting errors. We observe that LSFM-global achieves exceptionally improved accuracy and robustness, as compared to the other two models. This is attributed to the larger training sample used, the increased demographic range, and the quality of the MeIn3D scans. We will explore the dimorphic and quantity effects on the model performance in Sect.&#x000a0;<xref rid="Sec29" ref-type="sec">7.8</xref>. We also note that this is the first time that existing models are evaluated against a dataset containing a large variation in ethnicity and age. The significantly larger variability in the training set of LSFM-global allows it to generalize well to a much wider variety of faces than the more narrowly-focused existing models. We provide visualizations of fittings for four subjects from BU3D-FE from the LSFM-global model in Fig.&#x000a0;<xref rid="Fig15" ref-type="fig">15</xref>.<fig id="Fig16"><label>Fig. 16</label><caption><p>Cumulative error distributions of the per-vertex fitting error for the publicly-available models under test</p></caption><graphic xlink:href="11263_2017_1009_Fig16_HTML" id="MO46"/></fig>
<fig id="Fig17"><label>Fig. 17</label><caption><p>Two examples of out of sample reconstructions from BU3D-FE using LSFM models trained from 200, 1000, and 8000 subjects</p></caption><graphic xlink:href="11263_2017_1009_Fig17_HTML" id="MO47"/></fig>
<fig id="Fig18"><label>Fig. 18</label><caption><p>Fitting results broken down by different demographic groups</p></caption><graphic xlink:href="11263_2017_1009_Fig18_HTML" id="MO48"/></fig>
</p></sec><sec id="Sec29"><title>Effect of Demographics and Training Set Size</title><p id="Par111">MeIn3D is simultaneously the largest and most variable 3D facial dataset that has existed to date. To provide greater insight into how demographic variability and training set size impact the performance of 3D Morphable Models, we now explore in detail the impact of these two factors on the intrinsics and fitting application of our model (Figs.&#x000a0;<xref rid="Fig16" ref-type="fig">16</xref>,&#x000a0;<xref rid="Fig17" ref-type="fig">17</xref>).</p><sec id="Sec30"><title>Demographics-Specific Analysis of 3D Model Comparisons</title><p id="Par112">In this section, we present a more detailed view of the 3D model fitting comparisons of Sect.&#x000a0;<xref rid="Sec28" ref-type="sec">7.7</xref>. We report performance measures of the compared models on every considered demographic group separately. Figure&#x000a0;<xref rid="Fig18" ref-type="fig">18</xref> presents the CED curves of per-vertex fitting error of all compared models for each considered demographic group. Interestingly, Brunton et al.&#x000a0;model outperforms BFM in all groups except for the group White-over 50, where the situation is clearly reversed. Also, Surrey model performs worse than BFM on the groups of White ethnicity, but on contrary it has a clear advantage over BFM on Black and Chinese groups. Finally, LSFM-global clearly outperforms all other models in all groups, even in groups that are very similar to the demographics of the training data that the other models have built upon, such as the group White-18 to 50.</p><p id="Par113">Intuition suggests that bespoke facial models have value in providing a tailored, more compact model to fit out of sample data. To explore this is indeed the case quantitatively, we construct a model from one demographic group (Black) and perform the a fitting against (a) an ethnicity matched test set and (b) a non-ethnicity matched test set (combination of all White test sets). Figure&#x000a0;<xref rid="Fig19" ref-type="fig">19</xref> shows the result of this test. The same model can clearly be seen to perform better on the demographically matched test set, demonstrating the significance of demographics in 3D facial modelling, and the value of bespoke demographic facial models.<fig id="Fig19"><label>Fig. 19</label><caption><p>In this experiment, a model trained from samples purely drawn from a Black ethnic group is fitted to both a demographically similar Black test set and to an ethnically different white database. The performance is optimal when the demographics of the model match that of the test set</p></caption><graphic xlink:href="11263_2017_1009_Fig19_HTML" id="MO49"/></fig>
<fig id="Fig20"><label>Fig. 20</label><caption><p>Effect of training set size on odel intrinsics. <bold>a</bold> Compactness. <bold>b</bold> Generalization. <bold>c</bold> Specificity, and on the fitting performance of the model <bold>(d)</bold>
</p></caption><graphic xlink:href="11263_2017_1009_Fig20_HTML" id="MO50"/></fig>
</p></sec><sec id="Sec31"><title>Effect of Training Set Size</title><p id="Par114">Given the fact that MeIn3D dataset is so much larger than existing training data sets, it is natural to question the effect of varying the size of the training set on the performance of the constructed 3DMM. To explore this, we repeat the intrinsic evaluation of Sect.&#x000a0;<xref rid="Sec26" ref-type="sec">7.5</xref> as well as the fitting experiment of Sect.&#x000a0;<xref rid="Sec28" ref-type="sec">7.7</xref> for different versions of the LSFM-global model, trained from varying numbers of samples.</p><p id="Par115">The results are visualized in the plots of Fig.&#x000a0;<xref rid="Fig20" ref-type="fig">20</xref>. Regarding the intrinsic evaluation, we first of all observe that the compactness curve goes down as the training size is increased. This is an expected artifact because the compactness measure gives a negative bias to the cases of larger training sets, since the total variance increases significantly. However, this does not mean that the real compactness of the model becomes worse. In addition, we observe that the generalization error decreases significantly as the training size increases. This is attributed to the fact that the statistical model can generalize better when it has been learnt from more training samples. In addition, it is interesting to notice that the specificity measures do not exhibit any statistically significant change with the size of the training set, with the corresponding curves being very close with each other. This means that according to that measure, the faces synthesized by the model retain their degree of realism as the training size increases. But in the same time, they seem to be able to represent a wider variety of human faces, as the aforementioned results on generalization suggest.</p><p id="Par116">Regarding the model fitting performance (Fig.&#x000a0;<xref rid="Fig20" ref-type="fig">20</xref>d), we can see clear improvements for around one order of magnitude more data than is currently used, albeit with diminishing returns beyond a few thousand samples. We also note that even with only 100 samples, LSFM-global matches the performance of the BFM, which was trained on 200 samples. This can be attributed to the larger variability of the LSFM training set, demonstrating how crucial this is for building effective 3DMMs.</p><p id="Par117">Finally, Fig.&#x000a0;<xref rid="Fig17" ref-type="fig">17</xref> visually shows the effect on two BU3D-FE subject reconstructions for models trained from varying numbers of samples. As the training size increases, the model stops overfitting to noise present in the raw scans, and starts to capture the actual shape of the individual more accurately.</p></sec><sec id="Sec32"><title>Limiting Both the Demographics Variability and the Training Size</title><p id="Par118">In the extensive experiments of the previous sections, we have seen that our model yields a significantly improved performance as compared to the existing publicly available 3D face models, both in terms of quantitative and qualitative evaluation. However, it has not been clear until now what is the merit of our 3DMM construction pipeline on this success. Therefore, in this section we evaluate our pipeline by factoring out the advantages that our large-scale dataset offers us.</p><p id="Par119">In more detail, we apply our pipeline on a conventional, small-scale dataset (200 random samples from MeIn3D that correspond to the White ethnic group), which has the same size and similar demographics to that used in the BFM model. The resultant model, which we call SSM-200W (small scale model, built on 200 White subjects), serves only the evaluation purposes of this section and is obviously not to be preferred over our LSFM models.</p><p id="Par120">We then compare SSM-200W with the existing models on a test set (disjoint from the training set) that also contains samples from the White ethnic group only. This compares solely our model building procedure with the corresponding procedures of the existing models. For this comparison, we follow again the model fitting evaluation protocol that we described in Sect.<xref rid="Sec28" ref-type="sec">7.7</xref>. Figure&#x000a0;<xref rid="Fig21" ref-type="fig">21</xref> presents the results, in terms of CED curves of per-vertex fitting errors. We observe that SSM-200W clearly outperforms the existing 3D facial shape models. This clearly shows the effectiveness and robustness of our model building pipeline.<fig id="Fig21"><label>Fig. 21</label><caption><p>In this experiment, we evaluate our model construction pipeline by applying it to a small-scale training set of 200 white subjects, similar to the one used in the training of BFM. We compare the resultant model (SSM-200W) with the publicly available models, by fitting all models to a test set from the white group. Cumulative error distribution curves of the per-vertex fitting error are plotted for each tested model</p></caption><graphic xlink:href="11263_2017_1009_Fig21_HTML" id="MO51"/></fig>
</p></sec></sec><sec id="Sec33"><title>Age Classification From 3D Shape</title><p id="Par121">As a final evaluation, we use the unique traits of the MeIn3D dataset to compare the descriptive power of LSFM-global, BFM and Brunton et al.&#x000a0;models in an age classification experiment. In more detail, we project all the face meshes of the training set onto each of the four models and use the corresponding shape vectors, <inline-formula id="IEq117"><alternatives><tex-math id="M249">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\alpha }$$\end{document}</tex-math><mml:math id="M250"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b1;</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11263_2017_1009_Article_IEq117.gif"/></alternatives></inline-formula>, to represent them, see Eq.&#x000a0;(<xref rid="Equ3" ref-type="">3</xref>). Using the demographic information of MeIn3D dataset, we train a linear support vector machine classifier for each model, which maps the corresponding shape vectors to four age classes: under 7, 7&#x02013;18, 18&#x02013;50, over 50.</p><p id="Par122">To measure the classification accuracy, we project all samples from the test set onto the models and then use the classifier to predict the age bracket for the test subjects. This provides an application-oriented evaluation of the quality of the low-dimensional representation that each 3DMM provides for the large variety of faces present in LSFM. As can be seen in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>, the LSFM-global model outperformed existing models in precision and recall and f-score, correctly classifying the age of 74% of the subjects in the challenging test set .<table-wrap id="Tab2"><label>Table 2</label><caption><p>Mean age classification scores</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Precision</th><th align="left">Recall</th><th align="left">F-Score</th></tr></thead><tbody><tr><td align="left">LSFM-global</td><td align="left">
<bold>0.74</bold>
</td><td align="left">
<bold>0.61</bold>
</td><td align="left">
<bold>0.60</bold>
</td></tr><tr><td align="left">BFM</td><td align="left">0.71</td><td align="left">0.54</td><td align="left">0.51</td></tr><tr><td align="left">Brunton et al.</td><td align="left">0.68</td><td align="left">0.53</td><td align="left">0.52</td></tr><tr><td align="left">Surrey Model</td><td align="left">0.70</td><td align="left">0.44</td><td align="left">0.39</td></tr></tbody></table><table-wrap-foot><p>Bold values indicate the best performance in each metric</p></table-wrap-foot></table-wrap>
</p></sec></sec><sec id="Sec34"><title>Conclusions and Future Work</title><p id="Par123">We have presented LSFM, the most powerful and statistically descriptive 3DMM ever constructed. By making both the LSFM software pipeline and models available, we help to usher in an exciting new era of large scale 3DMMs, where construction is radically simpler and large-scale models can become commonplace. We have demonstrated that our automatically constructed model comfortably outperforms existing state of the art 3DMMs thanks to the sheer variety of facial appearance it was trained on, and further reported on how the size of 3D datasets impacts model performance. We have explored for the very first time the structure of the high dimensional facial manifold, revealing how it is clustered by age and ethnicity variations, and demonstrated for the first time accurate age prediction from 3D shape alone. The ability of the model to differentiate faces according to ethnicity suggests that it is sensitive to subtle genetic variation. This raises the possibility that it may be useful in future medical work, for instance providing the basis for an automated diagnostic tool for patients with genetic conditions. In future work we will analyze in detail the qualities of the LSFM model, exploring what it can tell us about human face variation on the large scale, as well as exploring novel statistical methods for large-scale 3DMM construction. We will furthermore explore how shape and texture information can be fused in dense correspondence approaches in order to maximise the accuracy of the registration of facial meshes.</p></sec></body><back><fn-group><fn id="Fn1"><label>1</label><p id="Par3">Apart from soft-tissue facial shape, 3D morphable models have also been successfully applied in the modelling of human skull shape, see e.g.&#x000a0;Paysan et&#x000a0;al. (<xref ref-type="bibr" rid="CR32">2009c</xref>),&#x000a0;Duan et&#x000a0;al. (<xref ref-type="bibr" rid="CR22">2015</xref>),&#x000a0;Staal et&#x000a0;al. (<xref ref-type="bibr" rid="CR35">2015</xref>).</p></fn><fn id="Fn2"><label>2</label><p id="Par27">
<ext-link ext-link-type="uri" xlink:href="http://faces.cs.unibas.ch/bfm/">http://faces.cs.unibas.ch/bfm/</ext-link>.</p></fn><fn id="Fn3"><label>3</label><p id="Par28">
<ext-link ext-link-type="uri" xlink:href="http://statistical-face-models.mmci.uni-saarland.de/">http://statistical-face-models.mmci.uni-saarland.de/</ext-link>.</p></fn><fn id="Fn4"><label>4</label><p id="Par29">
<ext-link ext-link-type="uri" xlink:href="http://cvssp.org/faceweb/3dmm/facemodels/">http://cvssp.org/faceweb/3dmm/facemodels/</ext-link>.</p></fn><fn id="Fn5"><label>5</label><p id="Par34">
<ext-link ext-link-type="uri" xlink:href="https://github.com/menpo/lsfm">https://github.com/menpo/lsfm</ext-link>.</p></fn><fn id="Fn6"><label>6</label><p id="Par40">
<ext-link ext-link-type="uri" xlink:href="http://www.ibug.doc.ic.ac.uk/resources/lsfm">http://www.ibug.doc.ic.ac.uk/resources/lsfm</ext-link>.</p></fn></fn-group><ack><title>Acknowledgements</title><p> Funding was provided by Engineering and Physical Sciences Research Council (Grant Nos. EP/J017787/1, EP/N007743/1, DTA). This work was done while A. Roussos was with Imperial College London, funded by the Great Ormond Street Hospital Children&#x02019;s Charity (Face Value: W1037) and EP/N007743/1. The work of J. Booth was funded by a Qualcomm Innovation Fellowship.</p></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><mixed-citation publication-type="other">Alabort-i Medina, J., Antonakos, E., Booth, J., Snape, P., &#x00026; Zafeiriou, S. (2014). Menpo: A comprehensive platform for parametric image alignment and visual deformable models. In <italic>Proceedings of the ACM international conference on multimedia, MM &#x02019;14</italic>, pp. 679&#x02013;682. ACM, New York, NY, USA. doi:10.1145/2647868.2654890.</mixed-citation></ref><ref id="CR2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aldrian</surname><given-names>O</given-names></name><name><surname>Smith</surname><given-names>WA</given-names></name></person-group><article-title>Inverse rendering of faces with a 3D morphable model</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><year>2013</year><volume>35</volume><issue>5</issue><fpage>1080</fpage><lpage>1093</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2012.206</pub-id><pub-id pub-id-type="pmid">23520253</pub-id></element-citation></ref><ref id="CR3"><mixed-citation publication-type="other">Amberg, B., Knothe, R., &#x00026; Vetter, T. (2008). Expression invariant 3D face recognition with a morphable model. In <italic>8th IEEE international conference on automatic face &#x00026; gesture recognition FG&#x02019;08</italic>, pp. 1&#x02013;6. IEEE.</mixed-citation></ref><ref id="CR4"><mixed-citation publication-type="other">Amberg, B., Romdhani, S., &#x00026; Vetter, T. (2007). Optimal step nonrigid icp algorithms for surface registration. In <italic>IEEE conference on computer vision and pattern recognition CVPR&#x02019;07</italic>, pp. 1&#x02013;8. IEEE.</mixed-citation></ref><ref id="CR5"><mixed-citation publication-type="other">Antonakos, E., Alabort-i Medina, J., Tzimiropoulos, G., &#x00026; Zafeiriou, S. (2014). Hog active appearance models. In <italic>IEEE international conference on image processing (ICIP)</italic>, pp. 224&#x02013;228. IEEE.</mixed-citation></ref><ref id="CR6"><mixed-citation publication-type="other">Belhumeur, P. N., Jacobs, D.W., Kriegman, D., &#x00026; Kumar, N. (2011). Localizing parts of faces using a consensus of exemplars. In: <italic>Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</italic>, pp. 545&#x02013;552. IEEE.</mixed-citation></ref><ref id="CR7"><mixed-citation publication-type="other">Blanz, V., &#x00026; Vetter, T. (1999). A morphable model for the synthesis of 3d faces. In: Proceedings of the 26th annual conference on Computer graphics and interactive techniques, pp. 187&#x02013;194. ACM Press/Addison-Wesley Publishing Co.</mixed-citation></ref><ref id="CR8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blanz</surname><given-names>V</given-names></name><name><surname>Vetter</surname><given-names>T</given-names></name></person-group><article-title>Face recognition based on fitting a 3d morphable model</article-title><source>Pattern Analysis and Machine Intelligence, IEEE Transactions on</source><year>2003</year><volume>25</volume><issue>9</issue><fpage>1063</fpage><lpage>1074</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2003.1227983</pub-id></element-citation></ref><ref id="CR9"><mixed-citation publication-type="other">Bolkart, T., Brunton, A., Salazar, A., &#x00026; Wuhrer, S. (2013). Website of statistical 3d shape models of human faces. <ext-link ext-link-type="uri" xlink:href="http://statistical-face-models.mmci.uni-saarland.de/">http://statistical-face-models.mmci.uni-saarland.de/</ext-link>.</mixed-citation></ref><ref id="CR10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bolkart</surname><given-names>T</given-names></name><name><surname>Wuhrer</surname><given-names>S</given-names></name></person-group><article-title>3D faces in motion: Fully automatic registration and statistical analysis</article-title><source>Computer Vision and Image Understanding</source><year>2015</year><volume>131</volume><fpage>100</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1016/j.cviu.2014.06.013</pub-id></element-citation></ref><ref id="CR11"><mixed-citation publication-type="other">Bolkart, T., &#x00026; Wuhrer, S. (2015). A groupwise multilinear correspondence optimization for 3d faces. In: <italic>IEEE International Conference on Computer Vision (ICCV)</italic>.</mixed-citation></ref><ref id="CR12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bookstein</surname><given-names>FL</given-names></name></person-group><article-title>Principal warps: Thin-plate splines and the decomposition of deformations</article-title><source>IEEE Transactions on pattern analysis and machine intelligence</source><year>1989</year><volume>11</volume><issue>6</issue><fpage>567</fpage><lpage>585</lpage><pub-id pub-id-type="doi">10.1109/34.24792</pub-id></element-citation></ref><ref id="CR13"><mixed-citation publication-type="other">Booth, J., &#x00026; Zafeiriou, S. (2014). Optimal uv spaces for facial morphable model construction. In: <italic>Image Processing (ICIP), 2014 IEEE International Conference on</italic>, pp. 4672&#x02013;4676. IEEE.</mixed-citation></ref><ref id="CR14"><mixed-citation publication-type="other">Brunton, A., &#x00026; Bolkart, T., &#x00026; Wuhrer, S. (2014). Multilinear wavelets: A statistical shape space for human faces. In: <italic>European Conference on Computer Vision (ECCV)</italic>, pp. 297&#x02013;312. Springer.</mixed-citation></ref><ref id="CR15"><mixed-citation publication-type="other">Brunton, A., Lang, J., Dubois, E., &#x00026; Shu, C. (2011). Wavelet model-based stereo for fast, robust face reconstruction. In: <italic>Canadian Conference on Computer and Robot Vision (CRV)</italic>, pp. 347&#x02013;354.</mixed-citation></ref><ref id="CR16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunton</surname><given-names>A</given-names></name><name><surname>Salazar</surname><given-names>A</given-names></name><name><surname>Bolkart</surname><given-names>T</given-names></name><name><surname>Wuhrer</surname><given-names>S</given-names></name></person-group><article-title>Review of statistical shape spaces for 3d data with comparative analysis for human faces</article-title><source>Computer Vision and Image Understanding</source><year>2014</year><volume>128</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1016/j.cviu.2014.05.005</pub-id></element-citation></ref><ref id="CR17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cootes</surname><given-names>TF</given-names></name><name><surname>Edwards</surname><given-names>GJ</given-names></name><name><surname>Taylor</surname><given-names>CJ</given-names></name><etal/></person-group><article-title>Active appearance models</article-title><source>IEEE Transactions on pattern analysis and machine intelligence</source><year>2001</year><volume>23</volume><issue>6</issue><fpage>681</fpage><lpage>685</lpage><pub-id pub-id-type="doi">10.1109/34.927467</pub-id></element-citation></ref><ref id="CR18"><mixed-citation publication-type="other">Cosker, D., Krumhuber, E., &#x00026; Hilton, A. (2011). A facs valid 3d dynamic action unit database with applications to 3d dynamic morphable facial modeling. In: <italic>Computer Vision (ICCV), 2011 IEEE International Conference on</italic>, pp. 2296&#x02013;2303. IEEE.</mixed-citation></ref><ref id="CR19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Davies</surname><given-names>R</given-names></name><name><surname>Taylor</surname><given-names>C</given-names></name><etal/></person-group><source>Statistical models of shape: Optimisation and evaluation</source><year>2008</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name></element-citation></ref><ref id="CR20"><mixed-citation publication-type="other">Deng, J., Dong, W., Socher, R., Li, L. J., Li, K., &#x00026; Fei-Fei, L. (2009). Imagenet: A large-scale hierarchical image database. In: <italic>Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on</italic>, pp. 248&#x02013;255. IEEE.</mixed-citation></ref><ref id="CR21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duan</surname><given-names>F</given-names></name><name><surname>Huang</surname><given-names>D</given-names></name><name><surname>Tian</surname><given-names>Y</given-names></name><name><surname>Lu</surname><given-names>K</given-names></name><name><surname>Wu</surname><given-names>Z</given-names></name><name><surname>Zhou</surname><given-names>M</given-names></name></person-group><article-title>3d face reconstruction from skull by regression modeling in shape parameter spaces</article-title><source>Neurocomputing</source><year>2015</year><volume>151</volume><fpage>674</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2014.04.089</pub-id></element-citation></ref><ref id="CR22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Everingham</surname><given-names>M</given-names></name><name><surname>Van Gool</surname><given-names>L</given-names></name><name><surname>Williams</surname><given-names>CK</given-names></name><name><surname>Winn</surname><given-names>J</given-names></name><name><surname>Zisserman</surname><given-names>A</given-names></name></person-group><article-title>The pascal visual object classes (voc) challenge</article-title><source>International journal of computer vision</source><year>2010</year><volume>88</volume><issue>2</issue><fpage>303</fpage><lpage>338</lpage><pub-id pub-id-type="doi">10.1007/s11263-009-0275-4</pub-id></element-citation></ref><ref id="CR23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hammond</surname><given-names>P</given-names></name><name><surname>Suttie</surname><given-names>M</given-names></name></person-group><article-title>Large-scale objective phenotyping of 3d facial morphology</article-title><source>Human mutation</source><year>2012</year><volume>33</volume><issue>5</issue><fpage>817</fpage><lpage>825</lpage><pub-id pub-id-type="doi">10.1002/humu.22054</pub-id><pub-id pub-id-type="pmid">22434506</pub-id></element-citation></ref><ref id="CR24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heo</surname><given-names>J</given-names></name><name><surname>Savvides</surname><given-names>M</given-names></name></person-group><article-title>Gender and ethnicity specific generic elastic models from a single 2d image for novel 2d pose face synthesis and recognition</article-title><source>Pattern Analysis and Machine Intelligence, IEEE Transactions on</source><year>2012</year><volume>34</volume><issue>12</issue><fpage>2341</fpage><lpage>2350</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2011.275</pub-id></element-citation></ref><ref id="CR25"><mixed-citation publication-type="other">Huber, P., Hu, G., Tena, R., Mortazavian, P., Koppen, W. P., Christmas, W., R&#x000e4;tsch, M., &#x00026; Kittler, J. (2016). A multiresolution 3d morphable face model and fitting framework. In: <italic>Proceedings of the 11th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications</italic>.</mixed-citation></ref><ref id="CR26"><mixed-citation publication-type="other">Jain, V., &#x00026; Learned-Miller, E. G. (2010). Fddb: A benchmark for face detection in unconstrained settings. <italic>UMass Amherst Technical Report</italic>.</mixed-citation></ref><ref id="CR27"><mixed-citation publication-type="other">Kemelmacher-Shlizerman, I. (2013). Internet based morphable model. In: <italic>2013 IEEE international conference on computer vision</italic> (<italic>ICCV</italic>), pp. 3256&#x02013;3263. IEEE.</mixed-citation></ref><ref id="CR28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>DE</given-names></name></person-group><article-title>Dlib-ml: A machine learning toolkit</article-title><source>Journal of Machine Learning Research</source><year>2009</year><volume>10</volume><fpage>1755</fpage><lpage>1758</lpage></element-citation></ref><ref id="CR29"><mixed-citation publication-type="other">Patel, A., &#x00026; Smith, W. A. (2009). 3d morphable face models revisited. In <italic>2009 IEEE conference on computer vision and pattern recognition, CVPR</italic>, pp. 1327&#x02013;1334. IEEE.</mixed-citation></ref><ref id="CR30"><mixed-citation publication-type="other">Paysan, P., Knothe, R., Amberg, B., Romdhani, S., &#x00026; Vetter, T. (2009). A 3D face model for pose and illumination invariant face recognition. In <italic>Sixth IEEE international conference on advanced video and signal based surveillance, AVSS&#x02019;09</italic>, pp. 296&#x02013;301. IEEE.</mixed-citation></ref><ref id="CR31"><mixed-citation publication-type="other">Paysan, P., Knothe, R., Amberg, B., Romdhani, S., &#x00026; Vetter, T. (2009). Website of basel face model. <ext-link ext-link-type="uri" xlink:href="http://faces.cs.unibas.ch/bfm/">http://faces.cs.unibas.ch/bfm/</ext-link>.</mixed-citation></ref><ref id="CR32"><mixed-citation publication-type="other">Paysan, P., L&#x000fc;thi, M., Albrecht, T., Lerch, A., Amberg, B., Santini, F., &#x00026; Vetter, T. (2009). Face reconstruction from skull shapes and physical attributes. In <italic>DAGM-symposium</italic>, pp. 232&#x02013;241. Springer.</mixed-citation></ref><ref id="CR33"><mixed-citation publication-type="other">Sagonas, C., Tzimiropoulos, G., Zafeiriou, S., &#x00026; Pantic, M. (2013). 300 faces in-the-wild challenge: The first facial landmark localization challenge. In <italic>2013 IEEE international conference on computer vision workshops (ICCVW)</italic>, pp. 397&#x02013;403. IEEE.</mixed-citation></ref><ref id="CR34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salazar</surname><given-names>A</given-names></name><name><surname>Wuhrer</surname><given-names>S</given-names></name><name><surname>Shu</surname><given-names>C</given-names></name><name><surname>Prieto</surname><given-names>F</given-names></name></person-group><article-title>Fully automatic expression-invariant face correspondence</article-title><source>Machine Vision and Applications</source><year>2014</year><volume>25</volume><issue>4</issue><fpage>859</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1007/s00138-013-0579-9</pub-id></element-citation></ref><ref id="CR35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staal</surname><given-names>FC</given-names></name><name><surname>Ponniah</surname><given-names>AJ</given-names></name><name><surname>Angullia</surname><given-names>F</given-names></name><name><surname>Ruff</surname><given-names>C</given-names></name><name><surname>Koudstaal</surname><given-names>MJ</given-names></name><name><surname>Dunaway</surname><given-names>D</given-names></name></person-group><article-title>Describing Crouzon and Pfeiffer syndrome based on principal component analysis</article-title><source>Journal of Cranio-Maxillofacial Surgery</source><year>2015</year><volume>43</volume><issue>4</issue><fpage>528</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1016/j.jcms.2015.02.005</pub-id><pub-id pub-id-type="pmid">25792443</pub-id></element-citation></ref><ref id="CR36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toderici</surname><given-names>G</given-names></name><name><surname>Omalley</surname><given-names>SM</given-names></name><name><surname>Passalis</surname><given-names>G</given-names></name><name><surname>Theoharis</surname><given-names>T</given-names></name><name><surname>Kakadiaris</surname><given-names>IA</given-names></name></person-group><article-title>Ethnicity-and gender-based subject retrieval using 3-D face-recognition techniques</article-title><source>International Journal of Computer Vision</source><year>2010</year><volume>89</volume><issue>2&#x02013;3</issue><fpage>382</fpage><lpage>391</lpage><pub-id pub-id-type="doi">10.1007/s11263-009-0300-7</pub-id></element-citation></ref><ref id="CR37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van der Maaten</surname><given-names>L</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title>Visualizing data using t-SNE</article-title><source>Journal of Machine Learning Research</source><year>2008</year><volume>9</volume><issue>2579&#x02013;2605</issue><fpage>85</fpage></element-citation></ref><ref id="CR38"><mixed-citation publication-type="other">Vlasic, D., Brand, M., Pfister, H., &#x00026; Popovi&#x00107;, J. (2005). Face transfer with multilinear models. In <italic>ACM transactions on graphics</italic> (<italic>TOG</italic>) (Vol. <italic>24</italic>, pp. 426&#x02013;433). ACM.</mixed-citation></ref><ref id="CR39"><mixed-citation publication-type="other">Wedel, A., Pock, T., Zach, C., Bischof, H., &#x00026; Cremers, D. (2009). An improved algorithm for TV-L1 optical flow. In <italic>Statistical and geometrical approaches to visual motion analysis. Lecture Notes in Computer Science</italic> (pp. 23&#x02013;45). Berlin: Springer.</mixed-citation></ref><ref id="CR40"><mixed-citation publication-type="other">Zulqarnain Gilani, S., Shafait, F., &#x00026; Mian, A. (2015). Shape-based automatic detection of a large number of 3D facial landmarks. In <italic>Proceedings of the IEEE conference on computer vision and pattern recognition</italic>, pp. 4639&#x02013;4648.</mixed-citation></ref></ref-list></back></article>