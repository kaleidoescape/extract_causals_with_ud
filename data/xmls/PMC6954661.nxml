<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-title-group><journal-title>Bioinformatics</journal-title></journal-title-group><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1367-4811</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">31116391</article-id><article-id pub-id-type="pmc">6954661</article-id><article-id pub-id-type="doi">10.1093/bioinformatics/btz421</article-id><article-id pub-id-type="publisher-id">btz421</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Papers</subject><subj-group subj-group-type="category-toc-heading"><subject>Data and Text Mining</subject></subj-group></subj-group></article-categories><title-group><article-title>Improving data splitting for classification applications in spectrochemical analyses employing a random-mutation Kennard-Stone algorithm approach</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-2573-787X</contrib-id><name><surname>Morais</surname><given-names>Camilo L M</given-names></name><xref ref-type="corresp" rid="btz421-cor1"/><xref ref-type="aff" rid="btz421-aff1">1</xref><!--<email>cdlmedeiros-de-morai@uclan.ac.uk</email>--></contrib><contrib contrib-type="author"><name><surname>Santos</surname><given-names>Marfran C D</given-names></name><xref ref-type="aff" rid="btz421-aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Lima</surname><given-names>K&#x000e1;ssio M G</given-names></name><xref ref-type="aff" rid="btz421-aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Martin</surname><given-names>Francis L</given-names></name><xref ref-type="corresp" rid="btz421-cor1"/><xref ref-type="aff" rid="btz421-aff1">1</xref><!--<email>flmartin@uclan.ac.uk</email>--></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Wren</surname><given-names>Jonathan</given-names></name><role>Associate Editor</role></contrib></contrib-group><aff id="btz421-aff1"><label>1</label>
<institution>School of Pharmacy and Biomedical Sciences, University of Central Lancashire</institution>, Preston PR1 2HE, <country country="GB">UK</country></aff><aff id="btz421-aff2"><label>2</label>
<institution>Institute of Chemistry, Biological Chemistry and Chemometrics, Federal University of Rio Grande do Norte</institution>, Natal 59072-970, <country country="BR">Brazil</country></aff><author-notes><corresp id="btz421-cor1">To whom correspondence should be addressed. E-mail: <email>cdlmedeiros-de-morai@uclan.ac.uk</email> or <email>flmartin@uclan.ac.uk</email></corresp></author-notes><pub-date pub-type="ppub"><day>15</day><month>12</month><year>2019</year></pub-date><pub-date pub-type="epub" iso-8601-date="2019-05-22"><day>22</day><month>5</month><year>2019</year></pub-date><pub-date pub-type="pmc-release"><day>22</day><month>5</month><year>2019</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. --><volume>35</volume><issue>24</issue><fpage>5257</fpage><lpage>5263</lpage><history><date date-type="received"><day>25</day><month>1</month><year>2019</year></date><date date-type="rev-recd"><day>01</day><month>5</month><year>2019</year></date><date date-type="accepted"><day>15</day><month>5</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2019. Published by Oxford University Press.</copyright-statement><copyright-year>2019</copyright-year><license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="btz421.pdf"/><abstract><title>Abstract</title><sec id="s1"><title>Motivation</title><p>Data splitting is a fundamental step for building classification models with spectral data, especially in biomedical applications. This approach is performed following pre-processing and prior to model construction, and consists of dividing the samples into at least training and test sets; herein, the training set is used for model construction and the test set for model validation. Some of the most-used methodologies for data splitting are the random selection (RS) and the Kennard-Stone (KS) algorithms; here, the former works based on a random splitting process and the latter is based on the calculation of the Euclidian distance between the samples. We propose an algorithm called the Morais-Lima-Martin (MLM) algorithm, as an alternative method to improve data splitting in classification models. MLM is a modification of KS algorithm by adding a random-mutation factor.</p></sec><sec id="s2"><title>Results</title><p>RS, KS and MLM performance are compared in simulated and six real-world biospectroscopic applications using principal component analysis linear discriminant analysis (PCA-LDA). MLM generated a better predictive performance in comparison with RS and KS algorithms, in particular regarding sensitivity and specificity values. Classification is found to be more well-equilibrated using MLM. RS showed the poorest predictive response, followed by KS which showed good accuracy towards prediction, but relatively unbalanced sensitivities and specificities. These findings demonstrate the potential of this new MLM algorithm as a sample selection method for classification applications in comparison with other regular methods often applied in this type of data.</p></sec><sec id="s3"><title>Availability and implementation</title><p>MLM algorithm is freely available for MATLAB at <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.7393517.v1">https://doi.org/10.6084/m9.figshare.7393517.v1</ext-link>.</p></sec></abstract><funding-group><award-group award-type="grant"><funding-source><named-content content-type="funder-name">Coordena&#x000e7;&#x000e3;o de Aperfei&#x000e7;oamento de Pessoal de N&#x000ed;vel Superior</named-content><named-content content-type="funder-identifier">10.13039/501100002322</named-content></funding-source><award-id>88881.128982/2016-01</award-id></award-group><award-group award-type="grant"><funding-source><named-content content-type="funder-name">Biotechnology and Biological Sciences Research Council</named-content><named-content content-type="funder-identifier">10.13039/501100000268</named-content></funding-source><award-id>BB/D010055/1</award-id></award-group><award-group award-type="grant"><funding-source><named-content content-type="funder-name">Engineering and Physical Sciences Research Council</named-content><named-content content-type="funder-identifier">10.13039/501100000266</named-content></funding-source><award-id>GR/S75918/01</award-id><award-id>EP/K023349/1</award-id></award-group></funding-group><counts><page-count count="7"/></counts></article-meta></front><body><sec><title>1 Introduction</title><p>Data splitting is a process used to separate a given dataset into at least two subsets called &#x02018;training&#x02019; (or &#x02018;calibration&#x02019;) and &#x02018;test&#x02019; (or &#x02018;prediction&#x02019;). This step is usually implemented after pre-processing, when the samples&#x02019; spectra have been corrected for noise or undesired variability. These subsets are used towards constructing chemometric models for quantification or classification applications. In quantification, calibration models are built to assign a concentration or discrete value to a sample based on its spectral signature, whilst in classification applications, samples or experimental observations are assigned to &#x02018;classes&#x02019; based on their spectrochemical signature. This is made by using chemometric methods such as principal component analysis linear discriminant analysis (PCA-LDA) (<xref rid="btz421-B11" ref-type="bibr">Morais and Lima, 2018</xref>), partial least squares discriminant analysis (PLS-DA) (<xref rid="btz421-B2" ref-type="bibr">Brereton and Lloyd, 2014</xref>), or support vector machines (SVM) (<xref rid="btz421-B4" ref-type="bibr">Cortes and Vapnik, 1995</xref>). Sometimes, especially for large datasets, an extra subset called &#x02018;validation&#x02019; is also obtained, containing measurements observations used for optimizing factors in the chemometric model, such as the number of principal component (PCs) in PCA-LDA, latent variables in PLS-DA and kernel parameters in SVM. When the validation set is not present, cross-validation is applied. In this case, samples from the training set are used in an iterative validation process for optimizing these models parameters. This is made by firstly removing a certain number of samples from the training set and then building the classification model with the remaining samples, where the removed samples are predicted as a temporary validation set. This is performed for a certain number of repetitions until all training samples are excluded once from the training set and predicted as a temporary validation set. One of the most popular cross-validation methods is the leave-one-out cross-validation, where only one sample is removed from the training set per each iteration. A misclassification error is then calculated for this temporary validation set, where different models parameters, such as different number of factors or principal components, are tested. The training model with the lowest cross-validation error is then chosen as final, where the classification parameters that led to the lowest cross-validation error value are selected. The samples primarily excluded from modelling (test set) are used for final model evaluation, since they are considered as being external to the model (blind). In this case, one simulates how the model would behave in the presence of new observations, though they are often measured in the same experiment with the training samples.</p><p>To avoid the presence of bias introduced by manual data splitting, there are a number of computational methods that can be used for sample selection, such as based on leverage (<xref rid="btz421-B20" ref-type="bibr">Wang <italic>et al.</italic>, 1991</xref>), random selection (RS) or Kennard-Stone (KS) algorithm (<xref rid="btz421-B8" ref-type="bibr">Kennard and Stone, 1969</xref>). RS and KS are the most used methods for sample selection; the former due to its simplicity and the latter due to its adaptation to analytical chemistry applications, since it allows a training model covering most sources of variations within the dataset, ensuring the training model is more representative of the whole dataset. Currently, the original KS paper (<xref rid="btz421-B8" ref-type="bibr">Kennard and Stone, 1969</xref>) has &#x0003e;1000 citations, being the method of choice in many classification applications.</p><p>Although including as much variability as possible within the training model provides a good predictive performance, sometimes random phenomena might occur with new samples in a test set, in particular when samples come from complex matrices. An example of this is biological-derived samples. Biological samples can be affected by a series of factors that are difficult to include in relatively small datasets. For example, in clinical applications the spectrochemical response of a &#x02018;healthy&#x02019; and &#x02018;disease&#x02019; sample may vary according to changes in diet and lifestyle (<xref rid="btz421-B9" ref-type="bibr">Lindon <italic>et al.</italic>, 2017</xref>). The same applies for bacteria or viruses extracted from certain media, since environmental variations may also change their spectral signature. Additionally, random factors such as genetic mutations might affect the predictive performance of a classification model for biological samples in the future. These phenomena add a degree of &#x02018;randomness&#x02019; in the predictive behaviour of a classifier, since more extrapolations might be needed to address all of these issues. Thus, having in mind the inclusion of as much representativeness as possible in the training model but with a small degree of randomness, we propose a new algorithm based on a random-mutation Kennard-Stone approach; we call this the Morais-Lima-Martin (MLM) algorithm.</p><p>Towards comparison of the predictive response of MLM with RS and KS, we tested classification models on six real-world spectrochemical datasets using PCA-LDA, where the predictive performance in terms of accuracy, sensitivity and specificity were evaluated. In addition, simulations with normally distributed randomly data were performed to evidence the performance of the MLM algorithm in comparison with the RS and KS method.</p></sec><sec><title>2 Materials and methods</title><p>
<bold>Datasets.</bold> Six real-world datasets were used towards comparing the classification performance of RS, KS and MLM algorithms. Dataset 1 contains 280 infrared (IR) spectra of two Cryptococcus fungi specimens acquired via attenuated total reflection Fourier-transform infrared (ATR-FTIR) spectroscopy. This dataset is publically available at <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.7427927.v1">https://doi.org/10.6084/m9.figshare.7427927.v1</ext-link>. Class 1 is composed of 140 spectra of <italic>Cryptococcus neoformans</italic> samples and class 2 of 140 spectra of <italic>Cryptococcus gattii</italic> samples. Spectra were acquired in the 400&#x02013;4000&#x02009;cm<sup>&#x02212;1</sup> spectral range with a resolution of 4&#x02009;cm<sup>&#x02212;1</sup> and 16 co-added scans using a Bruker VERTEX 70 FTIR spectrometer (Bruker Optics, Ltd., UK). The spectral data were pre-processed by excising the biofingerprint region (900&#x02013;1800&#x02009;cm<sup>&#x02212;1</sup>), which was followed by automatic weighted least squares (AWLS) baseline correction and normalization to the Amide I peak (1650&#x02009;cm<sup>&#x02212;1</sup>). More details regarding this dataset can be found in literature (<xref rid="btz421-B5" ref-type="bibr">Costa <italic>et al.</italic>, 2016</xref>; <xref rid="btz421-B12" ref-type="bibr">Morais <italic>et al.</italic>, 2017</xref>).</p><p>Dataset 2 contains 240 IR spectra derived from formalin-fixed paraffin-embedded brain tissues separated into two classes. Class 1 contains 140 spectra from normal brain tissue, and class 2 contains 100 spectra from glioblastoma brain tissue. Spectra were collected via ATR-FTIR spectroscopy using a Bruker VECTOR 27 FTIR spectrometer with a Helios ATR attachment (Bruker Optics, Ltd., UK). The raw spectra, acquired in the 400&#x02013;4000&#x02009;cm<sup>&#x02212;1</sup> spectral range with a resolution of 8&#x02009;cm<sup>&#x02212;1</sup> and 32 co-added scans, were pre-processed by excising the biofingerprint region (900&#x02013;1800&#x02009;cm<sup>&#x02212;1</sup>), which was followed by rubberband baseline correction and normalization to the Amide I peak (1650&#x02009;cm<sup>&#x02212;1</sup>). This dataset is publicly available as part of the IRootLab toolbox (<ext-link ext-link-type="uri" xlink:href="http://trevisanj.github.io/irootlab/">http://trevisanj.github.io/irootlab/</ext-link>) (<xref rid="btz421-B19" ref-type="bibr">Trevisan <italic>et al.</italic>, 2013</xref>), and more information about it can be found in <xref rid="btz421-B7" ref-type="bibr">Gajjar <italic>et al.</italic> (2012)</xref>.</p><p>Dataset 3 contains 183 IR spectra distributed into 3 classes. Class 1 contains 59 spectra of Syrian hamster embryo (SHE) cells treated with benzo[a]pyrene (B[a]P), class 2 contains 62 spectra of SHE cells treated with 3-methylcholanthrene (3-MCA) and class 3 contains 62 spectra of SHE cells treated with anthracene (Ant). Spectra were acquired in the 400&#x02013;4000&#x02009;cm<sup>&#x02212;1</sup> spectral range with a resolution of 8&#x02009;cm<sup>&#x02212;1</sup> by using a Bruker TENSOR 27 spectrometer with a Helios ATR attachment (Bruker Optics, Ltd., UK). Pre-processing was performed by excising the biofingerprint region (900&#x02013;1800&#x02009;cm<sup>&#x02212;1</sup>), which was followed by rubberband baseline correction and normalization to the Amide I peak (1650&#x02009;cm<sup>&#x02212;1</sup>). This dataset is publicly available as part of the IRootLab toolbox (<ext-link ext-link-type="uri" xlink:href="http://trevisanj.github.io/irootlab/">http://trevisanj.github.io/irootlab/</ext-link>) (<xref rid="btz421-B19" ref-type="bibr">Trevisan <italic>et al.</italic>, 2013</xref>), and further information can be found in <xref rid="btz421-B18" ref-type="bibr">Trevisan <italic>et al.</italic> (2010)</xref>.</p><p>Dataset 4 contains 270 IR spectra from blood samples divided into four classes. Class 1 is composed of 90 IR spectra of control samples, class 2 contains 88 spectra from patients with Dengue, class 3 contains 66 spectra from patients with Zika and class 4 contains 26 spectra from patients with Chikungunya. This dataset is publically available at <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.7427933.v1">https://doi.org/10.6084/m9.figshare.7427933.v1</ext-link>. Spectra were collected in ATR mode by using a Bruker VERTEX 70 FTIR spectrometer (Bruker Optics, Ltd., UK). Acquisition was performed in the 400&#x02013;4000&#x02009;cm<sup>&#x02212;1</sup> spectral range with a resolution of 4&#x02009;cm<sup>&#x02212;1</sup> and 16 co-added scans. Pre-processing was performed by excising the biofingerprint region (900&#x02013;1800&#x02009;cm<sup>&#x02212;1</sup>), which was followed by Savitzky-Golay smoothing (window of 7 points) (<xref rid="btz421-B17" ref-type="bibr">Savitzky and Golay, 1964</xref>), AWLS baseline correction and normalization to the Amide I peak (1650&#x02009;cm<sup>&#x02212;1</sup>). Further details about this dataset can be found in <xref rid="btz421-B16" ref-type="bibr">Santos <italic>et al.</italic> (2018)</xref>.</p><p>Dataset 5 contains 351 Raman spectra of blood plasma divided into two classes: 162 spectra of healthy individuals (class 1), and 189 spectra of ovarian cancer patients (class 2). This dataset is publicly available at <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.6744206.v1">https://doi.org/10.6084/m9.figshare.6744206.v1</ext-link>. Raman spectra were collected using an InVia Renishaw Raman spectrometer coupled with a charge-coupled device (CCD) detector and Leica microscope, with 5% laser power (785&#x02009;nm), 5x objective magnification, 10&#x02009;s exposure time and 2 accumulations in the spectral range of 400&#x02013;2000&#x02009;cm<sup>&#x02212;1</sup>. The spectral data were pre-processed by Savitzky-Golay smoothing (window of 15 points), AWLS baseline correction and vector normalization. Further details about this dataset can be found in <xref rid="btz421-B15" ref-type="bibr">Paraskevaidi <italic>et al.</italic> (2018)</xref>.</p><p>Dataset 6 contains 322 surface-enhanced Raman spectroscopy (SERS) spectra of blood plasma also divided into two classes: 133 spectra of healthy individuals (class 1), and 189 spectra of ovarian cancer patients (class 2). This dataset is publicly available at <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.6744206.v1">https://doi.org/10.6084/m9.figshare.6744206.v1</ext-link>. SERS spectra were collected using the same settings for dataset 5 but, in this case, silver nanoparticles were mixed with the biofluid before spectral acquisition. The spectral pre-processing was performed using Savitzky-Golay smoothing (window of 15 points), AWLS baseline correction and vector normalization. Further details about this dataset can be found in <xref rid="btz421-B15" ref-type="bibr">Paraskevaidi <italic>et al.</italic> (2018)</xref>.</p><p>Simulations were also performed with simulated data. This data were generated for each simulation (1000 simulations) based on a normally distributed random matrix with size of 100&#x02009;&#x000d7;&#x02009;1000 for class 1, and 100&#x02009;&#x000d7;&#x02009;1000 for class 2 (100 observations, 1000 variables per observation). The matrix values ranged randomly from -10 to 10 units. A shift of 5 units was randomly added to class 2 to create a difference between the classes. The codes to produce class 1 and class 2 in MATLAB are &#x02018;class_1&#x02009;=&#x02009;randn(100, 1000).*randn(100, 1000);&#x02019; and &#x02018;class_2 = (randn(100, 1000)+5).*randn(100, 1000);&#x02019;. Class 1 and class 2 were generated for each simulation (1000 times), where all algorithms (RS, KS and MLM) were independently applied per each simulation.</p><p>
<bold>Software.</bold> Data analysis was performed within the MATLAB R2014b (MathWorks, Inc., USA) environment. Pre-processing was performed using PLS Toolbox 7.9.3. (Eigenvector Research, Inc., USA) and classification was performed using the Classification Toolbox for MATLAB (<ext-link ext-link-type="uri" xlink:href="http://www.michem.unimib.it/">http://www.michem.unimib.it/</ext-link>) (<xref rid="btz421-B1" ref-type="bibr">Ballabio and Consonni, 2013</xref>). RS, KS and MLM algorithms were performed using laboratory-generated routines. MLM algorithm is public available at <ext-link ext-link-type="doi" xlink:href="10.6084/m9.figshare.7393517.v1">https://doi.org/10.6084/m9.figshare.7393517.v1</ext-link>.</p><p>
<bold>Sample selection.</bold> Samples were divided into training (70%) and test (30%) sets using, independently, the RS, KS or MLM algorithms. RS is based on a random sample selection where spectra from the original dataset are randomly assigned to training or test. KS algorithm is based on an Euclidian distance calculation, where the sample with maximum distance to all other samples are selected, then the samples which are as far away as possible from the selected samples are selected, until the selected number of samples is reached. This means that the samples are selected in such a way that they will uniformly cover the complete sample space, reducing the need for extrapolation of the remaining samples. MLM algorithm, based on a KS-based approach, applies a KS method to the data, as described before; then, a random-mutation factor is used in the KS results, where some samples from the training set are transferred to the test set, and some samples from the test set are transferred to training. Herein, the mutation factor was set at 10%. This value is inspired in the mutation probability of genetic algorithms (<xref rid="btz421-B14" ref-type="bibr">Morais <italic>et al.</italic>, 2019</xref>), where 10% is a common threshold employed to keep a balance between the degree of randomness and model convergence. MLM algorithm is visually illustrated in <xref ref-type="fig" rid="btz421-F1">Figure&#x000a0;1</xref>.
</p><fig id="btz421-F1" orientation="portrait" position="float"><label>Fig. 1.</label><caption><p>Illustration of the MLM algorithm based on a random-mutation of the Kennard-Stone (KS) method. Adapted from <xref rid="btz421-B13" ref-type="bibr">Morais <italic>et al.</italic> (2018)</xref></p></caption><graphic xlink:href="btz421f1"/></fig><p>
<bold>Classification.</bold> Classification was performed based on a PCA-LDA algorithm. For this, initially a principal component analysis (PCA) model is applied to the pre-processed data, decomposing the spectral space into a small number of PCs representing most of the original data-explained variance (<xref rid="btz421-B3" ref-type="bibr">Bro and Smilde, 2014</xref>). Each PC is composed of scores and loadings, the former representing the variance on samples direction, and the latter the variance on variables (e.g. wavenumber) direction. Then, the PCA scores are used as input for a linear discriminant analysis (LDA) classifier. LDA performs a Mahalanobis distance calculation to linearly classify the input space (PCA scores) into at least two classes (<xref rid="btz421-B6" ref-type="bibr">Dixon and Brereton, 2009</xref>; <xref rid="btz421-B11" ref-type="bibr">Morais and Lima, 2018</xref>). The LDA classification scores (<inline-formula id="IE1"><mml:math id="IM1"><mml:msub><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ik</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) can be calculated in a non-Bayesian form as (<xref rid="btz421-B6" ref-type="bibr">Dixon and Brereton, 2009</xref>; <xref rid="btz421-B11" ref-type="bibr">Morais and Lima, 2018</xref>):
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:msub><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ik</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">pooled</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula id="IE2"><mml:math id="IM2"><mml:msub><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a vector containing the input variables for sample <inline-formula id="IE3"><mml:math id="IM3"><mml:mi mathvariant="normal">i</mml:mi></mml:math></inline-formula>; <inline-formula id="IE4"><mml:math id="IM4"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the mean vector of class <inline-formula id="IE5"><mml:math id="IM5"><mml:mi mathvariant="normal">k</mml:mi></mml:math></inline-formula>; <inline-formula id="IE6"><mml:math id="IM6"><mml:msub><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">pooled</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the pooled covariance matrix between the classes; and, <inline-formula id="IE7"><mml:math id="IM7"><mml:mi mathvariant="normal">T</mml:mi></mml:math></inline-formula> represents the matrix transpose operation. Model optimization was performed using cross-validation venetian blinds with 10 splits.</p><p>The PCA-LDA classification performance was evaluated by means of accuracy, sensitivity and specificity calculations. Accuracy represents the total number of samples correctly classified considering true and false negatives; sensitivity measures the proportion of positives that are correctly identified; and, specificity measures the proportion of negatives that are correctly identified (<xref rid="btz421-B10" ref-type="bibr">Morais and Lima, 2017</xref>). These parameters are calculated as follows:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mi mathvariant="normal">Accuracy</mml:mi><mml:mi mathvariant="normal">&#x000a0;</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">%</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="normal">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">TN</mml:mi><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="normal">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">FN</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>&#x000d7;</mml:mo><mml:mn>100</mml:mn></mml:math></disp-formula><disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mi mathvariant="normal">Sensitivity</mml:mi><mml:mi mathvariant="normal">&#x000a0;</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">%</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="normal">TP</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="normal">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">FN</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>&#x000d7;</mml:mo><mml:mn>100</mml:mn></mml:math></disp-formula><disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:mi mathvariant="normal">Specificity</mml:mi><mml:mi mathvariant="normal">&#x000a0;</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">%</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="normal">TN</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="normal">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">FP</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>&#x000d7;</mml:mo><mml:mn>100</mml:mn></mml:math></disp-formula>where TP stands for true positives; TN for true negatives; FP for false positives; and, FN for false negatives.</p></sec><sec><title>3 Results</title><p>Six real-world datasets were evaluated using different data splitting techniques: RS, KS and our new MLM algorithm. These datasets are composed of IR and Raman spectra from biological-derived applications involving: IR spectra of fungi (dataset 1); IR spectra of cancer brain tissue (dataset 2); IR spectra for toxicological study (dataset 3); IR spectra of viruses (dataset 4); Raman spectra of plasma for ovarian cancer detection (dataset 5); and, SERS spectra of plasma for ovarian cancer detection (dataset 6). <xref ref-type="fig" rid="btz421-F2">Figure&#x000a0;2</xref> shows the pre-processed mean spectrum with standard deviation for each class in datasets 1&#x02013;6. The pre-processed spectra from these datasets were used as input for the sample selection techniques, where their classification performances were evaluated via the PCA-LDA algorithm.
</p><fig id="btz421-F2" orientation="portrait" position="float"><label>Fig. 2.</label><caption><p>Mean pre-processed spectrum with standard deviation (shaded) for each class in dataset 1 (<bold>a</bold>), 2 (<bold>b</bold>), 3 (<bold>c</bold>), 4 (<bold>d</bold>), 5 (<bold>e</bold>) and 6 (<bold>f</bold>)</p></caption><graphic xlink:href="btz421f2"/></fig><p>Dataset 1 is composed of 280 IR spectra for two fungi specimens groups (<italic>Cryptococcus neoformans</italic> [class 1]; <italic>Cryptococcus gattii</italic> [class 2]), each class having 170 spectra each. Both fungi classes are pathogenic agents responsible for causing Cryptococcosis in humans, differing in their epidemiology, host range, virulence, antifungal susceptibility and geographic distribution (<xref rid="btz421-B12" ref-type="bibr">Morais <italic>et al.</italic>, 2017</xref>). From a clinical point of view, Cryptococcus neoformans is a pathogen with a tendency to attack the central nervous system and its effects are mainly noted in immunosuppressed patients, whereas <italic>Cryptococcus gattii</italic> targets the lungs of immunocompetent, healthy individuals (<xref rid="btz421-B12" ref-type="bibr">Morais <italic>et al.</italic>, 2017</xref>). RS, KS and MLM were independently applied to the pre-processed spectra separating 70% of them for training and 30% for testing. Cross-validated PCA-LDA was applied for model construction using three PCs (99% cumulative explained variance) selected according to the minimum cross-validation error rate within the minimum number of PCs (<xref ref-type="fig" rid="btz421-F3">Fig.&#x000a0;3</xref>). The model fitting performance is shown in <xref rid="btz421-T1" ref-type="table">Table&#x000a0;1</xref>, where the best training (84%) and cross-validation (83%) accuracy are observed using RS algorithm. KS generates the worst fitting performance with 80% accuracy in both training and cross-validation. The MLM algorithm shows an intermediary performance with 83% and 82% accuracy in training and cross-validation, respectively.
</p><fig id="btz421-F3" orientation="portrait" position="float"><label>Fig. 3.</label><caption><p>PCA-LDA cross-validation error rate for datasets 1 (<bold>a</bold>), 2 (<bold>b</bold>), 3 (<bold>c</bold>), 4 (<bold>d</bold>), 5 (<bold>e</bold>) and 6 (<bold>f</bold>). CV: cross-validation; PCs: principal components</p></caption><graphic xlink:href="btz421f3"/></fig><table-wrap id="btz421-T1" orientation="portrait" position="float"><label>Table 1.</label><caption><p>PCA-LDA fitting accuracy for training and cross-validation (CV) varying with the sample selection method (RS: random selection; KS: Kennard-Stone; MLM: Morais-Lima-Martin) applied in datasets 1&#x02013;6</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Dataset</th><th align="left" rowspan="1" colspan="1">Sample selection method</th><th rowspan="1" colspan="1">Training accuracy (%)</th><th rowspan="1" colspan="1">CV accuracy (%)</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">RS</td><td rowspan="1" colspan="1">84</td><td rowspan="1" colspan="1">83</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">KS</td><td rowspan="1" colspan="1">80</td><td rowspan="1" colspan="1">80</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">MLM</td><td rowspan="1" colspan="1">83</td><td rowspan="1" colspan="1">82</td></tr><tr><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">RS</td><td rowspan="1" colspan="1">85</td><td rowspan="1" colspan="1">83</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">KS</td><td rowspan="1" colspan="1">81</td><td rowspan="1" colspan="1">80</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">MLM</td><td rowspan="1" colspan="1">82</td><td rowspan="1" colspan="1">77</td></tr><tr><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">RS</td><td rowspan="1" colspan="1">86</td><td rowspan="1" colspan="1">84</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">KS</td><td rowspan="1" colspan="1">83</td><td rowspan="1" colspan="1">82</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">MLM</td><td rowspan="1" colspan="1">84</td><td rowspan="1" colspan="1">80</td></tr><tr><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">RS</td><td rowspan="1" colspan="1">92</td><td rowspan="1" colspan="1">91</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">KS</td><td rowspan="1" colspan="1">90</td><td rowspan="1" colspan="1">90</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">MLM</td><td rowspan="1" colspan="1">93</td><td rowspan="1" colspan="1">90</td></tr><tr><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">RS</td><td rowspan="1" colspan="1">93</td><td rowspan="1" colspan="1">93</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">KS</td><td rowspan="1" colspan="1">89</td><td rowspan="1" colspan="1">88</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">MLM</td><td rowspan="1" colspan="1">91</td><td rowspan="1" colspan="1">88</td></tr><tr><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">RS</td><td rowspan="1" colspan="1">74</td><td rowspan="1" colspan="1">72</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">KS</td><td rowspan="1" colspan="1">75</td><td rowspan="1" colspan="1">72</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">MLM</td><td rowspan="1" colspan="1">76</td><td rowspan="1" colspan="1">75</td></tr></tbody></table></table-wrap><p>Although the best fitting accuracy, the RS-based model exhibits a very poor sensitivity, at 69%, in the test set (<xref rid="btz421-T2" ref-type="table">Table&#x000a0;2</xref>). The specificity is high (88%), but the model seems to have a poor balance in terms of sensitivity and specificity, indicating that one class is much better classified than the other. The KS-based model with the worst fitting gives the best specificity (98%), but the sensitivity remains the same. On the other hand, the MLM-based model shows the best well-balanced performance, where the specificity falls to 78%, but the sensitivity increases to 74%, indicating that both classes are well-classified, and the model is not skewed towards a good classification of just one of the classes. Overall accuracy varying with the sample selection method is depicted in <xref ref-type="fig" rid="btz421-F4">Figure&#x000a0;4</xref>, where the accuracy for dataset 1 using MLM (81%) is close to the KS algorithm (83%), which achieves the best accuracy due to the great specificity of this model. RS has the worst accuracy (79%), indicating that the performance of this method in the test set is inferior to the other algorithms that had worst fitting; thus, confirming that good fitting is not necessarily associated with good predictions.
</p><fig id="btz421-F4" orientation="portrait" position="float"><label>Fig. 4.</label><caption><p>Accuracy in the test set obtained by PCA-LDA varying with the sample selection method (RS: random selection; KS: Kennard-Stone; MLM: Morais-Lima-Martin) applied in datasets 1&#x02013;6</p></caption><graphic xlink:href="btz421f4"/></fig><table-wrap id="btz421-T2" orientation="portrait" position="float"><label>Table 2.</label><caption><p>Sensitivity and specificity for the test set obtained by PCA-LDA varying with the sample selection method (RS: random selection; KS: Kennard-Stone; MLM: Morais-Lima-Martin) applied in datasets 1&#x02013;6</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/><col valign="top" align="center" span="1"/><col valign="top" align="center" span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Dataset</th><th rowspan="1" colspan="1">Sample selection method</th><th rowspan="1" colspan="1">Sensitivity (%)</th><th rowspan="1" colspan="1">Specificity (%)</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">RS</td><td rowspan="1" colspan="1">69</td><td rowspan="1" colspan="1">88</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">KS</td><td rowspan="1" colspan="1">69</td><td rowspan="1" colspan="1">98</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">MLM</td><td rowspan="1" colspan="1">74</td><td rowspan="1" colspan="1">78</td></tr><tr><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">RS</td><td rowspan="1" colspan="1">79</td><td rowspan="1" colspan="1">63</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">KS</td><td rowspan="1" colspan="1">79</td><td rowspan="1" colspan="1">80</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">MLM</td><td rowspan="1" colspan="1">81</td><td rowspan="1" colspan="1">80</td></tr><tr><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">RS</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 1</td><td rowspan="1" colspan="1">83</td><td rowspan="1" colspan="1">87</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 2</td><td rowspan="1" colspan="1">79</td><td rowspan="1" colspan="1">89</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 3</td><td rowspan="1" colspan="1">89</td><td rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">KS</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 1</td><td rowspan="1" colspan="1">94</td><td rowspan="1" colspan="1">97</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 2</td><td rowspan="1" colspan="1">100</td><td rowspan="1" colspan="1">92</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 3</td><td rowspan="1" colspan="1">84</td><td rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">MLM</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 1</td><td rowspan="1" colspan="1">94</td><td rowspan="1" colspan="1">92</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 2</td><td rowspan="1" colspan="1">95</td><td rowspan="1" colspan="1">95</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 3</td><td rowspan="1" colspan="1">84</td><td rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">RS</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 1</td><td rowspan="1" colspan="1">96</td><td rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 2</td><td rowspan="1" colspan="1">100</td><td rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 3</td><td rowspan="1" colspan="1">85</td><td rowspan="1" colspan="1">98</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 4</td><td rowspan="1" colspan="1">88</td><td rowspan="1" colspan="1">95</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">KS</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 1</td><td rowspan="1" colspan="1">100</td><td rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 2</td><td rowspan="1" colspan="1">100</td><td rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 3</td><td rowspan="1" colspan="1">90</td><td rowspan="1" colspan="1">98</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 4</td><td rowspan="1" colspan="1">88</td><td rowspan="1" colspan="1">97</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">MLM</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 1</td><td rowspan="1" colspan="1">100</td><td rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 2</td><td rowspan="1" colspan="1">100</td><td rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 3</td><td rowspan="1" colspan="1">95</td><td rowspan="1" colspan="1">98</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Class 4</td><td rowspan="1" colspan="1">88</td><td rowspan="1" colspan="1">99</td></tr><tr><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">RS</td><td rowspan="1" colspan="1">94</td><td rowspan="1" colspan="1">88</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">KS</td><td rowspan="1" colspan="1">94</td><td rowspan="1" colspan="1">95</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">MLM</td><td rowspan="1" colspan="1">94</td><td rowspan="1" colspan="1">91</td></tr><tr><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">RS</td><td rowspan="1" colspan="1">70</td><td rowspan="1" colspan="1">70</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">KS</td><td rowspan="1" colspan="1">72</td><td rowspan="1" colspan="1">84</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">MLM</td><td rowspan="1" colspan="1">72</td><td rowspan="1" colspan="1">89</td></tr></tbody></table></table-wrap><p>Dataset 2 is composed of 140 spectra of normal (class 1) and 100 spectra of gliobastoma (class 2) brain tissue samples. Gliobastoma is the brain cancer type with the poorest survival rate (<xref rid="btz421-B7" ref-type="bibr">Gajjar <italic>et al.</italic>, 2012</xref>). Reference methods for detecting these types of cancer, such as immunohistochemical detection of isocitrate dehydrogenase (IDH), suffers from some limitations, especially their subjective nature (<xref rid="btz421-B7" ref-type="bibr">Gajjar <italic>et al.</italic>, 2012</xref>). The use of IR spectroscopy has the potential to aid tumour differentiation based on a non-analyst dependent, fast and non-destructive methodology. In this dataset, both tumour types are differentiated based on their IR spectrochemical signature. The pre-processed IR spectra for dataset 2 are show in <xref ref-type="fig" rid="btz421-F2">Figure&#x000a0;2b</xref>. As before, RS, KS and MLM algorithms were applied to this dataset separating the data into training and test sets. PCA-LDA was applied as a classification method using 9 PCs (<xref ref-type="fig" rid="btz421-F3">Fig.&#x000a0;3b</xref>), accounting to 99% of cumulative explained variance. The training performance of this model in dataset 2 is shown in <xref rid="btz421-T1" ref-type="table">Table&#x000a0;1</xref>, where the RS algorithm presents the best fitting (training and cross-validation accuracy of 85 and 83%, respectively). The other algorithms (KS and MLM) have the lowest fitting performance with accuracies around 80%. Nevertheless, as before, the situation is reversed in the test set, where the RS algorithm has the worst sensitivity and specificity values (<xref rid="btz421-T2" ref-type="table">Table&#x000a0;2</xref>). In the test set, the best sensitivity and specificity values are obtained using MLM, with a slightly superior performance than KS algorithm. The overall model accuracy also is better for MLM (<xref ref-type="fig" rid="btz421-F4">Fig.&#x000a0;4</xref>), where the accuracy in the test set is observed at 81% using MLM, at 79% using KS and at 72% using RS. This confirms MLM to be the method of choice for this dataset.</p><p>Dataset 3 consists of spectra derived from SHE cells treated with one of three agents: B[a]P, class 1; 3-MCA, class 2; or, Anthracene, class 3. Class 1 is composed of 59 IR spectra, and both class 2 and 3 of 62 spectra. Pre-processed spectra for this dataset are shown in <xref ref-type="fig" rid="btz421-F2">Figure&#x000a0;2c</xref>. PCA-LDA model was built using 10 PCs (99% cumulative explained variance) (<xref ref-type="fig" rid="btz421-F3">Fig.&#x000a0;3c</xref>). The best training performance was found using RS algorithm, followed by MLM and KS, which had similar fitting (<xref rid="btz421-T1" ref-type="table">Table&#x000a0;1</xref>). KS and MLM algorithms exhibit similar performance in the test set, with sensitivities and specificities for class 1 and 2&#x02009;&#x0003e;&#x02009;90%. For class 3, both algorithms show 100% specificity and 84% sensitivity. On the other hand, the RS algorithm presents a slightly better sensitivity for class 3 (89%), but lower sensitivity and specificities for the other classes (&#x0003c;90%). Accuracy in the test set was found to be superior for KS (93%), followed by MLM (91%) and RS (84%) (<xref ref-type="fig" rid="btz421-F4">Fig.&#x000a0;4</xref>). Similarly to dataset 1, KS has a slightly better performance than MLM; however, the figures of merit for MLM are more well-balanced, where extreme situations in KS (100% sensitivity or specificity) are not found, but more coherent values between these two metrics (i.e. sensitivity and specificity values closer to each other).</p><p>Dataset 4 is composed of control and typical virus-infected blood samples. Class 1 contains 90 IR spectra of control samples; class 2 contains 88 spectra of blood from patients with Dengue; class 3 contains 66 spectra of blood from patients with the Zika virus; and, class 4 contains 26 spectra of blood from patients with Chikungunya. These viruses are transmitted by mosquitos of genus Aedes, having many chemical similarities (e.g. Dengue and Zika are from the same family, Flaviviridae), in particular in their surface proteins (<xref rid="btz421-B16" ref-type="bibr">Santos <italic>et al.</italic>, 2018</xref>). Fast clinical diagnosis using reference methodologies is difficult; however, IR spectroscopy can be used as an alternative tool for viral infection differentiation (<xref rid="btz421-B16" ref-type="bibr">Santos <italic>et al.</italic>, 2018</xref>). Pre-processed spectra for dataset 4 are shown in <xref ref-type="fig" rid="btz421-F2">Figure&#x000a0;2d</xref>. PCA-LDA model was built using 6 PCs (<xref ref-type="fig" rid="btz421-F3">Fig.&#x000a0;3d</xref>), accounting for 97% of cumulative explained variance using RS and MLM sample selection methods, and 96% using KS sample selection method. RS and MLM exhibit similar fitting performance, with accuracies &#x0003e;90% in the training set. KS shows a slightly lower training performance with an accuracy of 90% in the training set (<xref rid="btz421-T1" ref-type="table">Table&#x000a0;1</xref>). In the test set, MLM algorithm shows the best sensitivity and specificity values (<xref rid="btz421-T2" ref-type="table">Table&#x000a0;2</xref>), followed by KS and RS. The overall accuracy in the test set also follows this trend, where the MLM algorithm has an accuracy of 98%, followed by KS (96%) and RS (94%) (<xref ref-type="fig" rid="btz421-F4">Fig.&#x000a0;4</xref>).</p><p>Both datasets 5 and 6 are for diagnosis of ovarian cancer based respectively on the Raman and SERS spectra of blood plasma. These techniques have great potential towards liquid biopsy diagnosis of ovarian cancer in a minimally-invasive, rapid and objective fashion (<xref rid="btz421-B15" ref-type="bibr">Paraskevaidi <italic>et al.</italic>, 2018</xref>). Both datasets contain 2 classes, where dataset 5 is divided into 162 Raman spectra for class 1 (healthy controls) and 189 Raman spectra for class 2 (ovarian cancer); and dataset 6 is divided into 133 SERS spectra for class 1 (healthy controls) and 189 SERS spectra for class 2 (ovarian cancer). These spectra are shown in <xref ref-type="fig" rid="btz421-F2">Figure&#x000a0;2e and f</xref>, respectively. Model construction was performed with PCA-LDA using 14 PCs (<xref ref-type="fig" rid="btz421-F3">Fig.&#x000a0;3e and f</xref>, respectively), which accounted to 98% of cumulative variance in dataset 5 and 94% of cumulative variance in dataset 6. Training performance was superior using RS in dataset 5 and MLM in dataset 6 (<xref rid="btz421-T1" ref-type="table">Table&#x000a0;1</xref>), while for prediction of the external test set, the MLM algorithm showed similar classification performance in comparison with KS for dataset 5 and the best performance amongst all three algorithms in dataset 6 (<xref rid="btz421-T2" ref-type="table">Table&#x000a0;2</xref> and <xref ref-type="fig" rid="btz421-F4">Fig.&#x000a0;4</xref>), where the test accuracy for the MLM algorithm was equal to 92% in dataset 5 and 82% in dataset 6, in comparison with 94% (dataset 5) and 79% (dataset 6) using the KS algorithm and 91% (dataset 5) and 70% (dataset 6) using the RS algorithm.</p><p>Finally, 1000 simulations using a normally distributed randomly data were performed in order to compare the performance of the RS, KS and MLM algorithms in a more robust way. As depicted in <xref ref-type="fig" rid="btz421-F5">Figure&#x000a0;5</xref>, the MLM algorithm achieved the best classification performance in terms of accuracy among all algorithms tested, with an average accuracy of 67% in the range between 53 and 82%. RS algorithm achieved the worst accuracy values, with an average of 66% and range 50&#x02013;80%, while KS achieved an accuracy value similar to MLM (67%), but with a poorer lower-limit, where accuracies ranged between 50 and 82%. In addition, the histogram profiles in <xref ref-type="fig" rid="btz421-F5">Figure&#x000a0;5</xref> show that amongst all 1000 simulations, MLM algorithm achieved the highest frequency peak (&#x0003e;150 times) above the average accuracy of 67%, while for RS and KS algorithms the highest frequency peak is below the average accuracy of 67%.
</p><fig id="btz421-F5" orientation="portrait" position="float"><label>Fig. 5.</label><caption><p>PCA-LDA accuracy distribution and histogram for 1000 simulations using normally distributed randomly data, where (<bold>a</bold>) RS, (<bold>b</bold>) KS and (<bold>c</bold>) MLM algorithm</p></caption><graphic xlink:href="btz421f5"/></fig><p>These findings confirm the hypothesis that our new MLM algorithm based on a random-mutation KS algorithm approach presents a better overall performance than using RS or KS algorithms independently, especially due to the well-balanced sensitivity and specificity values in the prediction set for real-world samples. The fact that RS individually achieved good fitting but a lower predictive performance indicates that this algorithm might not include a representative variance in the training model. This reinforces the hypothesis that not necessarily an algorithm with good fitting, as demonstrated using RS, will generate good predictive results towards external samples.</p></sec></body><back><ack id="ack1"><title>Acknowledgements</title><p>CLMM would like to thank Coordena&#x000e7;&#x000e3;o de Aperfei&#x000e7;oamento de Pessoal de N&#x000ed;vel Superior (CAPES) &#x02013; Brazil for financial support. MCDS thanks CNPq &#x02013; Brazil for his studentship. Approaches and methodologies used in this study were developed in work funded by the Biotechnology and Biological Sciences Research Council and the Engineering and Physical Sciences Research Council.</p><sec><title>Funding</title><p>This work was supported by Coordena&#x000e7;&#x000e3;o de Aperfei&#x000e7;oamento de Pessoal de N&#x000ed;vel Superior (CAPES) - Brazil (grant 88881.128982/2016-01), Biotechnology and Biological Sciences Research Council (grant number BB/D010055/1) and the Engineering and Physical Sciences Research Council (EPSRC; Grant Nos: GR/S75918/01 and EP/K023349/1).</p><p>
<italic>Conflict of Interest</italic>: none declared.</p></sec></ack><ref-list id="ref1"><title>References</title><ref id="btz421-B1"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Ballabio</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Consonni</surname><given-names>V.</given-names></name></person-group> (<year>2013</year>) 
<article-title>Classification tools in chemistry. Part 1: linear models. PLS-DA</article-title>. <source>Anal. Methods</source>, <volume>5</volume>, <fpage>3790</fpage>&#x02013;<lpage>3798</lpage>.</mixed-citation></ref><ref id="btz421-B2"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Brereton</surname><given-names>R.G.</given-names></name>, <name name-style="western"><surname>Lloyd</surname><given-names>G.R.</given-names></name></person-group> (<year>2014</year>) 
<article-title>Partial least squares discriminant analysis: taking the magic away</article-title>. <source>J. Chemometr</source>., <volume>28</volume>, <fpage>213</fpage>&#x02013;<lpage>225</lpage>.</mixed-citation></ref><ref id="btz421-B3"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Bro</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Smilde</surname><given-names>A.K.</given-names></name></person-group> (<year>2014</year>) 
<article-title>Principal component analysis</article-title>. <source>Anal. Methods</source>, <volume>6</volume>, <fpage>2812</fpage>&#x02013;<lpage>2831</lpage>.</mixed-citation></ref><ref id="btz421-B4"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Cortes</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Vapnik</surname><given-names>V.</given-names></name></person-group> (<year>1995</year>) 
<article-title>Support-vector networks</article-title>. <source>Mach. Learn</source>., <volume>20</volume>, <fpage>273</fpage>&#x02013;<lpage>297</lpage>.</mixed-citation></ref><ref id="btz421-B5"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Costa</surname><given-names>F.S.L.</given-names></name></person-group>
<etal>et al</etal> (<year>2016</year>) 
<article-title>Attenuated total reflection Fourier transform infrared (ATR-FTIR) spectroscopy as a new technology for discrimination between Cryptococcus neoformans and <italic>Cryptococcus gattii</italic></article-title>. <source>Anal. Methods</source>, <volume>8</volume>, <fpage>7107</fpage>&#x02013;<lpage>7115</lpage>.</mixed-citation></ref><ref id="btz421-B6"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Dixon</surname><given-names>S.J.</given-names></name>, <name name-style="western"><surname>Brereton</surname><given-names>R.G.</given-names></name></person-group> (<year>2009</year>) 
<article-title>Comparison of performance of five common classifiers represented as boundary methods: Euclidean distance to centroids, linear discriminant analysis, quadratic discriminant analysis, learning vector quantization and support vector machines, as dependent on data structure</article-title>. <source>Chemometr. Intell. Lab. Syst</source>., <volume>95</volume>, <fpage>1</fpage>&#x02013;<lpage>17</lpage>.</mixed-citation></ref><ref id="btz421-B7"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Gajjar</surname><given-names>K.</given-names></name></person-group>
<etal>et al</etal> (<year>2012</year>) 
<article-title>Diagnostic segregation of human brain tumours using Fourier-transform infrared and/or Raman spectroscopy coupled with discriminant analysis</article-title>. <source>Anal. Methods</source>, <volume>5</volume>, <fpage>89</fpage>&#x02013;<lpage>102</lpage>.<pub-id pub-id-type="pmid">24098310</pub-id></mixed-citation></ref><ref id="btz421-B8"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Kennard</surname><given-names>R.W.</given-names></name>, <name name-style="western"><surname>Stone</surname><given-names>L.A.</given-names></name></person-group> (<year>1969</year>) 
<article-title>Computer aided design of experiments</article-title>. <source>Technometrics</source>, <volume>11</volume>, <fpage>137</fpage>&#x02013;<lpage>148</lpage>.</mixed-citation></ref><ref id="btz421-B9"><mixed-citation publication-type="book">
<person-group person-group-type="author"><name name-style="western"><surname>Lindon</surname><given-names>J.C.</given-names></name></person-group>
<etal>et al</etal> (<year>2017</year>) <source>Encyclopedia of Spectroscopy and Spectrometry</source>. Vol. 1, <edition>3</edition>rd edn. 
<publisher-name>Academic Press</publisher-name>, 
<publisher-loc>Oxford</publisher-loc>.</mixed-citation></ref><ref id="btz421-B10"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Morais</surname><given-names>C.L.M.</given-names></name>, <name name-style="western"><surname>Lima</surname><given-names>K.M.G.</given-names></name></person-group> (<year>2017</year>) 
<article-title>Comparing unfolded and two-dimensional discriminant analysis and support vector machines for classification of EEM data</article-title>. <source>Chemometr. Intell. Lab. Syst</source>., <volume>170</volume>, <fpage>1</fpage>&#x02013;<lpage>12</lpage>.</mixed-citation></ref><ref id="btz421-B11"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Morais</surname><given-names>C.L.M.</given-names></name>, <name name-style="western"><surname>Lima</surname><given-names>K.M.G.</given-names></name></person-group> (<year>2018</year>) 
<article-title>Principal component analysis with linear and quadratic discriminant analysis for identification of cancer samples based on mass spectrometry</article-title>. <source>J. Braz. Chem. Soc</source>., <volume>29</volume>, <fpage>472</fpage>&#x02013;<lpage>481</lpage>.</mixed-citation></ref><ref id="btz421-B12"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Morais</surname><given-names>C.L.M.</given-names></name></person-group>
<etal>et al</etal> (<year>2017</year>) 
<article-title>Variable selection with a support vector machine for discriminating Cryptococcus fungal species based on ATR FTIR spectroscopy</article-title>. <source>Anal. Methods</source>, <volume>9</volume>, <fpage>2964</fpage>&#x02013;<lpage>2970</lpage>.</mixed-citation></ref><ref id="btz421-B13"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Morais</surname><given-names>C.L.M.</given-names></name></person-group>
<etal>et al</etal> (<year>2018</year>) 
<article-title>A computational protocol for sample selection in biological-derived infrared spectroscopy datasets using Morais-Lima-Martin (MLM) algorithm</article-title>. <source>Protoc. Exchange</source>, doi: 10.1038/protex.2018.141. </mixed-citation></ref><ref id="btz421-B14"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Morais</surname><given-names>C.L.M.</given-names></name></person-group>
<etal>et al</etal> (<year>2019</year>) 
<article-title>Standardization of complex biologically derived spectrochemical datasets</article-title>. <source>Nat. Protoc</source>., <volume>14</volume>, <fpage>1546</fpage>&#x02013;<lpage>1577</lpage>.<pub-id pub-id-type="pmid">30953040</pub-id></mixed-citation></ref><ref id="btz421-B15"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Paraskevaidi</surname><given-names>M.</given-names></name></person-group>
<etal>et al</etal> (<year>2018</year>) 
<article-title>Raman spectroscopic techniques to detect ovarian cancer biomarkers in blood plasma</article-title>. <source>Talanta</source>, <volume>189</volume>, <fpage>281</fpage>&#x02013;<lpage>288</lpage>.<pub-id pub-id-type="pmid">30086919</pub-id></mixed-citation></ref><ref id="btz421-B16"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Santos</surname><given-names>M.C.D.</given-names></name></person-group>
<etal>et al</etal> (<year>2018</year>) 
<article-title>ATR-FTIR spectroscopy with chemometric algorithms of multivariate classification in the discrimination between healthy vs. dengue vs. chikungunya vs. zika clinical samples</article-title>. <source>Anal. Methods</source>, <volume>10</volume>, <fpage>1280</fpage>&#x02013;<lpage>1285</lpage>.</mixed-citation></ref><ref id="btz421-B17"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Savitzky</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Golay</surname><given-names>M.J.</given-names></name></person-group> (<year>1964</year>) 
<article-title>Smoothing and differentiation of data by simplified least squares procedures</article-title>. <source>Anal. Chem</source>., <volume>36</volume>, <fpage>1627</fpage>&#x02013;<lpage>1639</lpage>.</mixed-citation></ref><ref id="btz421-B18"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Trevisan</surname><given-names>J.</given-names></name></person-group>
<etal>et al</etal> (<year>2010</year>) 
<article-title>Syrian hamster embryo (SHE) assay (pH 6.7) coupled with infrared spectroscopy and chemometrics towards toxicological assessment</article-title>. <source>Analyst</source>, <volume>135</volume>, <fpage>3266</fpage>&#x02013;<lpage>3272</lpage>.<pub-id pub-id-type="pmid">20938551</pub-id></mixed-citation></ref><ref id="btz421-B19"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Trevisan</surname><given-names>J.</given-names></name></person-group>
<etal>et al</etal> (<year>2013</year>) 
<article-title>IRootLab: a free and open-source MATLAB toolbox for vibrational biospectroscopy data analysis</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>1095</fpage>&#x02013;<lpage>1097</lpage>.<pub-id pub-id-type="pmid">23422340</pub-id></mixed-citation></ref><ref id="btz421-B20"><mixed-citation publication-type="journal">
<person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name></person-group>
<etal>et al</etal> (<year>1991</year>) 
<article-title>Multivariate instrument standardization</article-title>. <source>Anal. Chem</source>., <volume>63</volume>, <fpage>2750</fpage>&#x02013;<lpage>2756</lpage>.</mixed-citation></ref></ref-list></back></article>