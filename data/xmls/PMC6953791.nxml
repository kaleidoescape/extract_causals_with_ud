<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">31923226</article-id><article-id pub-id-type="pmc">6953791</article-id><article-id pub-id-type="publisher-id">PONE-D-19-25387</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0226990</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Bioassays and Physiological Analysis</subject><subj-group><subject>Electrophysiological Techniques</subject><subj-group><subject>Cardiac Electrophysiology</subject><subj-group><subject>Electrocardiography</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Cardiology</subject><subj-group><subject>Arrhythmia</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Cardiology</subject><subj-group><subject>Heart Rate</subject><subj-group><subject>Tachycardia</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject><subj-group><subject>Deep Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Cardiology</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Cardiology</subject><subj-group><subject>Heart Rate</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Single-modal and multi-modal false arrhythmia alarm reduction using attention-based convolutional and recurrent neural networks</article-title><alt-title alt-title-type="running-head">Single-modal and multi-modal false arrhythmia alarm reduction using deep learning</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-3806-8487</contrib-id><name><surname>Mousavi</surname><given-names>Sajad</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Data curation</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Validation</role><role content-type="http://credit.casrai.org/">Visualization</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/><xref ref-type="corresp" rid="cor001">*</xref></contrib><contrib contrib-type="author"><name><surname>Fotoohinasab</surname><given-names>Atiyeh</given-names></name><role content-type="http://credit.casrai.org/">Data curation</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Afghah</surname><given-names>Fatemeh</given-names></name><role content-type="http://credit.casrai.org/">Funding acquisition</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/></contrib></contrib-group><aff id="aff001">
<addr-line>School of Informatics, Computing and Cyber Systems, Northern Arizona University, Flagstaff, Arizona, United States of America</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Bacciu</surname><given-names>Davide</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">
<addr-line>Universita degli Studi di Pisa, ITALY</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>SajadMousavi@nau.edu</email></corresp></author-notes><pub-date pub-type="collection"><year>2020</year></pub-date><pub-date pub-type="epub"><day>10</day><month>1</month><year>2020</year></pub-date><volume>15</volume><issue>1</issue><elocation-id>e0226990</elocation-id><history><date date-type="received"><day>9</day><month>9</month><year>2019</year></date><date date-type="accepted"><day>9</day><month>12</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; 2020 Mousavi et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Mousavi et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0226990.pdf"/><abstract><p>This study proposes a deep learning model that effectively suppresses the false alarms in the intensive care units (ICUs) without ignoring the true alarms using single- and multi- modal biosignals. Most of the current work in the literature are either rule-based methods, requiring prior knowledge of arrhythmia analysis to build rules, or classical machine learning approaches, depending on hand-engineered features. In this work, we apply convolutional neural networks to automatically extract time-invariant features, an attention mechanism to put more emphasis on the important regions of the segmented input signal(s) that are more likely to contribute to an alarm, and long short-term memory units to capture the temporal information presented in the signal segments. We trained our method efficiently using a two-step training algorithm (i.e., pre-training and fine-tuning the proposed network) on the dataset provided by the PhysioNet computing in cardiology challenge 2015. The evaluation results demonstrate that the proposed method obtains better results compared to other existing algorithms for the false alarm reduction task in ICUs. The proposed method achieves a sensitivity of 93.88% and a specificity of 92.05% for the alarm classification, considering three different signals. In addition, our experiments for 5 separate alarm types leads significant results, where we just consider a single-lead ECG (e.g., a sensitivity of 90.71%, a specificity of 88.30%, an AUC of 89.51 for alarm type of Ventricular Tachycardia arrhythmia).</p></abstract><funding-group><award-group id="award001"><funding-source><institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100008982</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>657260</award-id><principal-award-recipient><name><surname>Afghah</surname><given-names>Fatemeh</given-names></name></principal-award-recipient></award-group><award-group id="award002"><funding-source><institution>National Institute On Minority Health and Health Disparities of the National Institutes of Health</institution></funding-source><award-id>U54MD012388</award-id><principal-award-recipient><name><surname>Afghah</surname><given-names>Fatemeh</given-names></name></principal-award-recipient></award-group><funding-statement>This material is based upon work supported by the National Science Foundation under Grant Number 1657260. Research reported in this publication was also supported by the National Institute On Minority Health and Health Disparities of the National Institutes of Health under Award Number U54MD012388. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><fig-count count="5"/><table-count count="7"/><page-count count="15"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>Data are publicly available through the following link: <ext-link ext-link-type="uri" xlink:href="https://www.physionet.org/content/challenge-2015/1.0.0/">https://www.physionet.org/content/challenge-2015/1.0.0/</ext-link>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>Data are publicly available through the following link: <ext-link ext-link-type="uri" xlink:href="https://www.physionet.org/content/challenge-2015/1.0.0/">https://www.physionet.org/content/challenge-2015/1.0.0/</ext-link>.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>The electrocardiogram (ECG) is a biomedical signal that includes information about the electrical activity of heart function and heart conditions over a period of time. Monitoring and interpretation of ECG signals serve the most useful tool for medical staff in ICUs to check the patients&#x02019; heart condition such as arrhythmia, ventricular hypertrophy, and myocardial infarction, etc. Cardiac arrhythmias can cause serious and even potentially fatal symptoms if they are not inspected promptly. Although patient-monitoring alarms play an indispensable role in saving patients&#x02019; lives, the high rate of false alarms not only can be annoying for patients but also may delay the response of medical staff due to making them less sensitive to warnings. Moreover, it can delay patients&#x02019; recovery by causing sleep deprivation and depressed immune systems. Therefore, suppressing the rate of false alarms in ICUs will improve the quality of patient care and reduce the number of missed true fatal alarms by medical staff. As reported by Aboukhalil et al. [<xref rid="pone.0226990.ref001" ref-type="bibr">1</xref>] and Drew et al. [<xref rid="pone.0226990.ref002" ref-type="bibr">2</xref>], the rate of false alarms in ICUs reaches as high as almost 90%. In regard to this concern, the PhysioNet directed the challenge 2015 to reduce the incidence of false arrhythmia alarms in ICUs while the true alarms are not suppressed [<xref rid="pone.0226990.ref003" ref-type="bibr">3</xref>].</p><p>In order to reduce the rate of false alarms in ICUs, various methods have been proposed. Typically, they can be classified into two general categories: 1) methods based on cardiac rules and 2) machine learning based methods. In the first category, some cardiac rules are defined by experts to detect alarm types. All of the approaches in this category depend primarily on the QRS-complex detection in order to estimate heart rate (HR) and evaluate the signal quality. Ansari et al. [<xref rid="pone.0226990.ref004" ref-type="bibr">4</xref>] adopted several peak detection algorithms to create a robust peak detection algorithm and exploited the information from all three ECG, ABP and PPG signals. Fallet et al. [<xref rid="pone.0226990.ref005" ref-type="bibr">5</xref>] used an adaptive frequency tracking algorithm to estimate HR from PPG and ABP signals and an adaptive mathematical morphology approach to estimate HR from the ECG. Also, they exploited the Spectral Purity Index (SPI) to quantify the morphological changes of QRS complexes related to the Ventricular Arrhythmia. Then, they employed a set of rules based on the HR and the SPI to inspect false alarms. Plesinger et al. [<xref rid="pone.0226990.ref006" ref-type="bibr">6</xref>] and Couto et al. [<xref rid="pone.0226990.ref007" ref-type="bibr">7</xref>] applied a set of rules on each alarm types to distinguish between false and true alarms using ECG, ABP and PLETH signals. He et al. [<xref rid="pone.0226990.ref008" ref-type="bibr">8</xref>] classified alarms using ECG and ABP signals by following a set of rules related to Signal Quality Index (SQI) and Heart Rate Variability (HRV). However, one challenge with the false alarm detection based on cardiac rules is the need for an expert to determine the rules and the required thresholds. To tackle this, recent studies have exploited machine-learning approaches to detect false alarms.</p><p>In machine learning based methods, a false alarm detection model is trained using some extracted features from the dataset&#x02019;s samples. In [<xref rid="pone.0226990.ref009" ref-type="bibr">9</xref>], features of interest are extracted from the two-dimensional beat-to-beat correlograms using Fast Fourier Transform (FFT) and principle component analysis (PCA) as well as basic statistical and self-similarity analysis. Then, several machine learning algorithms are evaluated using the extracted features to detect false alarms. In [<xref rid="pone.0226990.ref010" ref-type="bibr">10</xref>], a random forest technique is applied to reduce false alarms using different methods of probability and class assignments. Lehman et al. [<xref rid="pone.0226990.ref011" ref-type="bibr">11</xref>] adopted a supervised denoising autoencoder (SDAE) to identify false alarms in Ventricular Tachycardia using features of interest extracted by FFT. Kalidas and Tamil [<xref rid="pone.0226990.ref012" ref-type="bibr">12</xref>] used a combination of logical and SVM algorithm to classify arrhythmias using ECG and PPG signals. In their work, the features of interest are a set of both time and frequency-domain information. [<xref rid="pone.0226990.ref013" ref-type="bibr">13</xref>] and [<xref rid="pone.0226990.ref014" ref-type="bibr">14</xref>] proposed game theoretical approaches in order to extract more discriminative features to reduce the rate of false alarms.</p><p>The performance of the classification methods highly depends on the quality of class discriminating features in terms of on what extent they can capture the main characteristics of the input. Most of the machine learning methods are trained based on hand-crafted features. However, one challenge facing the hand-crafted features is that it depends on a specific dataset, thereby new features may be needed if the dataset changes in terms of size and variety of patients. Although deep learning algorithms have been utilized in medical applications [<xref rid="pone.0226990.ref015" ref-type="bibr">15</xref>&#x02013;<xref rid="pone.0226990.ref017" ref-type="bibr">17</xref>], only a few numbers of studies in the false alarm reduction literature applied deep learning methods and automatic feature extraction [<xref rid="pone.0226990.ref011" ref-type="bibr">11</xref>, <xref rid="pone.0226990.ref018" ref-type="bibr">18</xref>]. In this paper, we propose a deep learning-based approach to reduce the rate of false alarms in ICUs for five life-threatening arrhythmias: Asystole (ASY), Extreme Bradycardia (EBR), Extreme Tachycardia (ETC), Ventricular Tachycardia (VTA), and Ventricular Flutter/Fibrillation (VFB). The performance of the proposed model is evaluated using the publicly available alarm dataset for ICUs provided by &#x0201c;PhysioNet computing in cardiology challenge 2015&#x0201d;. The experimental results show the proposed method can significantly suppress the rate of false alarms in ICU equipment with respect to five mentioned life-threatening arrhythmias without suppressing true alarms. In the following, the main contributions of this work are summarized:</p><list list-type="bullet"><list-item><p>We present a multi-modal model that integrates three main signals of arterial blood pressure (ABP), photoplethysmograph (PPG) and ECG in order to enhance the accuracy of arrhythmia detection and reduce the false alarm rate in ICUs. A multi-modal approach that analyzes a set of independent sources/signals for alarm detection can significantly improve the alarm detection performance. The reason behind this idea is that each independent channel or source of data is inclined to distinct noise and/or artifacts, thereby a hidden pattern in a certain channel caused by noise and/or artifacts can be disclosed by other clean channels.</p></list-item><list-item><p>We develop a network architecture for automatic feature extraction that utilizes a convolutional neural network (CNN) with two consecutive one-dimensional convolutional layers composed of different filter sizes, attention and long short-term memory (LSTM) units, and a classification layer. The CNN part extracts a vector of features from each segment of a single channel, while the attention and LSTM units are trained to identify the most effective parts of the segment in the detection and capture long-range of dependencies between segments of an input signal, respectively. Typically, some indicators appear in the signals as early as few hours before cardiac events [<xref rid="pone.0226990.ref019" ref-type="bibr">19</xref>&#x02013;<xref rid="pone.0226990.ref021" ref-type="bibr">21</xref>]. Since considering the entire length of the signals is not necessarily feasible, an attention mechanism along with a memory-based approach can divide the signals into different partitions by putting a higher weight on the most important ones to save space/computation as well as enhance the accuracy.</p></list-item><list-item><p>We apply two loss functions of Mean False Error (MFE) and Mean Squared False Error (MSFE) instead of using the common loss function in deep learning algorithms; Mean Squared Error (MSE), to reduce the effect of class unbalanced dataset on degrading the performance. This proposed loss function propagates the training error for a misclassified sample without considering its membership to the major or minor class.</p></list-item></list><p>In the next section (<xref ref-type="sec" rid="sec002">Methodology</xref>), we describe the proposed false arrhythmia alarm reduction method. Dataset section provides a description of the dataset used in this study. In Section Experimental Results, we present the experimental results and compare the performance of the proposed algorithm to other state-of-the-art algorithms, followed by the conclusion in Section Conclusion.</p></sec><sec sec-type="materials|methods" id="sec002"><title>Methodology</title><p>We develop a deep learning model to classify the arrhythmias from the segments of three common physiological signals of ECG, ABP, and PPG signals based on a two-stage approach to further reduce the false alarm rate. In the first part, we develop three pre-trained networks to extract features of interest for the three biosignals separately, followed by a shallow neural network in the second part that uses the extracted features from the pre-trained nets to perform a classification task. At each time step, pre-trained networks extract features of their corresponding input signals, and then, the extracted features are averaged and fed to the fully-connect layer with the size of 256 neurons followed by a dropout block. Finally, a softmax layer is used to determine the probability of the input signal belonging to each class of interest (true or false alarm). <xref ref-type="fig" rid="pone.0226990.g001">Fig 1</xref> shows an overall view of the proposed model for reducing false arrhythmia alarms in ICUs. It should be noted that the dropout block is frozen during the testing phase and is just used in the training phase. In the following sections, we describe the details of different parts of the proposed model.</p><fig id="pone.0226990.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226990.g001</object-id><label>Fig 1</label><caption><title>An overview of the network architecture for multi-model false alarm reduction method.</title><p>AVG: average, FC: fully connected layer.</p></caption><graphic xlink:href="pone.0226990.g001"/></fig><sec id="sec003"><title>Pre-processing</title><p>Prior to feature extraction and classification parts, the ECG, ABP, and PPG signals were subjected to normalization and segmentation steps. For the normalization step, the signals are normalized to a range of 0 to 1. The segmentation part is perfomed using a sliding 200-sample window with an overlap of 25% for all three signals separately. These segments are fed to their corresponding networks (i.e., ECG, ABP, and PPG NETs as shown in <xref ref-type="fig" rid="pone.0226990.g001">Fig 1</xref>) as the input sequences. It is worth mentioning that the pre-processing process does not include any noise removing and/or filtering steps to remove muscle artifacts and baseline wander.</p></sec><sec id="sec004"><title>The model architecture</title><p>The following subsections describe the main parts of the automatic feature extraction network. We train a feature extraction network for each of the three input signals separately. <xref ref-type="fig" rid="pone.0226990.g002">Fig 2</xref> illustrates the proposed network architecture for automatic feature extraction.</p><fig id="pone.0226990.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226990.g002</object-id><label>Fig 2</label><caption><title>The network architecture of the proposed model for feature extraction.</title></caption><graphic xlink:href="pone.0226990.g002"/></fig><sec id="sec005"><title>Convolutional neural network (CNN)</title><p>We employ two consecutive 1D convolutional layers with different sizes of filters and a max-pooling layer following the first convolutional layer. The first convolutional layer is composed of 32 filters with a kernel size of 2 &#x000d7; 1 and a stride 1, and a Rectified Linear Unit (ReLU) layer. The second convolutional layer with larger sizes of filters has 64 filters with a kernel size of 2 &#x000d7; 1 and a stride 1, and a ReLU layer. The max-pooling layer has a pooling region of size 2 &#x000d7; 1 with a stride size of 2 &#x000d7; 1. At each time step, a sequence of a segmented signal (e.g., ECG, ABP or PPG) with the size of n is fed to the CNN to extract features of interest. The second CNN layer generates <italic>D</italic> feature maps of size <italic>L</italic> &#x000d7; 1 for each sample of the input signal, which is converted to L vectors of D-dimension as follows:
<disp-formula id="pone.0226990.e001"><alternatives><graphic xlink:href="pone.0226990.e001.jpg" id="pone.0226990.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="2.em"/><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>D</mml:mi></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p><p>Here, we have 64 feature maps with the sizes of 5 &#x000d7; 1 (see <xref ref-type="fig" rid="pone.0226990.g002">Fig 2</xref>).</p></sec><sec id="sec006"><title>Attention and long short-term memory (LSTM) units</title><p>We use an attention unit to learn the most effective parts of the input signal that are responsible to trigger a specific alarm. The attention mechanism has also been used in previous biomedical signal processing studies such as [<xref rid="pone.0226990.ref017" ref-type="bibr">17</xref>, <xref rid="pone.0226990.ref022" ref-type="bibr">22</xref>] to improve the atrial fibrillation classification performance. In [<xref rid="pone.0226990.ref022" ref-type="bibr">22</xref>], they have placed attention modules after the LSTM units to have attentions on each 30s input segment. However, we put the attention units before LSTM units to focus on the segments parts (each segment is divided into fixed predefined parts (i.e., here, 10)) instead of input segments of the signal. The attention unit assigns a probability value to each part of the signal to specify its importance in the prediction process (e.g., predicting true or false alarm). For instance, as depicted in <xref ref-type="fig" rid="pone.0226990.g002">Fig 2</xref>, the attention unit assigns a probability value to each vector extracted from the input segment by the CNN. Finally, an expected value of the most effective regions of the input segments is generated using the probability values provided by the attention units (represented by the feature vector, <italic>C</italic><sub><italic>t</italic></sub>).</p><p><xref ref-type="fig" rid="pone.0226990.g003">Fig 3</xref> illustrates a systematic diagram of the attention unit utilized in our proposed model. The attention unit is fed by two inputs: (1) <italic>L</italic> feature vectors, <italic>C</italic><sub><italic>t</italic>,1</sub>, <italic>C</italic><sub><italic>t</italic>,2</sub>, &#x02026;, <italic>C</italic><sub><italic>t</italic>,<italic>L</italic></sub>, where each <italic>C</italic><sub><italic>t</italic>,<italic>i</italic></sub> represents a different part of the input segment, and (2) A hidden state <italic>h</italic><sub><italic>t</italic>&#x02212;1</sub>, which is the internal state of the RNN at the previous time step, <italic>t</italic> &#x02212; 1. Then, it calculates a vector, <italic>c</italic><sub><italic>t</italic></sub> which is a weighted sum over feature slices, <italic>C</italic><sub><italic>t</italic>,<italic>i</italic></sub>. With respect to the aforementioned assumptions, the attention mechanism can be formulated as:
<disp-formula id="pone.0226990.e002"><alternatives><graphic xlink:href="pone.0226990.e002.jpg" id="pone.0226990.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mo form="prefix">tanh</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula>
<disp-formula id="pone.0226990.e003"><alternatives><graphic xlink:href="pone.0226990.e003.jpg" id="pone.0226990.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula></p><fig id="pone.0226990.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226990.g003</object-id><label>Fig 3</label><caption><title>A systematic diagram of the attention unit.</title><p>The attention unit takes as input vertical feature slices, <italic>C</italic><sub><italic>t</italic>,<italic>i</italic></sub>
<italic>i</italic> &#x02208; 1, 2, &#x02026;, <italic>L</italic>, and the RNN previous hidden state, <italic>h</italic><sub><italic>t</italic>&#x02212;1</sub>. Then, it computes a linear weighted vector, <italic>c</italic><sub><italic>t</italic></sub> that is a multiplication of each feature slice and its corresponding importance, <italic>&#x003b1;</italic><sub><italic>t</italic>,<italic>i</italic></sub>.</p></caption><graphic xlink:href="pone.0226990.g003"/></fig><p>In the above equations, <italic>&#x003b1;</italic><sub><italic>t</italic>,<italic>i</italic></sub> is the importance of part <italic>i</italic> of the input segment. <italic>f</italic>(.) is a softmax function that processes a vector of L real numbers as input, and normalizes them into probability values. At first, a vector consisted of a weighted sum over <italic>C</italic><sub><italic>t</italic>,<italic>i</italic></sub> and <italic>h</italic><sub><italic>t</italic>&#x02212;1</sub> values is created and passed to the tanh function. Then, the softmax function normalizes the <italic>L</italic> values of the input vector and creates <italic>&#x003b1;</italic><sub><italic>t</italic>,<italic>i</italic></sub>. In other words, each <italic>&#x003b1;</italic><sub><italic>t</italic>,<italic>i</italic></sub> is considered as the amount of importance of the corresponding vector <italic>C</italic><sub><italic>t</italic>,<italic>i</italic></sub> among <italic>L</italic> vectors in the input segment. Finally, the attention unit calculates <italic>c</italic><sub><italic>t</italic></sub>, a weighted sum of all vectors <italic>C</italic><sub><italic>t</italic>,<italic>i</italic></sub> with respect to <italic>&#x003b1;</italic><sub><italic>t</italic>,<italic>i</italic></sub>s. Following the above process, the model attempts to learn to put more emphasis on the important regions of the input segment with higher probabilities that make to trigger an alarm (e.g., a false or true alarm) in ICUs.</p><p>In order to extract temporal information and capture long-range of dependencies between segments of the input signal, we employ a stack of two long short-term memory (LSTM) units with sizes of 256. The LSTM units are following the attention units and take <italic>c</italic><sub><italic>t</italic>+<italic>i</italic></sub> values produced by the attention units and the previous hidden states of the LSTM units as inputs to generate the next hidden states. In other words, the LSTM unit takes <italic>c</italic><sub><italic>t</italic></sub>, the output of attention unit at time <italic>t</italic>, and <italic>h</italic><sub><italic>t</italic>&#x02212;1</sub>, previous hidden state, to return the next hidden state <italic>h</italic><sub><italic>t</italic></sub>. The new hidden states are fed to the attention units to produce the value of <italic>h</italic><sub><italic>t</italic></sub> at the next step and also the fully-connected layer with a size of 256 (see <xref ref-type="fig" rid="pone.0226990.g002">Fig 2</xref>).</p></sec><sec id="sec007"><title>Classification layer</title><p>This layer specifies the label of the input signal (i.e., true or false alarm) and consists of a fully-connected layer followed by a softmax layer. The softmax layer assigns probabilities that the given input belongs to each of the class labels (i.e., true or false alarm classes). Note that this layer is removed while the model depicted in <xref ref-type="fig" rid="pone.0226990.g002">Fig 2</xref> is used as a feature extractor in the network illustrated in <xref ref-type="fig" rid="pone.0226990.g001">Fig 1</xref>.</p></sec></sec><sec id="sec008"><title>Loss calculation</title><p>An important caveat in the false alarm reduction research is the class imbalance problem, meaning that the number of true alarms is much less than the false alarms. This problem causes to drop the performance of the applied method for the minor class. To tackle this problem, we examined two loss functions: mean false error (MFE) and mean squared false error (MSFE) [<xref rid="pone.0226990.ref023" ref-type="bibr">23</xref>, <xref rid="pone.0226990.ref024" ref-type="bibr">24</xref>] instead of the commonly used Mean Squared Error (MSE) in deep learning algorithms. These loss functions calculate the training error without considering the membership of the misclassified sample to the major or minor class. In other words, the MFE and MSFE methods capture the training error of the classes equally as opposed to the MSE method that is biased to the major class in a imbalanced dataset. The loss functions can be defined as follows:
<disp-formula id="pone.0226990.e004"><alternatives><graphic xlink:href="pone.0226990.e004.jpg" id="pone.0226990.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>l</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(3)</label></disp-formula>
<disp-formula id="pone.0226990.e005"><alternatives><graphic xlink:href="pone.0226990.e005.jpg" id="pone.0226990.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>F</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mi>l</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(4)</label></disp-formula>
<disp-formula id="pone.0226990.e006"><alternatives><graphic xlink:href="pone.0226990.e006.jpg" id="pone.0226990.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>F</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mi>l</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(5)</label></disp-formula></p><p>In the above equations, <italic>g</italic><sub><italic>i</italic></sub> is the class label (e.g., true or false alarm), <italic>G</italic><sub><italic>i</italic></sub> is the number of samples in the class <italic>g</italic><sub><italic>i</italic></sub>, <italic>N</italic> is the number of available classes (in this study, we have two classes), and <italic>l</italic>(<italic>g</italic><sub><italic>i</italic></sub>) is the error calculated over the class <italic>g</italic><sub><italic>i</italic></sub>.</p></sec><sec id="sec009"><title>Training algorithm</title><p>In order to effectively train the proposed model via back-propagation algorithm, we present a two-step training algorithm as illustrated in 1. Step 1 (lines 1-9) involves extracting the features of interest for a specific input signal (i.e., for each of ECG, ABP, and PPG signals, separately). Then, pre-trained networks are used as feature extractors for their corresponding models including ECG, ABP, and PPG. In this step, in order to apply the pre-trained networks as feature extractors, only the output of the fully-connected layer in the classification layer is utilized to represent the given signal and the softmax layer is discarded (i.e., line 8). In step 2 (lines 10-16), the classification task is accomplished using the three signals as shown in <xref ref-type="fig" rid="pone.0226990.g001">Fig 1</xref>. It must be pointed out that the three pre-trained networks are frozen during training process and the second part of the model is trained to generate a label. Also, training the models in both steps are performed with the same hyper-parameters.</p><p><bold>Algorithm 1</bold> Two-step training algorithm for the proposed model</p><p specific-use="line"><bold>Input</bold>: hyper-parameters, data</p><p specific-use="line"><bold>Output</bold>: f_model</p><p specific-use="line">&#x02003;<italic><bold>Step 1</bold></italic>:</p><p specific-use="line">1: <bold>for each</bold>
<italic>modal</italic>
<bold>in</bold> [<italic>ECG</italic>, <italic>ABP</italic>, <italic>PPG</italic>] <bold>do</bold></p><p specific-use="line">2: &#x02003;Initialize <italic>NET</italic>[<italic>modal</italic>] with random weights</p><p specific-use="line">3: &#x02003;<bold>for</bold>
<italic>i</italic> = 1 <bold>to</bold>
<italic>n</italic>_<italic>epochs</italic>
<bold>do</bold></p><p specific-use="line">4: &#x02003;&#x02003;<bold>for each</bold>
<italic>batch</italic>
<bold>in</bold>
<italic>batch</italic>_<italic>data</italic>(<italic>data</italic>, <italic>modal</italic>) <bold>do</bold></p><p specific-use="line">5: &#x02003;&#x02003;&#x02003;<italic>NET</italic>[<italic>modal</italic>] &#x02190; <italic>train_network</italic> (<italic>NET</italic>[<italic>modal</italic>], <italic>batch</italic>), <italic>as shown in</italic>
<xref ref-type="fig" rid="pone.0226990.g002">Fig 2</xref></p><p specific-use="line">6: &#x02003;&#x02003;<bold>end for</bold></p><p specific-use="line">7: &#x02003;<bold>end for</bold></p><p specific-use="line">8: &#x02003;<italic>NET</italic>[<italic>modal</italic>]&#x02190;<italic>r</italic>_<italic>softmax</italic>_<italic>layer</italic>(<italic>NET</italic>[<italic>modal</italic>])</p><p specific-use="line">9: <bold>end for</bold></p><p specific-use="line">&#x02003;<italic><bold>Step 2</bold></italic>:</p><p specific-use="line">10: Initialize <italic>f</italic>_<italic>model</italic> with random weights</p><p specific-use="line">11: <bold>for</bold>
<italic>i</italic> = 1 <bold>to</bold>
<italic>n</italic>_<italic>epochs</italic>
<bold>do</bold></p><p specific-use="line">12: &#x02003;<bold>for each</bold>
<italic>batch</italic>
<bold>in</bold>
<italic>batch</italic>_<italic>data</italic>(<italic>data</italic>) <bold>do</bold></p><p specific-use="line">13: &#x02003;&#x02003;<italic>f_model</italic> &#x02190; <italic>train_model</italic>(<italic>f_model</italic>, <italic>NET</italic>[<italic>ECG</italic>], <italic>NET</italic>[<italic>ABP</italic>], <italic>NET</italic>[<italic>PPG</italic>], <italic>batch</italic>), <italic>as shown in</italic>
<xref ref-type="fig" rid="pone.0226990.g001">Fig 1</xref></p><p specific-use="line">14: &#x02003;<bold>end for</bold>&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x02003;&#x022b3; Learning for <italic>NET</italic>[.] is frozen.</p><p specific-use="line">15: <bold>end for</bold></p><p specific-use="line">16: <bold>return</bold>
<italic>f</italic>_<italic>model</italic></p></sec></sec><sec id="sec010"><title>Dataset</title><p>We applied the publicly available alarm database for ICUs provided by PhysioNet computing in cardiology challenge 2015 [<xref rid="pone.0226990.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0226990.ref025" ref-type="bibr">25</xref>]. It includes five types of life-threatening arrhythmia alarms: Asystole (ASY), Extreme Bradycardia (EBR), Extreme Tachycardia (ETC), Ventricular Tachycardia (VTA), and Ventricular Flutter/Fibrillation (VFB). The definition and visualization of each alarm are presented in <xref rid="pone.0226990.t001" ref-type="table">Table 1</xref> and in <xref ref-type="fig" rid="pone.0226990.g005">Fig 5</xref>, respectively. The training set includes 750 recordings and the test set includes 500 recordings. The test set has not been publicly available yet, therefore we use the training set for both test and training purposes. Each is recording composed of two ECG leads and one or more pulsatile waveforms (i.e., the photoplethysmogram (PPG) and/or arterial blood pressure (ABP) waveform). <xref ref-type="fig" rid="pone.0226990.g004">Fig 4</xref> shows a sample of each type of the ECG, ABP and PPG signals. The signals were re-sampled to a resolution of 12 bit and frequency of 250 Hz and filtered by a finite impulse response (FIR) bandpass [0.05 to 40 Hz] and mains notch filters for denoising. The alarms were labeled with a team of expert to either &#x02018;true&#x02019; or &#x02018;false&#x02019;. <xref rid="pone.0226990.t002" ref-type="table">Table 2</xref> shows the statistics of the numbers of true and false alarms of each arrhythmia type in the training set.</p><table-wrap id="pone.0226990.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226990.t001</object-id><label>Table 1</label><caption><title>Alarms definition.</title></caption><alternatives><graphic id="pone.0226990.t001g" xlink:href="pone.0226990.t001"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Alarm Type</th><th align="center" rowspan="1" colspan="1">Definition</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">
<monospace>Asystole(ASY)</monospace>
</td><td align="center" rowspan="1" colspan="1">There might not be heartbeats for more than 4s in the signal</td></tr><tr><td align="left" rowspan="1" colspan="1">
<monospace>Extreme Bradycardia (EBR)</monospace>
</td><td align="center" rowspan="1" colspan="1">The heart rate is less than 40 beats per minute (bpm)</td></tr><tr><td align="left" rowspan="1" colspan="1">
<monospace>Extreme Tachycardia (ETC)</monospace>
</td><td align="center" rowspan="1" colspan="1">The heart rate would be greater than 140 bpm for 17 consecutive beats</td></tr><tr><td align="left" rowspan="1" colspan="1">
<monospace>Ventricular Tachycardia (VTA)</monospace>
</td><td align="center" rowspan="1" colspan="1">A sequence of five or more ventricular beats with the heart rate greater than 100 bpm in the signal</td></tr><tr><td align="left" rowspan="1" colspan="1">
<monospace>Ventricular Flutter/Fibrillation (VFB)</monospace>
</td><td align="center" rowspan="1" colspan="1">A rapid Fibrillatory, flutter, or oscillatory waveform for at least 4 seconds in the signal</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t001fn001"><p>HR: Heart rate</p></fn></table-wrap-foot></table-wrap><table-wrap id="pone.0226990.t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226990.t002</object-id><label>Table 2</label><caption><title>The statistics of the numbers of true and false alarms of each arrhythmia type.</title></caption><alternatives><graphic id="pone.0226990.t002g" xlink:href="pone.0226990.t002"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Alarm</th><th align="center" rowspan="1" colspan="1"># of patients</th><th align="center" rowspan="1" colspan="1"># of false alarms</th><th align="right" rowspan="1" colspan="1"># of true alarms</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Asystole (ASY)</td><td align="center" rowspan="1" colspan="1">122</td><td align="center" rowspan="1" colspan="1">100</td><td align="right" rowspan="1" colspan="1">22</td></tr><tr><td align="left" rowspan="1" colspan="1">Extreme Bradycardia (EBR)</td><td align="center" rowspan="1" colspan="1">89</td><td align="center" rowspan="1" colspan="1">43</td><td align="right" rowspan="1" colspan="1">46</td></tr><tr><td align="left" rowspan="1" colspan="1">Extreme Tachycardia (ETC)</td><td align="center" rowspan="1" colspan="1">140</td><td align="center" rowspan="1" colspan="1">9</td><td align="right" rowspan="1" colspan="1">131</td></tr><tr><td align="left" rowspan="1" colspan="1">Ventricular Tachycardia (VTA)</td><td align="center" rowspan="1" colspan="1">341</td><td align="center" rowspan="1" colspan="1">252</td><td align="right" rowspan="1" colspan="1">89</td></tr><tr><td align="left" rowspan="1" colspan="1">Ventricular Flutter/Fibrillation (VFB)</td><td align="center" rowspan="1" colspan="1">58</td><td align="center" rowspan="1" colspan="1">52</td><td align="right" rowspan="1" colspan="1">6</td></tr><tr><td align="left" rowspan="1" colspan="1">Total</td><td align="center" rowspan="1" colspan="1">750</td><td align="center" rowspan="1" colspan="1">456</td><td align="right" rowspan="1" colspan="1">294</td></tr></tbody></table></alternatives></table-wrap><fig id="pone.0226990.g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226990.g004</object-id><label>Fig 4</label><caption><title>Illustration of an electrocardiogram (ECG), an arterial blood pressure (ABP) and a photoplethysmogram (PPG) signal.</title></caption><graphic xlink:href="pone.0226990.g004"/></fig><fig id="pone.0226990.g005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226990.g005</object-id><label>Fig 5</label><caption><title>Five common critical alarm types in the intensive care units as used in the PhysioNet/computing in cardiology challenge 2015 [<xref rid="pone.0226990.ref003" ref-type="bibr">3</xref>].</title></caption><graphic xlink:href="pone.0226990.g005"/></fig></sec><sec id="sec011"><title>Experimental results</title><p>The performance of the proposed model was evaluated using the PhysioNet challenge-2015 dataset. Since multi-modal prediction is based on the three signals of ECG, ABP and PPG, only 220 samples out of 750 recordings that include all these signals are used and for the single-modal method all samples are utilized. The PhysioNet challenge 2015 [<xref rid="pone.0226990.ref025" ref-type="bibr">25</xref>] have considered two main events: (i) real-time setting in which the information before the alarm onset can be used, and (ii) retrospective setting in which up to 30 seconds of data after the alarm can be used. In this study, we focus on the real-time setting where only information prior to occurring the alarm is used. As mentioned above, using all signals in the learning process makes the model take benefit of all available information and extract the correlation between different models. We used <italic>k</italic>-fold cross-validation approach to train and test the proposed model with a <italic>k</italic> size of 10 unless explicitly stated otherwise. Indeed, we divided the dataset into k = 10 folds. Then, for each fold of the 10 folds, one fold is used for evaluating the model and the remaining 9 folds are used to train the model. In the end, all evaluation results were concatenated. It is worth noting that the pre-training and fine-tuning steps were performed for each round of the cross-validation rounds.</p><p>Both whole model and the three networks (ECG, ABP and PPG Nets) were trained with a maximum of 100 epochs and a mini-batch size of 10. The RMSProp optimizer was applied to minimize the <italic>l</italic><sub><italic>MFE</italic></sub> loss with a learning rate parameter of <italic>&#x003b1;</italic> = 0.001. Two different regularization techniques were used to prevent the overfitting problem. First, the dropout layer with the probability of dropping of 0.5 (as shown in <xref ref-type="fig" rid="pone.0226990.g001">Fig 1</xref>). At every learning iteration, the dropout function chooses the some nodes randomly and deletes them along with their connections. Second, an additional <italic>L</italic><sub>2</sub> regularization term with <italic>&#x003b2;</italic> = 0.001 was added to the loss function. This kind of regularization tries to punish the model parameters with large values. As a result, it prevents an unstable learning (i.e., the exploding gradient problem). Python programming language along with Google Tensorflow deep learning library were used to implement our model. Furthermore, a machine with 8 CPUs (Intel(R) Xeon(R) CPU @ 3.60 GHz), 32 GB memory and Ubuntu 16.04 was utilized to run the k-fold cross validation. The training time for each epoch was 98 seconds on average and the testing time for each batch of 20 EEG epochs was approximately 0.102 seconds.</p><p>Different metrics were considered to assess the performance of the proposed model. These metrics include accuracy (ACC), sensitivity (SEN), specificity (SPE), precision (PRE), F1-score, and area under the ROC curve (AUC). We also report the PhysioNet Challenge 2015 score for our proposed method. It is defined as <italic>score</italic> = (<italic>TP</italic> + <italic>TN</italic>)/(<italic>TP</italic> + <italic>TN</italic> + <italic>FP</italic> + 5 &#x000d7; <italic>FN</italic>), where TP is true positives, FP is false positives, FN is false negatives, and TN is true negatives. All results are reported as an average over k-folds, where k can set to 5 and 10).</p><sec id="sec012"><title>Results and discussion</title><p>The results in <xref rid="pone.0226990.t003" ref-type="table">Table 3</xref> represent the alarm classification (as true or false alarm) success for our proposed method against other methods in the literature while three signals (i.e., ECG II, ABP and PPG) are considered. It can be seen from the table that our model significantly outperforms other methods. We also experimented our single-modal (using just one single lead) approach to bold how outcome might be different. <xref rid="pone.0226990.t003" ref-type="table">Table 3</xref> demonstrates using the multi-modal approach absolutely leads in better performance results compared to the single-modal one.</p><table-wrap id="pone.0226990.t003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226990.t003</object-id><label>Table 3</label><caption><title>Comparison of performance of the proposed model against other algorithms on the PhysioNet challenge-2015 dataset.</title></caption><alternatives><graphic id="pone.0226990.t003g" xlink:href="pone.0226990.t003"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" colspan="6" style="border-top:thick" rowspan="1">Best Performance (%)</th></tr><tr><th align="left" rowspan="1" colspan="1">Method</th><th align="center" rowspan="1" colspan="1">Signal</th><th align="center" rowspan="1" colspan="1"># of samples</th><th align="center" rowspan="1" colspan="1">CV</th><th align="center" rowspan="1" colspan="1"><italic>SEN</italic></th><th align="center" rowspan="1" colspan="1"><italic>SPE</italic></th><th align="center" rowspan="1" colspan="1"><italic>PRE</italic></th><th align="center" rowspan="1" colspan="1"><italic>F</italic>1&#x02014;<italic>score</italic></th><th align="center" rowspan="1" colspan="1"><italic>AUC</italic></th><th align="center" rowspan="1" colspan="1"><italic>ACC</italic></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><bold>Multi-modal method</bold></td><td align="center" rowspan="1" colspan="1">All</td><td align="center" rowspan="1" colspan="1">220</td><td align="center" rowspan="1" colspan="1">10-fold CV</td><td align="center" rowspan="1" colspan="1"><bold><underline>93.88</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>92.05</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>79.31</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>85.98</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>92.99</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>92.50</underline></bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Zaeri-Amirani et al. [<xref rid="pone.0226990.ref014" ref-type="bibr">14</xref>]</td><td align="center" rowspan="1" colspan="1">All</td><td align="center" rowspan="1" colspan="1">220</td><td align="center" rowspan="1" colspan="1">10-fold CV</td><td align="center" rowspan="1" colspan="1">73</td><td align="center" rowspan="1" colspan="1">75</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">81</td><td align="center" rowspan="1" colspan="1">77</td></tr><tr><td align="left" rowspan="1" colspan="1">Afghah et al. [<xref rid="pone.0226990.ref028" ref-type="bibr">28</xref>]</td><td align="center" rowspan="1" colspan="1">All</td><td align="center" rowspan="1" colspan="1">220</td><td align="center" rowspan="1" colspan="1">10-fold CV</td><td align="center" rowspan="1" colspan="1">80</td><td align="center" rowspan="1" colspan="1">71</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">74.32</td><td align="center" rowspan="1" colspan="1">77.6</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Single-modal method</bold></td><td align="center" rowspan="1" colspan="1">ECG II</td><td align="center" rowspan="1" colspan="1">220</td><td align="center" rowspan="1" colspan="1">10-fold CV</td><td align="center" rowspan="1" colspan="1">73.33</td><td align="center" rowspan="1" colspan="1">87.74</td><td align="char" char="." rowspan="1" colspan="1">63.46</td><td align="center" rowspan="1" colspan="1">68.04</td><td align="center" rowspan="1" colspan="1">80.53</td><td align="center" rowspan="1" colspan="1">84.50</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Single-modal method</bold></td><td align="center" rowspan="1" colspan="1">ABP</td><td align="center" rowspan="1" colspan="1">220</td><td align="center" rowspan="1" colspan="1">10-fold CV</td><td align="center" rowspan="1" colspan="1">78.72</td><td align="center" rowspan="1" colspan="1">65.35</td><td align="char" char="." rowspan="1" colspan="1">41.11</td><td align="center" rowspan="1" colspan="1">54</td><td align="center" rowspan="1" colspan="1">72.04</td><td align="center" rowspan="1" colspan="1">68.50</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Single-modal method</bold></td><td align="center" rowspan="1" colspan="1">PPG</td><td align="center" rowspan="1" colspan="1">220</td><td align="center" rowspan="1" colspan="1">10-fold CV</td><td align="center" rowspan="1" colspan="1">87.50</td><td align="center" rowspan="1" colspan="1">63.15</td><td align="char" char="." rowspan="1" colspan="1">42.96</td><td align="center" rowspan="1" colspan="1">57.53</td><td align="center" rowspan="1" colspan="1">75.32</td><td align="center" rowspan="1" colspan="1">69</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t003fn001"><p>All: ECG II, ABP, PPG; CV: Cross Validation</p></fn></table-wrap-foot></table-wrap><p>The results provided in <xref rid="pone.0226990.t003" ref-type="table">Table 3</xref> are for 220 samples of dataset with three available signals, aggregating all alarm types. We also evaluated our model with samples with just Ventricular Tachycardia alarm type. There were two main reasons that we selected this alarm type, (1) the number of samples for other life-threatening arrhythmia alarm types were too small, Asystole (34: 4 true and 30 false alarms), Extreme Bradycardia (30: 21 false and 9 true alarms), Extreme Tachycardia (15: 14 false and 1 true alarms), Ventricular-Flutter/Fibrillation (17: 12 false and 5 true alarms), and Ventricular Tachycardia (124: 106 false and 18 true alarms), (2) the Ventricular Tachycardia alarms are more difficult than other alarm types to detect [<xref rid="pone.0226990.ref025" ref-type="bibr">25</xref>]. <xref rid="pone.0226990.t004" ref-type="table">Table 4</xref> shows the performance of our proposed model for Ventricular Tachycardia alarm type using a single-lead signal and multi-lead signals. Our method achieves remarkable results for both the multi-modal and the single-modal (ECG II) approaches, a sensitivity and a specificity of 93.75% and 93.92% for the single-modal technique, and a sensitivity and a specificity of 93.75% and 95.49% for the multi-modal technique. As shown in the table, our method outweighs the other method significantly. It also can be seen that using all available signals performs better compared to the single-lead signal. The reason behind this improvement is that the multi-modal approach has integrated information from three input signals that makes the model to give better performance.</p><table-wrap id="pone.0226990.t004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226990.t004</object-id><label>Table 4</label><caption><title>Comparison of performance of the proposed model against other algorithms for alarm type of Ventricular Tachycardia arrhythmia on the PhysioNet challenge-2015 dataset.</title></caption><alternatives><graphic id="pone.0226990.t004g" xlink:href="pone.0226990.t004"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" colspan="6" style="border-top:thick" rowspan="1">Best Performance (%)</th></tr><tr><th align="left" rowspan="1" colspan="1">Method</th><th align="center" rowspan="1" colspan="1">Signal</th><th align="center" rowspan="1" colspan="1"># of samples</th><th align="center" rowspan="1" colspan="1">CV</th><th align="center" rowspan="1" colspan="1"><italic>SEN</italic></th><th align="center" rowspan="1" colspan="1"><italic>SPE</italic></th><th align="center" rowspan="1" colspan="1"><italic>PRE</italic></th><th align="center" rowspan="1" colspan="1"><italic>F</italic>1&#x02014;<italic>score</italic></th><th align="center" rowspan="1" colspan="1"><italic>AUC</italic></th><th align="center" rowspan="1" colspan="1"><italic>ACC</italic></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><bold>Multi-modal method</bold></td><td align="center" rowspan="1" colspan="1">All</td><td align="center" rowspan="1" colspan="1">124/220</td><td align="center" rowspan="1" colspan="1">10-fold CV</td><td align="center" rowspan="1" colspan="1"><bold><underline>93.75</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>95.49</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>85.41</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>86.67</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>94.61</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>95</underline></bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Afghah et al. [<xref rid="pone.0226990.ref028" ref-type="bibr">28</xref>]</td><td align="center" rowspan="1" colspan="1">All</td><td align="center" rowspan="1" colspan="1">124/220</td><td align="center" rowspan="1" colspan="1">10-fold CV</td><td align="center" rowspan="1" colspan="1">86</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">73</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">85.48</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Single-modal method</bold></td><td align="center" rowspan="1" colspan="1">ECG II</td><td align="center" rowspan="1" colspan="1">124/220</td><td align="center" rowspan="1" colspan="1">10-fold CV</td><td align="center" rowspan="1" colspan="1">93.75</td><td align="center" rowspan="1" colspan="1">93.92</td><td align="center" rowspan="1" colspan="1">79.16</td><td align="center" rowspan="1" colspan="1">84.58</td><td align="center" rowspan="1" colspan="1">93.84</td><td align="center" rowspan="1" colspan="1">93.75</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Single-modal method</bold></td><td align="center" rowspan="1" colspan="1">ABP</td><td align="center" rowspan="1" colspan="1">124/220</td><td align="center" rowspan="1" colspan="1">10-fold CV</td><td align="center" rowspan="1" colspan="1">81.25</td><td align="center" rowspan="1" colspan="1">75.68</td><td align="center" rowspan="1" colspan="1">41.95</td><td align="center" rowspan="1" colspan="1">69.76</td><td align="center" rowspan="1" colspan="1">78.46</td><td align="center" rowspan="1" colspan="1">76.67</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Single-modal method</bold></td><td align="center" rowspan="1" colspan="1">PPG</td><td align="center" rowspan="1" colspan="1">124/220</td><td align="center" rowspan="1" colspan="1">10-fold CV</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">50</td><td align="center" rowspan="1" colspan="1">33.33</td><td align="center" rowspan="1" colspan="1">50</td><td align="center" rowspan="1" colspan="1">75</td><td align="center" rowspan="1" colspan="1">60</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t004fn001"><p>All: ECG II, ABP, PPG; CV: Cross Validation</p></fn></table-wrap-foot></table-wrap><p>We also investigated how our model behaves for all alarm types using single-lead ECG waveforms. <xref rid="pone.0226990.t005" ref-type="table">Table 5</xref> compares the performance (in terms of true positive rate (TPR or also called the sensitivity) true negative rate (TNR or also called specificity) and AUC) of various algorithms using different signals. As can be seen in <xref rid="pone.0226990.t005" ref-type="table">Table 5</xref>, the proposed method performs better than the methods proposed by Lehman et al. [<xref rid="pone.0226990.ref011" ref-type="bibr">11</xref>] and Li et al. [<xref rid="pone.0226990.ref026" ref-type="bibr">26</xref>] on Ventricular Tachycardia (VTA) alarm. Furthermore, our method using single-lead ECG (ECG II) detects Extreme Bradycardia (EBR), Extreme Tachycardia (ETC) and Ventricular-Flutter/Fibrillation (VFB) alarms significaly better than other methods using two-lead ECG (Lehman et al. [<xref rid="pone.0226990.ref011" ref-type="bibr">11</xref>]) and all available signals, including ECG II, ECG V, ABP and PPG (Ansari et al. [<xref rid="pone.0226990.ref027" ref-type="bibr">27</xref>] and Gajowniczek et al. [<xref rid="pone.0226990.ref010" ref-type="bibr">10</xref>]). Moreover, as shown in <xref rid="pone.0226990.t005" ref-type="table">Table 5</xref>, our proposed single-modal method leads to comparable results (in some cases, even better outcomes) for detecting Asystole (ASY) and Ventricular Tachycardia (VTA) arrhythmical alarm types compared to other listed algorithms that have utilized more than one signal. In addition, we note that here our remarkable results were obtained using a single-lead ECG (ECG II), however having more than one modal would leads to a improvement in performance results. In addition, we have tested our proposed method without employing attention mechanism into the network, and using MSE loss function. <xref rid="pone.0226990.t006" ref-type="table">Table 6</xref> presents the evaluation results with various metrics. As it can be seen from the table, our proposed method in which we consider the attention module and utilize the mean false alarm (MFE) loss achieved significantly better findings compared to the ones that do not employ attention mechanism and use the MSE loss function instead of MFE loss function.</p><table-wrap id="pone.0226990.t005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226990.t005</object-id><label>Table 5</label><caption><title>Comparison of performance of the proposed model against other algorithms for all alarm types on the PhysioNet challenge-2015 dataset.</title></caption><alternatives><graphic id="pone.0226990.t005g" xlink:href="pone.0226990.t005"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" colspan="3" style="border-top:thick" rowspan="1">ASY</th><th align="center" colspan="3" style="border-top:thick" rowspan="1">EBR</th><th align="center" colspan="3" style="border-top:thick" rowspan="1">ETC</th><th align="center" colspan="3" style="border-top:thick" rowspan="1">VTA</th><th align="center" colspan="3" style="border-top:thick" rowspan="1">VFB</th></tr><tr><th align="left" rowspan="1" colspan="1">Method</th><th align="center" rowspan="1" colspan="1">Signal</th><th align="center" rowspan="1" colspan="1">CV</th><th align="center" rowspan="1" colspan="1">TPR</th><th align="center" rowspan="1" colspan="1">TNR</th><th align="center" rowspan="1" colspan="1">AUC</th><th align="center" rowspan="1" colspan="1">TPR</th><th align="center" rowspan="1" colspan="1">TNR</th><th align="center" rowspan="1" colspan="1">AUC</th><th align="center" rowspan="1" colspan="1">TPR</th><th align="center" rowspan="1" colspan="1">TNR</th><th align="center" rowspan="1" colspan="1">AUC</th><th align="center" rowspan="1" colspan="1">TPR</th><th align="center" rowspan="1" colspan="1">TNR</th><th align="center" rowspan="1" colspan="1">AUC</th><th align="center" rowspan="1" colspan="1">TPR</th><th align="center" rowspan="1" colspan="1">TNR</th><th align="center" rowspan="1" colspan="1">AUC</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><bold>Single-modal method</bold></td><td align="center" rowspan="1" colspan="1">ECG II</td><td align="center" rowspan="1" colspan="1">5-fold</td><td align="center" rowspan="1" colspan="1"><bold><underline>96.67</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>82.16</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>89.41</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>97.78</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>94.85</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>96.31</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>100</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>100</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>100</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>90.71</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>88.30</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>89.51</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>100</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>97.22</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>98.61</underline></bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Lehman et al. [<xref rid="pone.0226990.ref011" ref-type="bibr">11</xref>]</td><td align="center" rowspan="1" colspan="1">ECG II<xref ref-type="table-fn" rid="t005fn002">*</xref></td><td align="center" rowspan="1" colspan="1">10-fold</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">87</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1">Li et al. [<xref rid="pone.0226990.ref026" ref-type="bibr">26</xref>]</td><td align="center" rowspan="1" colspan="1">ECG II</td><td align="center" rowspan="1" colspan="1">0.67/0.33</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">76.70</td><td align="center" rowspan="1" colspan="1">59.80</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1">Lehman et al. [<xref rid="pone.0226990.ref011" ref-type="bibr">11</xref>]</td><td align="center" rowspan="1" colspan="1">ECG II/V<xref ref-type="table-fn" rid="t005fn002">*</xref></td><td align="center" rowspan="1" colspan="1">10-fold</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">89</td><td align="center" rowspan="1" colspan="1">86</td><td align="center" rowspan="1" colspan="1">91</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1">Ansari et al. [<xref rid="pone.0226990.ref027" ref-type="bibr">27</xref>]</td><td align="center" rowspan="1" colspan="1">All</td><td align="center" rowspan="1" colspan="1">5-fold</td><td align="center" rowspan="1" colspan="1">84.97</td><td align="center" rowspan="1" colspan="1">89.21</td><td align="center" rowspan="1" colspan="1">-</td><td align="char" char="." rowspan="1" colspan="1">90.49</td><td align="center" rowspan="1" colspan="1">90.05</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">96.55</td><td align="center" rowspan="1" colspan="1">97.80</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">96.63</td><td align="center" rowspan="1" colspan="1">95.47</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">92.40</td><td align="char" char="." rowspan="1" colspan="1">61.64</td><td align="center" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1">Gajowniczek et al. [<xref rid="pone.0226990.ref010" ref-type="bibr">10</xref>]</td><td align="center" rowspan="1" colspan="1">All</td><td align="center" rowspan="1" colspan="1">10-fold</td><td align="center" rowspan="1" colspan="1">85</td><td align="center" rowspan="1" colspan="1">90</td><td align="center" rowspan="1" colspan="1">95</td><td align="char" char="." rowspan="1" colspan="1">84.5</td><td align="center" rowspan="1" colspan="1">91</td><td align="char" char="." rowspan="1" colspan="1">93.3</td><td align="center" rowspan="1" colspan="1">99.2</td><td align="center" rowspan="1" colspan="1">77.8</td><td align="center" rowspan="1" colspan="1">99</td><td align="center" rowspan="1" colspan="1">67.8</td><td align="center" rowspan="1" colspan="1">88.9</td><td align="center" rowspan="1" colspan="1">87</td><td align="center" rowspan="1" colspan="1">83.3</td><td align="char" char="." rowspan="1" colspan="1">94.2</td><td align="center" rowspan="1" colspan="1">95</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t005fn001"><p>All: ECG II, ECG V, ABP, and PPG; CV: Cross Validation;</p></fn><fn id="t005fn002"><p>*: 1250 records (750 train, 500 hidden test of Physionet), in which 562 records contains VTA alarms</p></fn></table-wrap-foot></table-wrap><table-wrap id="pone.0226990.t006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226990.t006</object-id><label>Table 6</label><caption><title>Comparison of performance of the proposed model against the proposed model without employing attention and the proposed method using MSE loss for all alarm types on the PhysioNet challenge-2015 dataset, considering just a single lead (ECG II; all available samples (750 samples)).</title></caption><alternatives><graphic id="pone.0226990.t006g" xlink:href="pone.0226990.t006"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" colspan="3" style="border-top:thick" rowspan="1">ASY</th><th align="center" colspan="3" style="border-top:thick" rowspan="1">EBR</th><th align="center" colspan="3" style="border-top:thick" rowspan="1">ETC</th><th align="center" colspan="3" style="border-top:thick" rowspan="1">VTA</th><th align="center" colspan="3" style="border-top:thick" rowspan="1">VFB</th></tr><tr><th align="left" rowspan="1" colspan="1">Method</th><th align="center" rowspan="1" colspan="1">CV</th><th align="center" rowspan="1" colspan="1">TPR</th><th align="center" rowspan="1" colspan="1">TNR</th><th align="center" rowspan="1" colspan="1">AUC</th><th align="center" rowspan="1" colspan="1">TPR</th><th align="center" rowspan="1" colspan="1">TNR</th><th align="center" rowspan="1" colspan="1">AUC</th><th align="center" rowspan="1" colspan="1">TPR</th><th align="center" rowspan="1" colspan="1">TNR</th><th align="center" rowspan="1" colspan="1">AUC</th><th align="center" rowspan="1" colspan="1">TPR</th><th align="center" rowspan="1" colspan="1">TNR</th><th align="center" rowspan="1" colspan="1">AUC</th><th align="center" rowspan="1" colspan="1">TPR</th><th align="center" rowspan="1" colspan="1">TNR</th><th align="center" rowspan="1" colspan="1">AUC</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><bold>Proposed method</bold></td><td align="center" rowspan="1" colspan="1">5-fold</td><td align="center" rowspan="1" colspan="1"><bold><underline>96.67</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>82.16</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>89.41</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>97.78</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>94.85</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>96.31</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>100</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>100</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>100</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>90.71</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>88.30</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>89.51</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>100</underline></bold></td><td align="center" rowspan="1" colspan="1"><bold><underline>97.22</underline></bold></td><td align="char" char="." rowspan="1" colspan="1"><bold><underline>98.61</underline></bold></td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Proposed method (No attention)</bold></td><td align="center" rowspan="1" colspan="1">5-fold</td><td align="center" rowspan="1" colspan="1">91</td><td align="char" char="." rowspan="1" colspan="1">75.78</td><td align="char" char="." rowspan="1" colspan="1">83.39</td><td align="char" char="." rowspan="1" colspan="1">84.38</td><td align="char" char="." rowspan="1" colspan="1">77.78</td><td align="char" char="." rowspan="1" colspan="1">81.08</td><td align="center" rowspan="1" colspan="1">98.17</td><td align="center" rowspan="1" colspan="1">55.56</td><td align="center" rowspan="1" colspan="1">50</td><td align="char" char="." rowspan="1" colspan="1">78.76</td><td align="char" char="." rowspan="1" colspan="1">72.38</td><td align="char" char="." rowspan="1" colspan="1">75.57</td><td align="center" rowspan="1" colspan="1">37.5</td><td align="center" rowspan="1" colspan="1">82</td><td align="char" char="." rowspan="1" colspan="1">59.75</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Proposed method (With MSE)</bold></td><td align="center" rowspan="1" colspan="1">5-fold</td><td align="center" rowspan="1" colspan="1">43</td><td align="char" char="." rowspan="1" colspan="1">96.40</td><td align="char" char="." rowspan="1" colspan="1">69.70</td><td align="char" char="." rowspan="1" colspan="1">88.46</td><td align="char" char="." rowspan="1" colspan="1">83.33</td><td align="char" char="." rowspan="1" colspan="1">85.89</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">33.33</td><td align="center" rowspan="1" colspan="1">50</td><td align="char" char="." rowspan="1" colspan="1">53.90</td><td align="char" char="." rowspan="1" colspan="1">83.74</td><td align="char" char="." rowspan="1" colspan="1">68.82</td><td align="center" rowspan="1" colspan="1">14.29</td><td align="center" rowspan="1" colspan="1">98.03</td><td align="char" char="." rowspan="1" colspan="1">56.16</td></tr></tbody></table></alternatives></table-wrap><p>Furthermore, <xref rid="pone.0226990.t007" ref-type="table">Table 7</xref> reports the evaluation results of our single-modal proposed method with various metrics, including the challenge score provided by the PhysioNet Challenge 2015, using just the ECG II signal. This table can be used as a reference to compare future work.</p><table-wrap id="pone.0226990.t007" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226990.t007</object-id><label>Table 7</label><caption><title>Performance of the proposed model for all alarm types on the PhysioNet challenge-2015 dataset, considering just a single lead (ECG II; all available samples (750 samples)).</title></caption><alternatives><graphic id="pone.0226990.t007g" xlink:href="pone.0226990.t007"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" style="border-top:thick" rowspan="1" colspan="1"/><th align="center" colspan="7" style="border-top:thick" rowspan="1">Best Performance (%)</th></tr><tr><th align="left" rowspan="1" colspan="1">Alarm</th><th align="center" rowspan="1" colspan="1">SEN</th><th align="center" rowspan="1" colspan="1">SPE</th><th align="center" rowspan="1" colspan="1">PRE</th><th align="center" rowspan="1" colspan="1">F1-score</th><th align="center" rowspan="1" colspan="1">AUC</th><th align="center" rowspan="1" colspan="1">ACC</th><th align="center" rowspan="1" colspan="1">Score</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><bold>ASY</bold></td><td align="center" rowspan="1" colspan="1">96.67</td><td align="center" rowspan="1" colspan="1">82.17</td><td align="center" rowspan="1" colspan="1">57.33</td><td align="center" rowspan="1" colspan="1">69.21</td><td align="center" rowspan="1" colspan="1">89.41</td><td align="center" rowspan="1" colspan="1">84.20</td><td align="center" rowspan="1" colspan="1">81.20</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>EBR</bold></td><td align="center" rowspan="1" colspan="1">97.78</td><td align="center" rowspan="1" colspan="1">94.85</td><td align="center" rowspan="1" colspan="1">93.76</td><td align="center" rowspan="1" colspan="1">95.56</td><td align="center" rowspan="1" colspan="1">96.31</td><td align="center" rowspan="1" colspan="1">96</td><td align="center" rowspan="1" colspan="1">92.35</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>ETC</bold></td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">100</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>VTA</bold></td><td align="center" rowspan="1" colspan="1">90.71</td><td align="center" rowspan="1" colspan="1">88.30</td><td align="center" rowspan="1" colspan="1">74.88</td><td align="center" rowspan="1" colspan="1">81.41</td><td align="center" rowspan="1" colspan="1">89.51</td><td align="center" rowspan="1" colspan="1">88.89</td><td align="center" rowspan="1" colspan="1">81.55</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>VFB</bold></td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">97.22</td><td align="center" rowspan="1" colspan="1">87.50</td><td align="center" rowspan="1" colspan="1">91.67</td><td align="center" rowspan="1" colspan="1">98.61</td><td align="center" rowspan="1" colspan="1">97.50</td><td align="center" rowspan="1" colspan="1">97.50</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t007fn001"><p>Score: PhysioNet/CinC Challenge 2015 Score</p></fn></table-wrap-foot></table-wrap></sec></sec><sec sec-type="conclusions" id="sec013"><title>Conclusion</title><p>False arrhythmia alarm reduction in ICUs is a challenging classification problem because of the presence of different sources of noise and artifacts in the data (i.e., the collected signals) as well as a large number of false alarms that results in the class imbalance problem. In this study, we proposed a deep learning-based network composed of the CNN layers, attention mechanism, and LSTM units to reduce false alarm arrhythmia in ICUs. We also utilized a new loss function to alleviate the effect of the class imbalance problem while training the model. Our proposed approach utilized a two-step training algorithm that trains the model for each modal (i.e., ECG, ABP, and PPG) to efficiently extract features, and then uses the combined features of each modal to classify the three-input signal to a true or false alarm (i.e., in a multi-modal way). Our proposed multi- and single-modal approaches demonstrated high performance for the suppression of false alarms without disregarding the true alarms compared to the existing algorithms in the literature.</p></sec></body><back><ref-list><title>References</title><ref id="pone.0226990.ref001"><label>1</label><mixed-citation publication-type="journal">
<name><surname>Aboukhalil</surname><given-names>A</given-names></name>, <name><surname>Nielsen</surname><given-names>L</given-names></name>, <name><surname>Saeed</surname><given-names>M</given-names></name>, <name><surname>Mark</surname><given-names>RG</given-names></name>, <name><surname>Clifford</surname><given-names>GD</given-names></name>. <article-title>Reducing false alarm rates for critical arrhythmias using the arterial blood pressure waveform</article-title>. <source>Journal of biomedical informatics</source>. <year>2008</year>;<volume>41</volume>(<issue>3</issue>):<fpage>442</fpage>&#x02013;<lpage>451</lpage>. <pub-id pub-id-type="doi">10.1016/j.jbi.2008.03.003</pub-id>
<pub-id pub-id-type="pmid">18440873</pub-id></mixed-citation></ref><ref id="pone.0226990.ref002"><label>2</label><mixed-citation publication-type="journal">
<name><surname>Drew</surname><given-names>BJ</given-names></name>, <name><surname>Harris</surname><given-names>P</given-names></name>, <name><surname>Z&#x000e8;gre-Hemsey</surname><given-names>JK</given-names></name>, <name><surname>Mammone</surname><given-names>T</given-names></name>, <name><surname>Schindler</surname><given-names>D</given-names></name>, <name><surname>Salas-Boni</surname><given-names>R</given-names></name>, <etal>et al</etal>
<article-title>Insights into the problem of alarm fatigue with physiologic monitor devices: a comprehensive observational study of consecutive intensive care unit patients</article-title>. <source>PloS one</source>. <year>2014</year>;<volume>9</volume>(<issue>10</issue>):<fpage>e110274</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0110274</pub-id>
<pub-id pub-id-type="pmid">25338067</pub-id></mixed-citation></ref><ref id="pone.0226990.ref003"><label>3</label><mixed-citation publication-type="other">PhysioNet. Reducing False Arrhythmia Alarms in the ICU; 2015. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.physionet.org/challenge/2015/">http://www.physionet.org/challenge/2015/</ext-link>.</mixed-citation></ref><ref id="pone.0226990.ref004"><label>4</label><mixed-citation publication-type="other">Ansari S, Belle A, Najarian K. Multi-modal integrated approach towards reducing false arrhythmia alarms during continuous patient monitoring: the PhysioNet Challenge 2015. In: 2015 Computing in Cardiology Conference (CinC). IEEE; 2015. p. 1181&#x02013;1184.</mixed-citation></ref><ref id="pone.0226990.ref005"><label>5</label><mixed-citation publication-type="other">Fallet S, Yazdani S, Vesin JM. A multimodal approach to reduce false arrhythmia alarms in the intensive care unit. In: 2015 Computing in Cardiology Conference (CinC). IEEE; 2015. p. 277&#x02013;280.</mixed-citation></ref><ref id="pone.0226990.ref006"><label>6</label><mixed-citation publication-type="other">Plesinger F, Klimes P, Halamek J, Jurak P. False alarms in intensive care unit monitors: detection of life-threatening arrhythmias using elementary algebra, descriptive statistics and fuzzy logic. In: Computing in Cardiology Conference (CinC), 2015. IEEE; 2015. p. 281&#x02013;284.</mixed-citation></ref><ref id="pone.0226990.ref007"><label>7</label><mixed-citation publication-type="other">Couto P, Ramalho R, Rodrigues R. Suppression of false arrhythmia alarms using ECG and pulsatile waveforms. In: Computing in Cardiology Conference (CinC), 2015. IEEE; 2015. p. 749&#x02013;752.</mixed-citation></ref><ref id="pone.0226990.ref008"><label>8</label><mixed-citation publication-type="other">He R, Zhang H, Wang K, Yuan Y, Li Q, Pan J, et al. Reducing false arrhythmia alarms in the ICU using novel signal quality indices assessment method. In: 2015 Computing in Cardiology Conference (CinC). IEEE; 2015. p. 1189&#x02013;1192.</mixed-citation></ref><ref id="pone.0226990.ref009"><label>9</label><mixed-citation publication-type="journal">
<name><surname>Antink</surname><given-names>CH</given-names></name>, <name><surname>Leonhardt</surname><given-names>S</given-names></name>, <name><surname>Walter</surname><given-names>M</given-names></name>. <article-title>Reducing false alarms in the ICU by quantifying self-similarity of multimodal biosignals</article-title>. <source>Physiological measurement</source>. <year>2016</year>;<volume>37</volume>(<issue>8</issue>):<fpage>1233</fpage>
<pub-id pub-id-type="doi">10.1088/0967-3334/37/8/1233</pub-id>
<pub-id pub-id-type="pmid">27454256</pub-id></mixed-citation></ref><ref id="pone.0226990.ref010"><label>10</label><mixed-citation publication-type="journal">
<name><surname>Gajowniczek</surname><given-names>K</given-names></name>, <name><surname>Grzegorczyk</surname><given-names>I</given-names></name>, <name><surname>Zabkowski</surname><given-names>T</given-names></name>. <article-title>Reducing False Arrhythmia Alarms Using Different Methods of Probability and Class Assignment in Random Forest Learning Methods</article-title>. <source>Sensors</source>. <year>2019</year>;<volume>19</volume>(<issue>7</issue>):<fpage>1588</fpage>
<pub-id pub-id-type="doi">10.3390/s19071588</pub-id></mixed-citation></ref><ref id="pone.0226990.ref011"><label>11</label><mixed-citation publication-type="other">Lehman EP, Krishnan RG, Zhao X, Mark RG, Li-wei HL. Representation Learning Approaches to Detect False Arrhythmia Alarms from ECG Dynamics. In: Machine Learning for Healthcare Conference; 2018. p. 571&#x02013;586.</mixed-citation></ref><ref id="pone.0226990.ref012"><label>12</label><mixed-citation publication-type="other">Kalidas V, Tamil LS. Enhancing accuracy of arrhythmia classification by combining logical and machine learning techniques. In: Computing in Cardiology Conference (CinC), 2015. IEEE; 2015. p. 733&#x02013;736.</mixed-citation></ref><ref id="pone.0226990.ref013"><label>13</label><mixed-citation publication-type="other">Afghah F, Razi A, Najarian K. A Shapley Value Solution to Game Theoretic-based Feature Reduction in False Alarm Detection. arXiv preprint arXiv:151201680. 2015;.</mixed-citation></ref><ref id="pone.0226990.ref014"><label>14</label><mixed-citation publication-type="other">Zaeri-Amirani M, Afghah F, Mousavi S. A Feature Selection Method Based on Shapley Value to False Alarm Reduction in ICUs A Genetic-Algorithm Approach. In: 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC); 2018. p. 319&#x02013;323.</mixed-citation></ref><ref id="pone.0226990.ref015"><label>15</label><mixed-citation publication-type="journal">
<name><surname>Acharya</surname><given-names>UR</given-names></name>, <name><surname>Fernandes</surname><given-names>SL</given-names></name>, <name><surname>WeiKoh</surname><given-names>JE</given-names></name>, <name><surname>Ciaccio</surname><given-names>EJ</given-names></name>, <name><surname>Fabell</surname><given-names>MKM</given-names></name>, <name><surname>Tanik</surname><given-names>UJ</given-names></name>, <etal>et al</etal>
<article-title>Automated Detection of Alzheimer&#x02019;s Disease Using Brain MRI Images&#x02013;A Study with Various Feature Extraction Techniques</article-title>. <source>Journal of Medical Systems</source>. <year>2019</year>;<volume>43</volume>(<issue>9</issue>):<fpage>302</fpage>
<pub-id pub-id-type="doi">10.1007/s10916-019-1428-9</pub-id>
<pub-id pub-id-type="pmid">31396722</pub-id></mixed-citation></ref><ref id="pone.0226990.ref016"><label>16</label><mixed-citation publication-type="other">Mousavi S, Afghah F. Inter-and intra-patient ecg heartbeat classification for arrhythmia detection: a sequence to sequence deep learning approach. In: ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE; 2019. p. 1308&#x02013;1312.</mixed-citation></ref><ref id="pone.0226990.ref017"><label>17</label><mixed-citation publication-type="other">Mousavi S, Afghah F, Razi A, Acharya UR. ECGNET: Learning where to attend for detection of atrial fibrillation with deep visual attention. In: 2019 IEEE EMBS International Conference on Biomedical &#x00026; Health Informatics (BHI). IEEE; 2019. p. 1&#x02013;4.</mixed-citation></ref><ref id="pone.0226990.ref018"><label>18</label><mixed-citation publication-type="other">Hooman OM, Al-Rifaie MM, Nicolaou MA. Deep Neuroevolution: Training Deep Neural Networks for False Alarm Detection in Intensive Care Units. In: 2018 26th European Signal Processing Conference (EUSIPCO). IEEE; 2018. p. 1157&#x02013;1161.</mixed-citation></ref><ref id="pone.0226990.ref019"><label>19</label><mixed-citation publication-type="journal">
<name><surname>Mozos</surname><given-names>I</given-names></name>, <name><surname>Caraba</surname><given-names>A</given-names></name>. <article-title>Electrocardiographic predictors of cardiovascular mortality</article-title>. <source>Disease markers</source>. <year>2015</year>;<volume>2015</volume>
<pub-id pub-id-type="doi">10.1155/2015/727401</pub-id>
<pub-id pub-id-type="pmid">26257460</pub-id></mixed-citation></ref><ref id="pone.0226990.ref020"><label>20</label><mixed-citation publication-type="journal">
<name><surname>Abdelghani</surname><given-names>SA</given-names></name>, <name><surname>Rosenthal</surname><given-names>TM</given-names></name>, <name><surname>Morin</surname><given-names>DP</given-names></name>. <article-title>Surface electrocardiogram predictors of sudden cardiac arrest</article-title>. <source>Ochsner Journal</source>. <year>2016</year>;<volume>16</volume>(<issue>3</issue>):<fpage>280</fpage>&#x02013;<lpage>289</lpage>. <pub-id pub-id-type="pmid">27660578</pub-id></mixed-citation></ref><ref id="pone.0226990.ref021"><label>21</label><mixed-citation publication-type="journal">
<name><surname>Lai</surname><given-names>D</given-names></name>, <name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Zhang</surname><given-names>X</given-names></name>, <name><surname>Su</surname><given-names>Y</given-names></name>, <name><surname>Heyat</surname><given-names>MBB</given-names></name>. <article-title>An Automated Strategy for Early Risk Identification of Sudden Cardiac Death by Using Machine Learning Approach on Measurable Arrhythmic Risk Markers</article-title>. <source>IEEE Access</source>. <year>2019</year>;<volume>7</volume>:<fpage>94701</fpage>&#x02013;<lpage>94716</lpage>. <pub-id pub-id-type="doi">10.1109/ACCESS.2019.2925847</pub-id></mixed-citation></ref><ref id="pone.0226990.ref022"><label>22</label><mixed-citation publication-type="other">Shashikumar SP, Shah AJ, Clifford GD, Nemati S. Detection of paroxysmal atrial fibrillation using attention-based bidirectional recurrent neural networks. In: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &#x00026; Data Mining. ACM; 2018. p. 715&#x02013;723.</mixed-citation></ref><ref id="pone.0226990.ref023"><label>23</label><mixed-citation publication-type="journal">
<name><surname>Mousavi</surname><given-names>S</given-names></name>, <name><surname>Afghah</surname><given-names>F</given-names></name>, <name><surname>Acharya</surname><given-names>UR</given-names></name>. <article-title>SleepEEGNet: Automated sleep stage scoring with sequence to sequence deep learning approach</article-title>. <source>PLoS ONE</source>
<volume>14</volume>(<issue>5</issue>): <fpage>e0216456</fpage>
<year>2019</year>; <pub-id pub-id-type="doi">10.1371/journal.pone.0216456</pub-id>
<pub-id pub-id-type="pmid">31063501</pub-id></mixed-citation></ref><ref id="pone.0226990.ref024"><label>24</label><mixed-citation publication-type="other">Wang S, Liu W, Wu J, Cao L, Meng Q, Kennedy PJ. Training deep neural networks on imbalanced data sets. In: Neural Networks (IJCNN), 2016 International Joint Conference on. IEEE; 2016. p. 4368&#x02013;4374.</mixed-citation></ref><ref id="pone.0226990.ref025"><label>25</label><mixed-citation publication-type="other">Clifford GD, Silva I, Moody B, Li Q, Kella D, Shahin A, et al. The PhysioNet/computing in cardiology challenge 2015: reducing false arrhythmia alarms in the ICU. In: 2015 Computing in Cardiology Conference (CinC). IEEE; 2015. p. 273&#x02013;276.</mixed-citation></ref><ref id="pone.0226990.ref026"><label>26</label><mixed-citation publication-type="other">Li AS, Johnson AE, Mark RG. False arrhythmia alarm reduction in the intensive care unit. arXiv preprint arXiv:170903562. 2017;.</mixed-citation></ref><ref id="pone.0226990.ref027"><label>27</label><mixed-citation publication-type="journal">
<name><surname>Ansari</surname><given-names>S</given-names></name>, <name><surname>Belle</surname><given-names>A</given-names></name>, <name><surname>Ghanbari</surname><given-names>H</given-names></name>, <name><surname>Salamango</surname><given-names>M</given-names></name>, <name><surname>Najarian</surname><given-names>K</given-names></name>. <article-title>Suppression of false arrhythmia alarms in the ICU: a machine learning approach</article-title>. <source>Physiological measurement</source>. <year>2016</year>;<volume>37</volume>(<issue>8</issue>):<fpage>1186</fpage>
<pub-id pub-id-type="doi">10.1088/0967-3334/37/8/1186</pub-id>
<pub-id pub-id-type="pmid">27454017</pub-id></mixed-citation></ref><ref id="pone.0226990.ref028"><label>28</label><mixed-citation publication-type="journal">
<name><surname>Afghah</surname><given-names>F</given-names></name>, <name><surname>Razi</surname><given-names>A</given-names></name>, <name><surname>Soroushmehr</surname><given-names>R</given-names></name>, <name><surname>Ghanbari</surname><given-names>H</given-names></name>, <name><surname>Najarian</surname><given-names>K</given-names></name>. <article-title>Game Theoretic Approach for Systematic Feature Selection; Application in False Alarm Detection in Intensive Care Units</article-title>. <source>Entropy</source>. <year>2018</year>;<volume>20</volume>(<issue>3</issue>):<fpage>190</fpage>
<pub-id pub-id-type="doi">10.3390/e20030190</pub-id></mixed-citation></ref></ref-list></back></article>