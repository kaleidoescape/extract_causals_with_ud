<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">31923217</article-id><article-id pub-id-type="pmc">6953814</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0226912</article-id><article-id pub-id-type="publisher-id">PONE-D-19-16185</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Computer Vision</subject><subj-group><subject>Target Detection</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Agriculture</subject><subj-group><subject>Crop Science</subject><subj-group><subject>Crops</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Mechanical Engineering</subject><subj-group><subject>Robotics</subject><subj-group><subject>Robots</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Imaging Techniques</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Equipment</subject><subj-group><subject>Optical Equipment</subject><subj-group><subject>Cameras</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Technology Development</subject><subj-group><subject>Prototypes</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Signal Processing</subject><subj-group><subject>Image Processing</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Research on motion planning for an indoor spray arm based on an improved potential field method</article-title><alt-title alt-title-type="running-head">Motion planning for indoor spraying arm</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4918-8708</contrib-id><name><surname>Zhao</surname><given-names>Dongjie</given-names></name><role content-type="http://credit.casrai.org/">Software</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="corresp" rid="cor001">*</xref></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Bin</given-names></name><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff002"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Zhao</surname><given-names>Ying</given-names></name><role content-type="http://credit.casrai.org/">Software</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Sun</surname><given-names>Qun</given-names></name><role content-type="http://credit.casrai.org/">Software</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Chuanjun</given-names></name><role content-type="http://credit.casrai.org/">Validation</role><xref ref-type="aff" rid="aff002"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Chong</given-names></name><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib></contrib-group><aff id="aff001"><label>1</label>
<addr-line>School of Mechanical &#x00026; Automotive Engineering, Liaocheng University, Liaocheng, China</addr-line></aff><aff id="aff002"><label>2</label>
<addr-line>College of Engineering, China Agricultural University, Beijing, China</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Lv</surname><given-names>Chen</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1"><addr-line>Nanyang Technological University, SINGAPORE</addr-line></aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>zdj1977@126.com</email></corresp></author-notes><pub-date pub-type="epub"><day>10</day><month>1</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>15</volume><issue>1</issue><elocation-id>e0226912</elocation-id><history><date date-type="received"><day>16</day><month>6</month><year>2019</year></date><date date-type="accepted"><day>6</day><month>12</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; 2020 Zhao et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Zhao et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0226912.pdf"/><abstract><p>The target spraying effect of spray robots mainly depends on the control performance of the spraying arm during the processes of aiming and tracking. To further improve the robustness of the endpoint control and positioning accuracy of the spray arm, an improved potential field algorithm for the motion planning and control of the spray arm is proposed based on prophase research. The algorithm introduces a velocity potential field, visual field constraints and joint position limit constraints into the traditional artificial potential field method. The velocity potential field is used to ensure that the target state of the spraying arm is at the same velocity as the target crop (relative velocity) to achieve stable target tracking. The visual field constraints and joint position limit constraints are utilized to ensure the efficiency of the visual servo control and the movement of the spray arm. The algorithm can plan a feasible trajectory for the spraying arm in Cartesian space and image space, and use the speed controller to control the spraying arm movement along the trajectory for aiming and tracking. Simulation analysis shows that the algorithm can plan better motion trajectories than the servo controller based on image moments in previous studies. In addition, the experimental results show that the algorithm can effectively improve the robustness of targeting and tracking control for the spray robot.</p></abstract><funding-group><award-group id="award001"><funding-source><institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100005153</institution-id><institution>China National Funds for Distinguished Young Scientists</institution></institution-wrap></funding-source><award-id>60703192</award-id><principal-award-recipient><name><surname>Zhao</surname><given-names>Ying</given-names></name></principal-award-recipient></award-group><award-group id="award002"><funding-source><institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100012470</institution-id><institution>Doctoral Program Foundation of Institutions of Higher Education of China</institution></institution-wrap></funding-source><award-id>20120008110046</award-id><principal-award-recipient><name><surname>Zhang</surname><given-names>Bin</given-names></name></principal-award-recipient></award-group><award-group id="award003"><funding-source><institution>A Project of Shandong Province Higher Educational Science and Technology Program</institution></funding-source><award-id>KJ2018BBB032</award-id><principal-award-recipient><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4918-8708</contrib-id><name><surname>Zhao</surname><given-names>Dongjie</given-names></name></principal-award-recipient></award-group><funding-statement>The work presented in this paper was carried out thanks to the support of the National Natural Science Foundation of China [grant number 60703192]; A Project of Shandong Province Higher Educational Science and Technology Program [grant number KJ2018BBB032]; and the Doctoral Program Foundation of Institutions of Higher Education of China [grant number 20120008110046]. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><fig-count count="13"/><table-count count="1"/><page-count count="19"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All relevant data are within the manuscript and its Supporting Information files.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All relevant data are within the manuscript and its Supporting Information files.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>For crops planted in a greenhouse environment with large plant spacing, such as cucurbit seedlings and lettuce seedlings in the early growing season, it is important to use target spraying technology to apply fertilizers and pesticides according to their position and size. In addition, it is of significance to improve the utilization rate of medicinal liquids and to alleviate soil pollution. Introducing a visual servo control into the spraying robot system and using the visual information obtained from the visual sensor to guide the spraying arm to complete the target movement, can satisfy the accuracy requirements of target operation and improve the adaptability of the spraying robot in unstructured environments (e.g., greenhouses) [<xref rid="pone.0226912.ref001" ref-type="bibr">1</xref>&#x02013;<xref rid="pone.0226912.ref005" ref-type="bibr">5</xref>].</p><p>It was found in reference [<xref rid="pone.0226912.ref006" ref-type="bibr">6</xref>] that spray robots can achieve a good target effect by using the visual tracking method based on image moments and a hybrid vision system that includes a monocular scene camera and a monocular (or multi) eye-in-hand camera. However, for the servo control of the spray arm, when the initial pose and the desired pose are quite different, the motion trajectory planned only by the speed controller is poor, which limits the speed of the spraying robot. Furthermore, the vibration of the spray robot caused by occasional larger undulations or obstacles on smooth greenhouse pavement will cause target crops to leave the field of view of the eye-in-hand camera, and the servo process will sometimes fail.</p><p>Meanwhile, the joint manipulator has a faster response speed and a more irregular workspace than the Cartesian-coordinate manipulator, and its irregular workspace has some restrictions on the motion trajectory of the manipulator [<xref rid="pone.0226912.ref007" ref-type="bibr">7</xref>&#x02013;<xref rid="pone.0226912.ref008" ref-type="bibr">8</xref>]. Therefore, it is necessary to optimize the visual servo process by adding various constraints, and applying the path planning method to reasonably control the motion of the manipulator.</p><p>The common methods in the trajectory planning include genetic algorithm [<xref rid="pone.0226912.ref009" ref-type="bibr">9</xref>&#x02013;<xref rid="pone.0226912.ref010" ref-type="bibr">10</xref>], simulated annealing [<xref rid="pone.0226912.ref011" ref-type="bibr">11</xref>&#x02013;<xref rid="pone.0226912.ref012" ref-type="bibr">12</xref>], artificial neural network [<xref rid="pone.0226912.ref013" ref-type="bibr">13</xref>&#x02013;<xref rid="pone.0226912.ref014" ref-type="bibr">14</xref>], A* algorithm [<xref rid="pone.0226912.ref015" ref-type="bibr">15</xref>], vector field method [<xref rid="pone.0226912.ref016" ref-type="bibr">16</xref>], adaptive algorithm [<xref rid="pone.0226912.ref017" ref-type="bibr">17</xref>&#x02013;<xref rid="pone.0226912.ref018" ref-type="bibr">18</xref>], particle swarm optimization algorithm [<xref rid="pone.0226912.ref019" ref-type="bibr">19</xref>&#x02013;<xref rid="pone.0226912.ref020" ref-type="bibr">20</xref>], artificial potential field method [<xref rid="pone.0226912.ref021" ref-type="bibr">21</xref>&#x02013;<xref rid="pone.0226912.ref022" ref-type="bibr">22</xref>], etc. Among these algorithms, the artificial potential field method has a simple structure, is convenient for real-time control on hardware entities, and can usually plan smoother and safer paths. This method has been widely used in real-time obstacle avoidance and smooth trajectory control [<xref rid="pone.0226912.ref023" ref-type="bibr">23</xref>&#x02013;<xref rid="pone.0226912.ref025" ref-type="bibr">25</xref>]. However, the algorithm also has some shortcomings, such as goal nonreachable with obstacle nearby (abbr. GNRON) and an insufficient dynamic path planning ability [<xref rid="pone.0226912.ref026" ref-type="bibr">26</xref>], which can be improved together with specific problems.</p><p>In this paper, the traditional artificial potential field method is appropriately improved according to visual tracking and target requirements of the spray arm, and the improved algorithm is used to plan the motion trajectory of the spray arm under the conditions of visual field constraints and joint limit constraints. The effect is verified by simulation and prototype tests.</p></sec><sec id="sec002"><title>Target spray arm and target operation</title><sec id="sec003"><title>System scheme for target spray robot</title><p>A hybrid vision structure similar to that in reference [<xref rid="pone.0226912.ref006" ref-type="bibr">6</xref>], including one scene camera and one (or several) eye-in-hand camera, is adopted by the target spray robot (<xref ref-type="fig" rid="pone.0226912.g001">Fig 1</xref>). The scene camera, mounted in the front of the robot body, is used to obtain location information about the object crops. The eye-in-hand camera, mounted at the end of the spray arm with the nozzle, is used to provide precise localization of the target crop. The control system consists of one personal computer (abbr. PC, host computer) and one(or several) digital signal processor (abbr. DSP, slave computer). The PC generates and transmits control instructions to the DSP by analyzing the scene camera images and real-time state information of the working parts (spray arm, nozzle, etc.) provided by the DSP. The DSP controls the movement of the spray arm and nozzle according to the PC instructions, the eye-in-hand camera images and the other sensors.</p><fig id="pone.0226912.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g001</object-id><label>Fig 1</label><caption><title>Target spraying robot system.</title><p>1. Nozzle 2. Eye-in-hand camera 3. Spray arm 4. Scene camera 5. Slave computer (DSP, not shown) 6. Host computer (PC) 7. Movement platform 8. Target crop 9. Object crop 10. Robot&#x02019;s motion direction.</p></caption><graphic xlink:href="pone.0226912.g001"/></fig><p>A ZUTO460 4-DOF series manipulator is selected to be the spray arm. The manipulator can achieve the movement along X-axis, Y-axis, Z-axis and the rotation along Z-axis of the end-effector, which meets the requirements of the translational motion of the nozzle in vertical spray mode, and is suitable for fertilization and pesticide application for many greenhouse crops. Furthermore, compared with the Cartesian coordinate manipulator in reference [<xref rid="pone.0226912.ref006" ref-type="bibr">6</xref>], the manipulator has a larger working space and a faster moving speed, and thus, more easily meets the target requirements when the robot moves more quickly.</p><p>The process of the spray arm guiding the nozzle to a target spray along with the forward motion of the spray robot can be described as follows: first, the control system, according to the position information about the object crops provided by the scene camera, controls the spray arm movement to make the crops enter smoothly into the eye-in-hand camera&#x02019;s view. Then, according to precise information about the target crop provided by the eye-in-hand camera, the control system controls the spray arm to move the nozzle quickly into spray position (target) and ensures the relative position between the nozzle and the target crop is unchanged (tracking spray). It is easy to understand that the effect of target spray is mainly determined by the visual servo control accuracy of the spray arm during the targeting and tracking stage.</p></sec><sec id="sec004"><title>Description of target operation issue</title><p>The spray arm needs to guide the nozzle to fulfill target and tracking spray operations during the forward movement of the spray robot. Regarding path planning, the motion of the nozzle during the targeting stage can be regarded as point to point movement, and it is necessary to ensure that the trajectory of the nozzle is smooth, and the path is short. The motion of the nozzle during the tracking spray stage can be regarded as continuous path movement, so that the nozzle must stably and accurately track the motion trajectories of the target crop relative to the spray robot. Moreover, to avoid the failure of the visual servo, the target crop should always be in the field of the eye-in-hand camera, and the planned targeting and tracking trajectories need to satisfy the spray arm&#x02019;s workspace, which is an irregular polyhedron due to structural constraints.</p><p>To solve above problems, a path-planning and visual tracking method based on an improved artificial potential field is proposed. The basic idea is that, based on the traditional artificial potential field, velocity potential field is introduced to meet the needs of stable tracking; in addition, field of view constraint and joint position limit constraints are introduced to ensure the validity of the servo control and the motion of the spray arm. Thus, a feasible trajectory is planned in Cartesian space and image space, and the image-based visual servo method is used to track the trajectory.</p></sec></sec><sec id="sec005"><title>Trajectory planning and target control based on the improved potential field method</title><sec id="sec006"><title>Traditional artificial potential field method</title><p>The traditional artificial potential field method regards the motion of a robot in planned space as a kind of motion in a virtual force field. Target points attract the robot, while obstacles or threat areas repel it, and it moves toward the target points under the action of a composition force. The traditional gravitational field U<sub><italic>att</italic></sub> and the repulsive force field U<sub><italic>rep</italic></sub> are usually defined as
<disp-formula id="pone.0226912.e001"><alternatives><graphic xlink:href="pone.0226912.e001.jpg" id="pone.0226912.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mi>&#x003b1;</mml:mi><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></alternatives><label>(1)</label></disp-formula>
<disp-formula id="pone.0226912.e002"><alternatives><graphic xlink:href="pone.0226912.e002.jpg" id="pone.0226912.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mrow><mml:msub><mml:mtext>U</mml:mtext><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0.5</mml:mn><mml:mi>&#x003b2;</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>&#x003c1;</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>&#x003c1;</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&#x02265;</mml:mo><mml:msub><mml:mi>&#x003c1;</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives><label>(2)</label></disp-formula>
where</p><p><bold><italic>P</italic></bold>&#x02014;&#x02014;current position vector of the robot</p><p><bold><italic>P</italic></bold><sub><italic>t</italic></sub>&#x02014;&#x02014;position vector of a target point</p><p><bold><italic>P</italic></bold><sub><italic>o</italic></sub>&#x02014;&#x02014;position vector of the closest point between an obstacle and the robot</p><p><italic>&#x003c1;</italic><sub>0</sub>&#x02014;&#x02014;influence distance of the obstacle repulsion field, <italic>mm</italic></p><p><italic>&#x003b1;</italic>, <italic>&#x003b2;</italic>&#x02014;&#x02014;positive proportional gain coefficient of gravity and repulsion</p><p>Gravity <bold><italic>F</italic></bold><sub><italic>att</italic></sub> and repulsion <bold><italic>F</italic></bold><sub><italic>rep</italic></sub> are equal to the negative gradients of U<sub><italic>att</italic></sub> and U<sub><italic>rep</italic></sub> respectively, while the virtual force on the robot <bold><italic>F</italic></bold> is the sum of the two vectors.
<disp-formula id="pone.0226912.e003"><alternatives><graphic xlink:href="pone.0226912.e003.jpg" id="pone.0226912.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mo>&#x02207;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>-</mml:mo><mml:mo>&#x02207;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives><label>(3)</label></disp-formula></p><p specific-use="continuation">where</p><p>&#x02207;&#x02014;&#x02014;Laplacian operator</p><p>The artificial potential field method can iteratively plan the discrete trajectory of the robot. The virtual force F determines the motion direction of the robot in the next time step:
<disp-formula id="pone.0226912.e004"><alternatives><graphic xlink:href="pone.0226912.e004.jpg" id="pone.0226912.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">k</mml:mi><mml:mo>+</mml:mo><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">&#x003b5;</mml:mi><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:math></alternatives><label>(4)</label></disp-formula></p><p specific-use="continuation">where</p><p><bold><italic>P</italic></bold><sub><bold><italic>k</italic></bold></sub>&#x02014;&#x02014;current position vector of the robot</p><p><bold><italic>P</italic></bold><sub><bold>k+1</bold></sub>&#x02014;&#x02014;current position vector of the robot in the next time step</p><p><bold><italic>&#x003b5;</italic></bold>&#x02014;&#x02014;iterative step size</p></sec><sec id="sec007"><title>Improved method</title><p>During the process of targeting and tracking spray, the spray robot keeps moving forward, which is identical to the situation in which the robot remains still and the target crop keeps moving back, that is, the situation in which the target is moving. Since the traditional artificial potential field model does not consider the speed factor, the planned path is prone to oscillation when tracking moving targets. That is, this method can only achieve a fast approach to moving targets, but it is difficult to stably track objects. Therefore, a velocity term is introduced into the gravitational field function to make the target state of the spray arm move at the same speed as the target crop.</p><p>Although greenhouse pavement is relatively flat, there are still occasional large fluctuations or obstacles, which may cause the target crop to escape the field of view of the hand-eye camera, and the servo process to fail in some cases. Therefore, field of view constraints are introduced, that is, the four boundaries of the field of view are regarded as obstacles. In addition, due to structural constraints, the joints of the waist and arm of the spray arm can only be rotated in specific ranges, and the limit positions on both sides of the ranges should also be regarded as obstacles.</p><p>The above gravitational and repulsive terms are defined in different description spaces. In particular, the four boundaries of the field of view are defined in image space, the limit positions of the joints are defined in joint space, the velocity term of the gravitational field is defined in Cartesian space, and its location term is defined in image space (according to reference [<xref rid="pone.0226912.ref006" ref-type="bibr">6</xref>], the expected spray position of the target crop is determined by its image moment). If the artificial potential field method is used to plan the trajectory, the virtual forces should be transformed into the same description space. In this paper, the method described in reference [<xref rid="pone.0226912.ref027" ref-type="bibr">27</xref>] is applied to transform the virtual forces between different descriptive spaces. Thus, if the potential field function U<sub><italic>f</italic></sub> = U(<italic>f</italic>(<bold><italic>P</italic></bold>)), and <italic>f</italic>(<bold><italic>P</italic></bold>) is continuously differentiable in the feasible region of <bold><italic>P</italic></bold>, then the virtual force <bold><italic>F</italic></bold><sub><bold><italic>f</italic></bold></sub> can be expressed as
<disp-formula id="pone.0226912.e005"><alternatives><graphic xlink:href="pone.0226912.e005.jpg" id="pone.0226912.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02207;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math></alternatives><label>(5)</label></disp-formula></p><p specific-use="continuation">where</p><p><inline-formula id="pone.0226912.e006"><alternatives><graphic xlink:href="pone.0226912.e006.jpg" id="pone.0226912.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi mathvariant="normal">P</mml:mi></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> &#x02014;&#x02014; the inverse (or pseudo inverse) of partial derivative <inline-formula id="pone.0226912.e030"><alternatives><graphic xlink:href="pone.0226912.e030.jpg" id="pone.0226912.e030g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M30"><mml:mfrac><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi mathvariant="normal">P</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula></p><p>On the premise of satisfying the field of view and joint limit constraints, the improved artificial potential field method is applied to plan the discrete trajectory of the camera in Cartesian space, which then is mapped into image space and tracked with the image-based visual servo controller.</p></sec><sec id="sec008"><title>Gravitational potential field and gravitation</title><p>To stably track the target crop and avoid oscillation, a velocity term is introduced into the gravitational potential field, and the gravitational potential field function is defined as
<disp-formula id="pone.0226912.e007"><alternatives><graphic xlink:href="pone.0226912.e007.jpg" id="pone.0226912.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup><mml:mo>-</mml:mo><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo>+</mml:mo><mml:mn>0.5</mml:mn><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></alternatives><label>(6)</label></disp-formula></p><p specific-use="continuation">where</p><p>s&#x02014;&#x02014;image moment vector of the target crop <inline-formula id="pone.0226912.e008"><alternatives><graphic xlink:href="pone.0226912.e008.jpg" id="pone.0226912.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi mathvariant="normal">k</mml:mi><mml:msqrt><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo>&#x003bc;</mml:mo></mml:mrow><mml:mrow><mml:mn>20</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>&#x003bc;</mml:mo></mml:mrow><mml:mrow><mml:mn>02</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:msqrt><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, (pixel, pixel, pixel)</p><p>s*&#x02014;&#x02014;expected value of s, (pixel, pixel, pixel)</p><p>v<sub>t</sub>&#x02014;&#x02014;relative velocity of the target crop, mm/s</p><p>v&#x02014;&#x02014;velocity of the end of the spray arm(or the eye-in-hand camera), mm/s</p><p><italic>&#x003b1;</italic><sub>1</sub>, &#x003b1;<sub>2</sub>&#x02014;&#x02014;positive proportional gain coefficient</p><p>The negative gradients of U<sub><italic>att</italic></sub>(<bold><italic>s</italic></bold>, <bold><italic>v</italic></bold>) relative to <bold><italic>s</italic></bold> and <bold><italic>v</italic></bold> can be called the relative position gravity <bold><italic>F</italic></bold><sub><italic>atts</italic></sub> and the relative velocity gravity <bold><italic>F</italic></bold><sub><italic>attv</italic></sub>, respectively, and
<disp-formula id="pone.0226912.e009"><alternatives><graphic xlink:href="pone.0226912.e009.jpg" id="pone.0226912.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mo>&#x02207;</mml:mo></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">L</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:mo>-</mml:mo><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives><label>(7)</label></disp-formula>
<disp-formula id="pone.0226912.e010"><alternatives><graphic xlink:href="pone.0226912.e010.jpg" id="pone.0226912.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mo>&#x02207;</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mo>)</mml:mo></mml:math></alternatives><label>(8)</label></disp-formula>
<disp-formula id="pone.0226912.e011"><alternatives><graphic xlink:href="pone.0226912.e011.jpg" id="pone.0226912.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo></mml:math></alternatives><label>(9)</label></disp-formula></p><p specific-use="continuation">where</p><p><inline-formula id="pone.0226912.e012"><alternatives><graphic xlink:href="pone.0226912.e012.jpg" id="pone.0226912.e012g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M12"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">L</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>&#x02014;&#x02014;inverse matrix of the image Jacobian matrix related to <bold><italic>s</italic></bold></p><p><bold><italic>F</italic></bold><sub><italic>att</italic></sub>(<bold><italic>P</italic></bold>)<bold>&#x02014;</bold>&#x02014;virtual resultant gravity</p><p>The function of F<sub>atts</sub>(P) makes the spray arm move along the shortest path to the desired spray position, its direction is from the current position to the desired position and its size is proportional to the relative position. The function of <bold><italic>F</italic></bold><sub><italic>attv</italic></sub>(<bold><italic>P</italic></bold>) makes the target state of the spray arm move at the same speed as the target crop; its direction is the motion direction of the target crop relative to the spray arm, and is proportional to the relative velocity. When the spray arm is aligned with the desired spray location and the relative velocity between the spray arm and the target crop is 0, <bold><italic>F</italic></bold><sub><italic>att</italic></sub>(<bold><italic>P</italic></bold>) = 0.</p></sec><sec id="sec009"><title>Repulsion field and repulsion force of field of view constraint</title><p>Suppose the crop image will be kept in the camera&#x02019;s view while the centroid of the crop image k<sub>0</sub>(u<sub>0</sub>, v<sub>0</sub>) is in region M of the camera&#x02019;s view (M&#x02019;s boundary is u<sub>min</sub>, u<sub>max</sub>, v<sub>min</sub>, v<sub>max</sub>). Let d be the influence distance of the boundary of the field of view (<xref ref-type="fig" rid="pone.0226912.g002">Fig 2</xref>).</p><fig id="pone.0226912.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g002</object-id><label>Fig 2</label><caption><title>The visual field of the eye-in-hand camera.</title></caption><graphic xlink:href="pone.0226912.g002"/></fig><p>To prevent k<sub>0</sub> from escaping from M, k<sub>0</sub> should be repulsed to return to safe region M<sub>0</sub> when it moves in M<sub>l</sub>, M<sub>r</sub>, M<sub>t</sub> and M<sub>b</sub>. By introducing logarithmic terms into the repulsive field function, the repulsive force tends to be infinite when <italic>k</italic><sub>0</sub> approaches the boundary of the camera&#x02019;s view. The repulsion field function is (<xref ref-type="fig" rid="pone.0226912.g003">Fig 3</xref>):
<disp-formula id="pone.0226912.e013"><alternatives><graphic xlink:href="pone.0226912.e013.jpg" id="pone.0226912.e013g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M13"><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mo>+</mml:mo><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives><label>(10)</label></disp-formula>
where
<disp-formula id="pone.0226912.e014"><alternatives><graphic xlink:href="pone.0226912.e014.jpg" id="pone.0226912.e014g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M14"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>d</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>d</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>d</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
<disp-formula id="pone.0226912.e015"><alternatives><graphic xlink:href="pone.0226912.e015.jpg" id="pone.0226912.e015g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M15"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>d</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>d</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>v</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>d</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>v</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>v</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula></p><fig id="pone.0226912.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g003</object-id><label>Fig 3</label><caption><title>The repulsion field of the visual field constraint.</title></caption><graphic xlink:href="pone.0226912.g003"/></fig><p>The repulsive force <bold><italic>F</italic></bold><sub><italic>repv</italic></sub> (as shown in <xref ref-type="fig" rid="pone.0226912.g004">Fig 4</xref>, the length and direction of the arrow represents the magnitude and direction of the repulsion force, respectively) of the field of view of the spray arm can be expressed as
<disp-formula id="pone.0226912.e016"><alternatives><graphic xlink:href="pone.0226912.e016.jpg" id="pone.0226912.e016g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M16"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02209;</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives><label>(11)</label></disp-formula></p><fig id="pone.0226912.g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g004</object-id><label>Fig 4</label><caption><title>The repulsive force of the visual field constraint.</title></caption><graphic xlink:href="pone.0226912.g004"/></fig></sec><sec id="sec010"><title>Repulsion field and repulsion force of joint limits</title><p>The three joint variables of the spray arm have certain a rotation range. Suppose <italic>q</italic><sub><italic>i</italic></sub> &#x02208; (<italic>q</italic><sub><italic>imin</italic></sub>, <italic>q</italic><sub><italic>imax</italic></sub>), <italic>i</italic> = 1, 2, 3, and &#x003b8; is the influence distance of the joint limit position. As a view constraint, the repulsion field of the joint limit is defined as follows.
<disp-formula id="pone.0226912.e017"><alternatives><graphic xlink:href="pone.0226912.e017.jpg" id="pone.0226912.e017g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M17"><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(12)</label></disp-formula>
where
<disp-formula id="pone.0226912.e018"><alternatives><graphic xlink:href="pone.0226912.e018.jpg" id="pone.0226912.e018g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M18"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula></p><p>Suppose &#x00393; = {q<sub>i</sub> &#x02208; [q<sub>imin</sub> + &#x003b8;, q<sub>imax</sub> &#x02212; &#x003b8;], i = 1,2,3}. The repulsion force of the spray arm&#x02019;s joint limit F<sub>repq</sub> can be expressed as
<disp-formula id="pone.0226912.e019"><alternatives><graphic xlink:href="pone.0226912.e019.jpg" id="pone.0226912.e019g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M19"><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mtext>L</mml:mtext><mml:mtext>r</mml:mtext></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>F</mml:mtext><mml:mrow><mml:mtext>repq</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>q</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mtext>F</mml:mtext><mml:mrow><mml:mtext>repq</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>q</mml:mtext><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mtext>F</mml:mtext><mml:mrow><mml:mtext>repq</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>q</mml:mtext><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mtext>T</mml:mtext></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mspace width="4pt"/><mml:mtext>q</mml:mtext><mml:mo>&#x02209;</mml:mo><mml:mo>&#x00393;</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mspace width="4pt"/><mml:mtext>q</mml:mtext><mml:mo>&#x02208;</mml:mo><mml:mo>&#x00393;</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></alternatives><label>(13)</label></disp-formula></p><p specific-use="continuation">where</p><p><bold>L</bold><sub><italic>r</italic></sub>&#x02014;&#x02014;Jacobi matrix of the spray arm
<disp-formula id="pone.0226912.e020"><alternatives><graphic xlink:href="pone.0226912.e020.jpg" id="pone.0226912.e020g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M20"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mo>&#x02207;</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula></p></sec><sec id="sec011"><title>Trajectory planning method</title><p>According to the gravitational and repulsive forces defined above, the resultant force of the spray arm in Cartesian space should be
<disp-formula id="pone.0226912.e021"><alternatives><graphic xlink:href="pone.0226912.e021.jpg" id="pone.0226912.e021g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M21"><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x003b2;</mml:mi><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b3;</mml:mi><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo></mml:math></alternatives><label>(14)</label></disp-formula></p><p specific-use="continuation">where</p><p><italic>&#x003b2;</italic>, <italic>&#x003b3;</italic>&#x02014;&#x02014;scaling factors.</p><p>The proportion of each component in F(P) can be changed by adjusting the values of &#x003b2; and &#x003b3;.</p><p>A feasible discrete trajectory for the eye-in-hand camera &#x00393; = {P<sub>k</sub>|k = 0,1, &#x022ef; n} can be planned in Cartesian space by using F(P) and <xref ref-type="disp-formula" rid="pone.0226912.e022">Eq (15)</xref>.
<disp-formula id="pone.0226912.e022"><alternatives><graphic xlink:href="pone.0226912.e022.jpg" id="pone.0226912.e022g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M22"><mml:msub><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">P</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">P</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:math></alternatives><label>(15)</label></disp-formula></p><p specific-use="continuation">where</p><p>&#x003b5;<sub>k</sub>&#x02014;&#x02014;step size of the kth control cycle</p><p>Further, combined with the eye-in-hand camera model, the values <inline-formula id="pone.0226912.e023"><alternatives><graphic xlink:href="pone.0226912.e023.jpg" id="pone.0226912.e023g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M23"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> of image moment <inline-formula id="pone.0226912.e024"><alternatives><graphic xlink:href="pone.0226912.e024.jpg" id="pone.0226912.e024g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M24"><mml:mi mathvariant="normal">s</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mi mathvariant="normal">k</mml:mi><mml:msqrt><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo>&#x003bc;</mml:mo></mml:mrow><mml:mrow><mml:mn>20</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>&#x003bc;</mml:mo></mml:mrow><mml:mrow><mml:mn>02</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:msqrt></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> corresponding to each trajectory point P<sub>k</sub> can be calculated. That is, a corresponding discrete trajectory in the image space <inline-formula id="pone.0226912.e025"><alternatives><graphic xlink:href="pone.0226912.e025.jpg" id="pone.0226912.e025g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M25"><mml:mi mathvariant="normal">&#x003a7;</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mi mathvariant="normal">k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:math></alternatives></inline-formula> is obtained.</p></sec><sec id="sec012"><title>Controller design</title><p>The image-based visual servo controller is used to track this trajectory. Suppose that in the <italic>k</italic> th control cycle, the error of the image features is defined as:
<disp-formula id="pone.0226912.e026"><alternatives><graphic xlink:href="pone.0226912.e026.jpg" id="pone.0226912.e026g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M26"><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">*</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives><label>(16)</label></disp-formula></p><p>A speed controller is selected to exponentially decrease the error. According to reference [<xref rid="pone.0226912.ref028" ref-type="bibr">28</xref>], the controller can be selected as
<disp-formula id="pone.0226912.e027"><alternatives><graphic xlink:href="pone.0226912.e027.jpg" id="pone.0226912.e027g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M27"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mo>&#x002d9;</mml:mo></mml:mover></mml:math></alternatives><label>(17)</label></disp-formula></p><p specific-use="continuation">where</p><p><inline-formula id="pone.0226912.e028"><alternatives><graphic xlink:href="pone.0226912.e028.jpg" id="pone.0226912.e028g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M28"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>&#x02014;&#x02014;pseudo-inverse of estimation of image Jacobian matrix <bold><italic>L</italic></bold><sub><italic>s</italic></sub>.</p><p>The visual system block diagram is shown in <xref ref-type="fig" rid="pone.0226912.g005">Fig 5</xref>. According to reference [<xref rid="pone.0226912.ref016" ref-type="bibr">16</xref>], the controller can make the system robust to model error and noise disturbance.</p><fig id="pone.0226912.g005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g005</object-id><label>Fig 5</label><caption><title>Block diagram of the proposed visual control system.</title></caption><graphic xlink:href="pone.0226912.g005"/></fig></sec></sec><sec id="sec013"><title>Simulation analysis</title><p>The above visual servo motion planning method based on the improved potential field method is validated by simulation in MATLAB software. The camera adopted a perspective projection model with a resolution of 1000 *1000 and a focal length of 10mm. Suppose that the spray robot moves at the speed of <italic>v</italic><sub><italic>hx</italic></sub> = 0.02m/s, <italic>v</italic><sub><italic>hy</italic></sub> = 0.3m/s and <italic>v</italic><sub><italic>hz</italic></sub> = 0m/s. A crop image parallel to the eye-in-hand camera plane, is selected after background segmentation and binarization as the target crop. The projection of the target crop at initial position and the desired spray position are shown in <xref ref-type="fig" rid="pone.0226912.g006">Fig 6</xref>. At the desired position, the canopy&#x02019;s depth of the target crop is <italic>Z</italic>* = 0.49<italic>m</italic>, and <bold><italic>S</italic></bold> = [493 582 262]<sup><italic>T</italic></sup>. Suppose that the spray robot stands still, and the target crop moves toward it.</p><fig id="pone.0226912.g006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g006</object-id><label>Fig 6</label><caption><title>Simulation image.</title><p>(A) Initial position. (B) Desired position.</p></caption><graphic xlink:href="pone.0226912.g006"/></fig><sec id="sec014"><title>(1) Effect of adding gravitational field</title><p><xref ref-type="fig" rid="pone.0226912.g007">Fig 7</xref> shows a simulation comparison of the planned trajectories between the potential field method with only a gravitational potential term and the image moment method in reference [<xref rid="pone.0226912.ref006" ref-type="bibr">6</xref>]. It can be seen that the nozzle&#x02019;s trajectory in image space of the former is obviously better than that of the latter, and the nozzle&#x02019;s trajectory in Cartesian space of the former is shorter and more reasonable than that of the latter.</p><fig id="pone.0226912.g007" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g007</object-id><label>Fig 7</label><caption><title>Results of introducing gravitational field.</title><p>(A) Motion trajectory in image space. (B) Motion trajectory in Cartesian space. Where the simulation result of potential field method is designated with a blue solid line, and the simulation result of image moment method is designated with a black dash-dotted line.</p></caption><graphic xlink:href="pone.0226912.g007"/></fig></sec><sec id="sec015"><title>(2) Effect of adding field of view constraints</title><p>The field boundary corresponding to the centroid k<sub>0</sub>(u<sub>0</sub>, v<sub>0</sub>) of the crop image is set as u<sub>0</sub> &#x02208; [200,800] and v<sub>0</sub> &#x02208; [200,800], and the influence distance of the field boundary is set as 100 pixels. <xref ref-type="fig" rid="pone.0226912.g008">Fig 8</xref> shows a simulation comparison of the planned trajectories between the potential field method with only field of view constraints and the image moment method in reference [<xref rid="pone.0226912.ref006" ref-type="bibr">6</xref>]. It can be seen that the latter can not ensure that the target crop always appears in the field of vision, which may lead to the failure of the servo task, and the former can avoid the problem.</p><fig id="pone.0226912.g008" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g008</object-id><label>Fig 8</label><caption><title>Results of introducing visual field constraints.</title><p>(A) Motion trajectory in image space. (B) Motion trajectory in Cartesian space. Where the simulation result of potential field method is designated with a blue solid line, and the simulation result of image moment method is designated with a black dash-dotted line.</p></caption><graphic xlink:href="pone.0226912.g008"/></fig></sec><sec id="sec016"><title>(3) Effect of adding joint limit constraints</title><p>The joint angle variation range of the waist, upper arm and lower arm joints are set as q<sub>1</sub> &#x02208; (&#x02212;1.7, 0.5)rad, q<sub>2</sub> &#x02208; (&#x02212;2.0, &#x02212;0.2)rad and q<sub>3</sub> &#x02208; (0.9,2.0)rad respectively. The influence distance of the joint limit position is set to 0.3 rad. <xref ref-type="fig" rid="pone.0226912.g009">Fig 9</xref> is a simulation comparison of the planned trajectories between the potential field method with only joint limit constraints and the image moment method in reference [<xref rid="pone.0226912.ref006" ref-type="bibr">6</xref>]. It can be seen that in this case, the trajectory planned by the latter makes the joints of both the waist and the lower arm exceed the setting range, leading to the failure of the servo task, while the trajectory planned by the former can avoid the problem.</p><fig id="pone.0226912.g009" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g009</object-id><label>Fig 9</label><caption><title>Results of introducing joint limit position constraints.</title><p>(A) Image moment method. (B) Potential field method. Where the trajectory of the waist is designated with a blue dotted line, the trajectory of the upper arm is designated with a red dash-dotted line, and the trajectory of the lower arm is designated with a black pecked line.</p></caption><graphic xlink:href="pone.0226912.g009"/></fig></sec><sec id="sec017"><title>(4) Comprehensive effect of the improved potential field method</title><p>The simulation results of the improved potential field method considering all the gravitational and repulsive terms are shown in <xref ref-type="fig" rid="pone.0226912.g010">Fig 10</xref>. <xref ref-type="fig" rid="pone.0226912.g010">Fig 10A</xref> is an error tracking curve of three moment features. It can be seen that all the moment features steadily converge and the target process lasts approximately 13 visual cycles. Influenced by the translation velocity of the robot in the X and Y directions, the errors of the three moment features in the tracking process are approximately &#x02212;3 pixels, &#x02212;4 pixels and 1 pixel, corresponding to position errors at the desired positions of &#x02212;1.5mm, &#x02212;2mm and 0.5mm, respectively. <xref ref-type="fig" rid="pone.0226912.g010">Fig 10B</xref> is velocity of the eye-in-hand camera (or nozzle) in the X, Y and Z directions, which converge to &#x02212;0.02<italic>m</italic>/s, &#x02212;0.3<italic>m</italic>/s and 0<italic>m</italic>/s, respectively, ensuring the target accuracy in the tracking spray stage. <xref ref-type="fig" rid="pone.0226912.g010">Fig 10C and 10D</xref> show the simulation comparison of the planned trajectories for the eye-in-hand camera between the potential field method and the image moment method in reference [<xref rid="pone.0226912.ref006" ref-type="bibr">6</xref>] in Cartesian space and image space, respectively. It can be seen that the trajectories in image space and Cartesian space of the former are obviously better than those of the latter.</p><fig id="pone.0226912.g010" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g010</object-id><label>Fig 10</label><caption><title>Results of the improved potential field method.</title><p>(A) Error tracking curve. Where the error tracking curve of moment feature 1 is designated with a blue dotted line, the error tracking curve of moment feature 2 is designated with a red dash-dotted line, and the error tracking curve of moment feature 3 is designated with a black pecked line. (B) Velocity of the eye-in-hand camera. Where the velocity in X direction is designated with a blue dotted line, the velocity in Y direction is designated with a red dash-dotted line, and the velocity in Z direction is designated with a black pecked line. (C) Motion trajectory in Cartesian space. Where the simulation result of potential field method is designated with a blue solid line, and the simulation result of image moment method is designated with a black dash-dotted line. (D) Motion trajectory in image space. Where the simulation result of potential field method is designated with a blue solid line, and the simulation result of image moment method is designated with a black dash-dotted line.</p></caption><graphic xlink:href="pone.0226912.g010"/></fig></sec></sec><sec id="sec018"><title>Experimental verification</title><p>Based on the preceding studies (reference [<xref rid="pone.0226912.ref006" ref-type="bibr">6</xref>]), an improved prototype (<xref ref-type="fig" rid="pone.0226912.g011">Fig 11</xref>) is built to test the effectiveness of the above motion planning method. The prototype used a ZUTO460-BRG type 4-axis manipulator as the sprayer arm, a Basler acA1300 industrial camera (resolution 1296*966 pixels) as the scene camera and an OV7725 chip network camera (resolution 640*480 pixels) as the eye-in-hand camera. Moreover, a KYD650N5 controllable laser lamp is used instead of a nozzle to measure the target error conveniently in the experiments.</p><fig id="pone.0226912.g011" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g011</object-id><label>Fig 11</label><caption><title>Experimental prototype.</title><p>1. Movement platform 2. Controller, driver, etc. 3. PC 4. Scene camera. 5. Spray arm 6. Eye-in-hand camera 7. Laser.</p></caption><graphic xlink:href="pone.0226912.g011"/></fig><p>The pavement of the greenhouse is relatively flat, and random vibration caused by unevenness is generally small. To facilitate the measurement of the target error in the experiment process, prototype experiments are carried out in a controllable laboratory environment.</p><p>Ten hawthorn leaves are selected as experiment objects. Before the experiment, the centroid for each leaf was marked, and the expected off-ground height of the laser lamp was estimated when targeting according to <italic>h</italic> = <italic>h</italic><sub>1</sub> + 2.8<italic>d</italic> (where <italic>h</italic><sub>1</sub>&#x02014; off-ground height of leaf, <italic>d</italic>&#x02014;diameter of the surrounding circle, the center of which is the centroid of the leaf), as shown in <xref ref-type="fig" rid="pone.0226912.g012">Fig 12</xref>. In the experiment, the laser lamp would be lit during the simulated tracking spray process.</p><fig id="pone.0226912.g012" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g012</object-id><label>Fig 12</label><caption><title>Schematic diagram of target and tracking effects.</title><p>1. Blade 2. Centroid (horizontal expected position) 3. Vertical desired position. 4,5. Horizontal and vertical range of effective target tracking.</p></caption><graphic xlink:href="pone.0226912.g012"/></fig><p>The deviation of the laser lamp&#x02019;s spot relative to the centroid mark during the tracking spray process is taken as the horizontal error <italic>err_h</italic>, and the maximum deviation of the laser lamp&#x02019;s height relative to its desired height is taken as the vertical error <italic>err_v</italic>.</p><p>To quantitatively evaluate the tracking spray&#x02019;s effect, it is stipulated that the horizontal relative error Re_h = |err_h|/d*100%, the vertical relative error Re_h = |err_h|/h*100%, and the tracking spray effect is divided into two kinds: effective tracking spray (Re_h &#x02264; 10% and Re_h &#x02264; 5%) and ineffective tracking spray (Re_h &#x0003e; 10% or Re_v &#x0003e; 5%).</p><p>Image processing and feature extraction are carried out using the method used in reference [<xref rid="pone.0226912.ref006" ref-type="bibr">6</xref>]. The method determines the expected value of the image moment is as follows: manually control the spray arm to move the nozzle into its desired spray location, and record the value of <inline-formula id="pone.0226912.e029"><alternatives><graphic xlink:href="pone.0226912.e029.jpg" id="pone.0226912.e029g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M29"><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>01</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:msqrt><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:mn>20</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:mn>02</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>00</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow><mml:mo>}</mml:mo></mml:math></alternatives></inline-formula> at the moment. The process is repeated five times, the average value is taken as the expected value, and the experiment results showed that the expected value of <bold><italic>S</italic></bold> is {237, 189, 202}.</p><p>During the experiments, the leaves are randomly placed with spacing of approximately 30~50<italic>mm</italic> in the X direction and 400~600<italic>mm</italic> in the Y direction, and several obstacles are set in the path of the prototype to simulate the unevenness of greenhouse pavement. The prototype is controlled to pass the obstacles and simulate target spraying on those leaves by two speeds of 100~150mm/s and 250~300mm/s, and each spray time is set to 0.5s, as shown in <xref ref-type="fig" rid="pone.0226912.g013">Fig 13</xref>.</p><fig id="pone.0226912.g013" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.g013</object-id><label>Fig 13</label><caption><title>Simulated target experiment.</title></caption><graphic xlink:href="pone.0226912.g013"/></fig><p>To compare the control effect of the improved potential field method with the image moment method of reference [<xref rid="pone.0226912.ref006" ref-type="bibr">6</xref>], ten experiments were carried out for each of the two methods. During the experiments, it was found that the value of Re_h was usually less than 4% of that expected for very special cases, such as the incorrect identification of leaves, while Re_h was always greater than 10% in these cases. Therefore, the factor of whether or not Re_h was greater than 10%, was only used to judge the tracking spray effectiveness in the experiment. For ease of judgment, a marked circle was drawn on each leaf with the centroid as the center and a radius of 0.1d. If the laser lamp&#x02019;s spot was always in the marked circle during simulated spraying, the tracking spray was judged to be effective; otherwise, the tracking spray was ineffective.</p><p>The statistical results of effective and ineffective tracking spray in various cases are shown in <xref rid="pone.0226912.t001" ref-type="table">Table 1</xref>. In the table, the effective tracking spray rate = the times of effective tracking spray / the total times of tracking spray * 100%, and the ineffective tracking spray rate = the times of ineffective tracking spray / the total times of tracking spray * 100%.</p><table-wrap id="pone.0226912.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0226912.t001</object-id><label>Table 1</label><caption><title>Statistical table of target and tracking effect.</title></caption><alternatives><graphic id="pone.0226912.t001g" xlink:href="pone.0226912.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">method</th><th align="center" rowspan="1" colspan="1">velocity<break/>(mm/s)</th><th align="center" rowspan="1" colspan="1">effective tracking spray rate (%)</th><th align="center" rowspan="1" colspan="1">ineffective tracking spray rate (%)</th></tr></thead><tbody><tr><td align="center" rowspan="2" colspan="1">Image moment method</td><td align="center" rowspan="1" colspan="1">100&#x02013;150</td><td align="char" char="." rowspan="1" colspan="1">82.7</td><td align="char" char="." rowspan="1" colspan="1">17.3</td></tr><tr><td align="center" rowspan="1" colspan="1">250&#x02013;300</td><td align="char" char="." rowspan="1" colspan="1">50.2</td><td align="char" char="." rowspan="1" colspan="1">49.8</td></tr><tr><td align="center" rowspan="2" colspan="1">Improved potential field method</td><td align="center" rowspan="1" colspan="1">100&#x02013;150</td><td align="char" char="." rowspan="1" colspan="1">94.5</td><td align="char" char="." rowspan="1" colspan="1">5.5</td></tr><tr><td align="center" rowspan="1" colspan="1">250&#x02013;300</td><td align="char" char="." rowspan="1" colspan="1">80.3</td><td align="char" char="." rowspan="1" colspan="1">19.7</td></tr></tbody></table></alternatives></table-wrap><p>The prototype test shows that the improved potential field method has a better tracking control effect than the image moment method in reference [<xref rid="pone.0226912.ref006" ref-type="bibr">6</xref>], and its advantages are more obvious with the increase of the velocity of the prototype. However, the former has higher calculation costs and increases the sampling period by approximately 21%, which is disadvantage and restricts the improvement of the prototype&#x02019;s velocity and target tracking accuracy. In addition, some factors, such as the model error of the prototype system and the deviation between the actual and ideal attitudes of the leaves are still important factors affecting the target tracking accuracy.</p></sec><sec sec-type="conclusions" id="sec019"><title>Conclusion</title><p>To further improve the motion control of the spray arm during the processes of targeting and tracking, and based on previous research about visual tracking methods that used image moments and a hybrid vision structure with a single scene camera and a single (or multi) eye-in-hand camera, a novel algorithm for motion planning and target control is proposed. This novel algorithm is based on an improved potential field algorithm and introduces velocity potential field, field of view constraints and joint position limit constraint based on the traditional artificial potential field. Specifically, the velocity potential field is introduced to achieve stable tracking by making the target state of the spray arm move at the same velocity as the crop (relative velocity). The field of view constraint is introduced to prevent the target crop escape from escaping from the field view of the eye-in-hand camera and to ensure the efficiency of the visual servo control. Joint position limit constraints are introduced to ensure that the planned trajectories of the joints are always within an allowable range. The simulation and experimental results show that the proposed method has a higher tracking accuracy, a better planned path and a higher robustness than the servo controller based on image moments. Future work will extend the motion planning algorithm of the manipulator to other platforms, such as logistics intelligent sorting systems.</p></sec><sec sec-type="supplementary-material" id="sec020"><title>Supporting information</title><supplementary-material content-type="local-data" id="pone.0226912.s001"><label>S1 Fig</label><caption><title>Flow chart of simulation analysis.</title><p>(TIF)</p></caption><media xlink:href="pone.0226912.s001.tif"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0226912.s002"><label>S2 Fig</label><caption><title>Structure diagram of the prototype software system.</title><p>Visual servo control system adopts master-slave control mode. The host computer is a PC, which is responsible for background segmentation and feature extraction of crop images, calculation of spray operation point&#x02019;s position, kinematics calculation of the spray arm, trajectory planning, system management and logic control, etc. PC sends control instructions to the slave computer through serial port. The lower computer adopts an advanced DSP, which is responsible for acquiring and processing the signals of photoelectric switch, driving motors according to the instructions of PC, real-time control on the spray arm, and feedback the running state to PC through serial port.</p><p>(TIF)</p></caption><media xlink:href="pone.0226912.s002.tif"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0226912.s003"><label>S3 Fig</label><caption><title>Flowchart diagram of the prototype software system.</title><p>(TIF)</p></caption><media xlink:href="pone.0226912.s003.tif"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0226912.s004"><label>S1 File</label><caption><title>Estimation method of crop position and platform speed based on scene camera image.</title><p>(DOCX)</p></caption><media xlink:href="pone.0226912.s004.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0226912.s005"><label>S2 File</label><caption><title>Pictures of experiment scene.</title><p>(DOCX)</p></caption><media xlink:href="pone.0226912.s005.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>We would like to thank Hongqiang Guo (Liaocheng University, China) for his helpful advice on manuscript revision.</p></ack><ref-list><title>References</title><ref id="pone.0226912.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Qiu</surname><given-names>BJ</given-names></name>, <name><surname>Yan</surname><given-names>R</given-names></name>, <name><surname>Ma</surname><given-names>J</given-names></name>, <name><surname>Guan</surname><given-names>XP</given-names></name>, <name><surname>Ou</surname><given-names>MX</given-names></name>. <article-title>Research progress analysis of variable rate sprayer technology</article-title>. <source>Transactions of the Chinese Society for Agricultural Machinery</source>. <year>2015</year>; <volume>46</volume>(<issue>3</issue>):<fpage>59</fpage>&#x02013;<lpage>72</lpage>. <pub-id pub-id-type="doi">10.6041/j.issn.1000-1298.2015.03.009</pub-id></mixed-citation></ref><ref id="pone.0226912.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Hong</surname><given-names>SW</given-names></name>, <name><surname>Zhao</surname><given-names>LY</given-names></name>, <name><surname>Zhu</surname><given-names>HP</given-names></name>. <article-title>CFD simulation of pesticide spray from air-assisted sprayers in an apple orchard: Tree deposition and off-target losses</article-title>. <source>Atmospheric Environment</source>. <year>2018</year>;<volume>175</volume>:<fpage>109</fpage>&#x02013;<lpage>119</lpage>. <pub-id pub-id-type="doi">10.1016/j.atmosenv.2017.12.001</pub-id></mixed-citation></ref><ref id="pone.0226912.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>XM</given-names></name>, <name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Li</surname><given-names>M</given-names></name>, <name><surname>Yuan</surname><given-names>J</given-names></name>, <name><surname>Fang</surname><given-names>QZ</given-names></name>, <name><surname>Hou</surname><given-names>JL</given-names></name>. <article-title>Design and test of smart-targeting spraying system on boom Sprayer</article-title>. <source>Transactions of the Chinese Society for Agricultural Machinery</source>. <year>2016</year>
<volume>47</volume>(<issue>3</issue>):<fpage>37</fpage>&#x02013;<lpage>44</lpage>. <pub-id pub-id-type="doi">10.6041/j.issn.1000-1298.2016.03.006</pub-id></mixed-citation></ref><ref id="pone.0226912.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Garcia-Santillan</surname><given-names>I</given-names></name>, <name><surname>Peluffo-Ordonez</surname><given-names>D</given-names></name>, <name><surname>Caranqui</surname><given-names>V</given-names></name>, <name><surname>Pusd&#x000e1;</surname><given-names>M</given-names></name>, <name><surname>Garrido</surname><given-names>F</given-names></name>, <name><surname>Granda</surname><given-names>P</given-names></name>. <article-title>Computer vision-based method for automatic detection of crop rows in potato fields</article-title>. <source>Advances in Intelligent Systems and Computing</source>, <year>2018</year>,<volume>721</volume>:<fpage>355</fpage>&#x02013;<lpage>366</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-319-73450-7_34</pub-id></mixed-citation></ref><ref id="pone.0226912.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Garcia-Santillan</surname><given-names>I</given-names></name>, <name><surname>Montalvo</surname><given-names>M</given-names></name>, <name><surname>Guerrero</surname><given-names>J</given-names></name>, <name><surname>Pajares</surname><given-names>G</given-names></name>. <article-title>Automatic detection of curved and straight crop rows from images in maize fields</article-title>. <source>Biosystems Engineering</source>. <year>2017</year>;<volume>156</volume>:<fpage>61</fpage>&#x02013;<lpage>79</lpage>. <pub-id pub-id-type="doi">10.1016/j.biosystemseng.2017.01.013</pub-id></mixed-citation></ref><ref id="pone.0226912.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Zhao</surname><given-names>DJ</given-names></name>, <name><surname>Zhang</surname><given-names>B</given-names></name>, <name><surname>Wang</surname><given-names>XL</given-names></name>, <name><surname>Guo</surname><given-names>HH</given-names></name>, <name><surname>Xu</surname><given-names>SB</given-names></name>. <article-title>Automatic target research of indoor spray robot based on image moments</article-title>. <source>Transactions of the Chinese Society for Agricultural Machinery</source>. <year>2016</year>;<volume>47</volume>(<issue>12</issue>): <fpage>22</fpage>&#x02013;<lpage>29</lpage>. <pub-id pub-id-type="doi">10.6041/j.issn.1000-1298.2016.12.004</pub-id></mixed-citation></ref><ref id="pone.0226912.ref007"><label>7</label><mixed-citation publication-type="other">Chang WC, Shao CK. Hybrid eye-to-hand and eye-in-hand visual servoing for autonomous robotic manipulation. Sice Conference. IEEE. 2010; 415~422.</mixed-citation></ref><ref id="pone.0226912.ref008"><label>8</label><mixed-citation publication-type="journal"><name><surname>Hua</surname><given-names>CC</given-names></name>, <name><surname>Wang</surname><given-names>YQ</given-names></name>, <name><surname>Guan</surname><given-names>XP</given-names></name>. <article-title>Visual tracking control for an uncalibrated robot system with unknown camera parameters</article-title>. <source>Robotics and Computer-Integrated Manufacturing</source>. <year>2014</year>; <volume>30</volume>(<issue>1</issue>): <fpage>19</fpage>&#x02013;<lpage>24</lpage>. <pub-id pub-id-type="doi">10.1016/j.rcim.2013.06.002</pub-id></mixed-citation></ref><ref id="pone.0226912.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Baizid</surname><given-names>K</given-names></name>, <name><surname>Yousnadj</surname><given-names>A</given-names></name>, <name><surname>Meddahi</surname><given-names>A</given-names></name>, <name><surname>Chellali</surname><given-names>R</given-names></name>, <name><surname>Iqbal</surname><given-names>J</given-names></name>. <article-title>Time scheduling and optimization of industrial robotized tasks based on genetic algorithms</article-title>. <source>Robotics and Computer-integrated Manufacturing</source>, <year>2015</year>, <volume>34</volume>:<fpage>140</fpage>&#x02013;<lpage>150</lpage>. <pub-id pub-id-type="doi">10.1016/j.rcim.2014.12.003</pub-id></mixed-citation></ref><ref id="pone.0226912.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>Zhao</surname><given-names>SP</given-names></name>, <name><surname>Zhu</surname><given-names>ZX</given-names></name>, <name><surname>Luo</surname><given-names>JJ</given-names></name>. <article-title>Multitask-based trajectory planning for redundant space robotics using improved genetic algorithm</article-title>. <source>Applied Sciences</source>, <year>2019</year>,<volume>9</volume>(<issue>11</issue>):<fpage>1</fpage>&#x02013;<lpage>22</lpage>. <pub-id pub-id-type="doi">10.3390/app9112226</pub-id></mixed-citation></ref><ref id="pone.0226912.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>Ning</surname><given-names>Q</given-names></name>, <name><surname>Tao</surname><given-names>GP</given-names></name>, <name><surname>Chen</surname><given-names>BC</given-names></name>, <name><surname>Lei</surname><given-names>YJ</given-names></name>, <name><surname>Yan</surname><given-names>H</given-names></name>, <name><surname>Zhao</surname><given-names>CP</given-names></name>. <article-title>Multi-UAVs trajectory and mission cooperative planning based on the Markov model</article-title>. <source>Physical communication</source>, <year>2019</year>,<volume>35</volume>:<fpage>1</fpage>&#x02013;<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1016/j.phycom.2019.100717</pub-id></mixed-citation></ref><ref id="pone.0226912.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>Q</given-names></name>, <name><surname>Wang</surname><given-names>L</given-names></name>, <name><surname>Zhou</surname><given-names>DS</given-names></name>. <article-title>Trajectory planning of 7-DOF space manipulator for minimizing base disturbance</article-title>. <source>International Journal of Advanced Robotic System</source>, <year>2016</year>,<volume>13</volume>: <fpage>1</fpage>&#x02013;<lpage>10</lpage>. <pub-id pub-id-type="doi">10.5772/62123</pub-id></mixed-citation></ref><ref id="pone.0226912.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>De Momi</surname><given-names>E</given-names></name>, <name><surname>Kranendonk</surname><given-names>L</given-names></name>, <name><surname>Valenti</surname><given-names>M</given-names></name>, <name><surname>Enayati</surname><given-names>N</given-names></name>, <name><surname>Ferrigno</surname><given-names>G</given-names></name>. <article-title>A neural network-based approach for trajectory planning in robot-human handover tasks</article-title>. <source>Frontiers in robotics AI</source>, <year>2016</year>,<volume>3</volume>:<fpage>1</fpage>&#x02013;<lpage>10</lpage>. <pub-id pub-id-type="doi">10.3389/frobt.2016.00034</pub-id></mixed-citation></ref><ref id="pone.0226912.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Abe</surname><given-names>A</given-names></name>.<article-title>Trajectory planning for flexible Cartesian robot manipulator by using artificial neural network: numerical simulation and experimental verification</article-title>. <source>Robotica</source>, <year>2011</year>,<volume>29</volume>:<fpage>797</fpage>&#x02013;<lpage>804</lpage>. <pub-id pub-id-type="doi">10.1017/S0263574710000767</pub-id></mixed-citation></ref><ref id="pone.0226912.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Xie</surname><given-names>L</given-names></name>, <name><surname>Xue</surname><given-names>SF</given-names></name>, <name><surname>Zhang</surname><given-names>JF</given-names></name>, <name><surname>Zhang</surname><given-names>MY</given-names></name>, <name><surname>Tian</surname><given-names>WL</given-names></name>, <name><surname>Haugen</surname><given-names>S</given-names></name>. <article-title>A path planning approach based on multi-direction A* algorithm for ships navigating within wind farm waters</article-title>. <source>Ocean Engineering</source>, <year>2019</year>,<volume>184</volume>:<fpage>311</fpage>&#x02013;<lpage>322</lpage>. <pub-id pub-id-type="doi">10.1016/j.oceaneng.2019.04.055</pub-id></mixed-citation></ref><ref id="pone.0226912.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Xu</surname><given-names>X</given-names></name>, <name><surname>Hu</surname><given-names>Y</given-names></name>, <name><surname>Zhai</surname><given-names>JM</given-names></name>, <name><surname>Li</surname><given-names>LZ</given-names></name>, <name><surname>Guo</surname><given-names>PS</given-names></name>. <article-title>A novel non-collision trajectory planning algorithm based on velocity potential field for robotic manipulator</article-title>. <source>Intermational Journal of Advanced Robotic Systems</source>, <year>2018</year>,<volume>15</volume>(<issue>4</issue>):<fpage>1</fpage>&#x02013;<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1177/1729881418787075</pub-id></mixed-citation></ref><ref id="pone.0226912.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>T</given-names></name>, <name><surname>Gong</surname><given-names>GF</given-names></name>, <name><surname>Yang</surname><given-names>HY</given-names></name>, <name><surname>Chen</surname><given-names>YX</given-names></name>, <name><surname>Zhu</surname><given-names>Y</given-names></name>. <article-title>Trajectory control of tunnel boring machine based on adaptive rectification trajectory planning and multi-cylinders coordinated control</article-title>. <source>International Journal of Precision Engineering and Manufacturing</source>, <year>2019</year>,<volume>20</volume>(<issue>10</issue>): <fpage>1721</fpage>&#x02013;<lpage>1733</lpage>. <pub-id pub-id-type="doi">10.1007/s12541-019-00073-5</pub-id></mixed-citation></ref><ref id="pone.0226912.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Yang</surname><given-names>CG</given-names></name>, <name><surname>Li</surname><given-names>ZJ</given-names></name>, <name><surname>Li</surname><given-names>J</given-names></name>. <article-title>Trajectory planning and optimized adaptive control for a class of wheeled inverted pendulum vehicle models</article-title>. <source>IEEE Transactions on Cybernetics</source>, <year>2012</year>,<volume>43</volume>(<issue>1</issue>):<fpage>24</fpage>&#x02013;<lpage>36</lpage>. <pub-id pub-id-type="doi">10.1109/TSMCB.2012.2198813</pub-id>
<pub-id pub-id-type="pmid">22695357</pub-id></mixed-citation></ref><ref id="pone.0226912.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>MM</given-names></name>, <name><surname>Luo</surname><given-names>JJ</given-names></name>, <name><surname>Walter</surname><given-names>U</given-names></name>. <article-title>Trajectory planning of free-floating space robot using Particle Swarm Optimization (PSO)</article-title>. <source>ACTA Astronautica</source>, <year>2015</year>,<volume>112</volume>: <fpage>77</fpage>&#x02013;<lpage>88</lpage>. <pub-id pub-id-type="doi">10.1016/j.actaastro.2015.03.008</pub-id></mixed-citation></ref><ref id="pone.0226912.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>CT</given-names></name>, <name><surname>Liao</surname><given-names>TT</given-names></name>. <article-title>A hybrid strategy for the time- and energy-efficient trajectory planning of parallel platform manipulators</article-title>. <source>Robotics and Computer-integrated Manufacturing</source>, <year>2011</year>,<volume>27</volume>(<issue>1</issue>):<fpage>72</fpage>&#x02013;<lpage>81</lpage>. <pub-id pub-id-type="doi">10.1016/j.rcim.2010.06.012</pub-id></mixed-citation></ref><ref id="pone.0226912.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Ameni</surname><given-names>A</given-names></name>, <name><surname>Khaled</surname><given-names>N</given-names></name>. <article-title>An advanced potential field method proposed for mobile robot path planning</article-title>. <source>Transactions of the Institute of Measurement and Control</source>. <year>2019</year>; <volume>11</volume>:<fpage>3132</fpage>&#x02013;<lpage>3144</lpage>. <pub-id pub-id-type="doi">10.1177/0142331218824393</pub-id></mixed-citation></ref><ref id="pone.0226912.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Kumar</surname><given-names>PB</given-names></name>, <name><surname>Rawat</surname><given-names>H</given-names></name>, <name><surname>Parhi</surname><given-names>DR</given-names></name>. <article-title>Path planning of humanoids based on artificial potential field method in unknown environments</article-title> [J]. <source>Expert Systems</source>,<year>2018</year>,<volume>36</volume>(<issue>2</issue>):<fpage>1</fpage>&#x02013;<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1111/exsy.12360</pub-id></mixed-citation></ref><ref id="pone.0226912.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>GL</given-names></name>, <name><surname>Liu</surname><given-names>J</given-names></name>. <article-title>Mobile Robot Path Planning Using Ant Colony Algorithm and Improved Potential Field Method</article-title>. <source>Computational Intelligence and Neuroscience</source>. <year>2019</year>:<fpage>1</fpage>&#x02013;<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1155/2019/1932812</pub-id>
<pub-id pub-id-type="pmid">31198416</pub-id></mixed-citation></ref><ref id="pone.0226912.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>WR</given-names></name>, <name><surname>Zhu</surname><given-names>MC</given-names></name>, <name><surname>Wang</surname><given-names>XM</given-names></name>, <name><surname>He</surname><given-names>S</given-names></name>, <name><surname>He</surname><given-names>JP</given-names></name>, <name><surname>Xu</surname><given-names>ZB</given-names></name>. <article-title>An improved artificial potential field method of trajectory planning and obstacle avoidance for redundant manipulators</article-title>. <source>International Journal of Advanced Robotic Systems</source>. <year>2018</year>;<volume>15</volume>(<issue>5</issue>):<fpage>1</fpage>&#x02013;<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1177/1729881418799562</pub-id></mixed-citation></ref><ref id="pone.0226912.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>WH</given-names></name>, <name><surname>Yang</surname><given-names>CG</given-names></name>, <name><surname>Jiang</surname><given-names>YM</given-names></name>, <name><surname>Liu</surname><given-names>XF</given-names></name>. <article-title>Motion Planning for Omnidirectional Wheeled Mobile Robot by Potential Field Method</article-title>. <source>Journal of Advanced Transportation</source>. <year>2017</year>;<fpage>1</fpage>&#x02013;<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1155/2017/4961383</pub-id></mixed-citation></ref><ref id="pone.0226912.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Bence</surname><given-names>Kov&#x000e1;cs</given-names></name>, <name><surname>G&#x000e9;za</surname><given-names>Szayer</given-names></name>, <name><surname>Tajti</surname><given-names>F</given-names></name>, <name><surname>Burdelis</surname><given-names>M</given-names></name>, <name><surname>P&#x000e9;ter</surname><given-names>Korondi</given-names></name>. <article-title>A novel potential field method for path planning of mobile robots by adapting animal motion attributes</article-title>. <source>Robotics and Autonomous Systems</source>. <year>2016</year>;<volume>82</volume>:<fpage>24</fpage>&#x02013;<lpage>34</lpage>. <pub-id pub-id-type="doi">10.1016/j.robot.2016.04.007</pub-id></mixed-citation></ref><ref id="pone.0226912.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Mezouar</surname><given-names>Y</given-names></name>, <name><surname>Chaumette</surname><given-names>F</given-names></name>. <article-title>Path planning for robust image-based control</article-title>. <source>IEEE Transactions on Robotics and Automation</source>. <year>2002</year>; <volume>18</volume>(<issue>4</issue>): <fpage>534</fpage>&#x02013;<lpage>549</lpage>. <pub-id pub-id-type="doi">10.1109/TRA.2002.802218</pub-id></mixed-citation></ref><ref id="pone.0226912.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Lu</surname><given-names>X</given-names></name>, <name><surname>Liu</surname><given-names>JT</given-names></name>, <name><surname>Li</surname><given-names>HF</given-names></name>, <name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Sun</surname><given-names>L</given-names></name>. <article-title>Attack and defense planning for competitive networked robots based on artificial potential field method</article-title>. <source>ROBOT</source>. <year>2013</year>; <volume>35</volume>(<issue>2</issue>): <fpage>218</fpage>&#x02013;<lpage>226</lpage>. <pub-id pub-id-type="doi">10.3724/SP.J.1218.2013.00218</pub-id></mixed-citation></ref></ref-list></back></article>