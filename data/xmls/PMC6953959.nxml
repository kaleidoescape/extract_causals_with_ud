<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Neuroimage Clin</journal-id><journal-id journal-id-type="iso-abbrev">Neuroimage Clin</journal-id><journal-title-group><journal-title>NeuroImage : Clinical</journal-title></journal-title-group><issn pub-type="epub">2213-1582</issn><publisher><publisher-name>Elsevier</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">31927500</article-id><article-id pub-id-type="pmc">6953959</article-id><article-id pub-id-type="publisher-id">S2213-1582(19)30451-6</article-id><article-id pub-id-type="doi">10.1016/j.nicl.2019.102104</article-id><article-id pub-id-type="publisher-id">102104</article-id><article-categories><subj-group subj-group-type="heading"><subject>Regular Article</subject></subj-group></article-categories><title-group><article-title>Automatic detection of lesion load change in Multiple Sclerosis using convolutional neural networks with segmentation confidence</article-title></title-group><contrib-group><contrib contrib-type="author" id="au0001"><name><surname>McKinley</surname><given-names>Richard</given-names></name><email>richard.mckinley@insel.ch</email><xref rid="aff0001" ref-type="aff">a</xref></contrib><contrib contrib-type="author" id="au0002"><name><surname>Wepfer</surname><given-names>Rik</given-names></name><xref rid="aff0001" ref-type="aff">a</xref></contrib><contrib contrib-type="author" id="au0003"><name><surname>Grunder</surname><given-names>Lorenz</given-names></name><xref rid="aff0001" ref-type="aff">a</xref></contrib><contrib contrib-type="author" id="au0004"><name><surname>Aschwanden</surname><given-names>Fabian</given-names></name><xref rid="aff0001" ref-type="aff">a</xref></contrib><contrib contrib-type="author" id="au0005"><name><surname>Fischer</surname><given-names>Tim</given-names></name><xref rid="aff0006" ref-type="aff">f</xref></contrib><contrib contrib-type="author" id="au0006"><name><surname>Friedli</surname><given-names>Christoph</given-names></name><xref rid="aff0004" ref-type="aff">d</xref></contrib><contrib contrib-type="author" id="au0007"><name><surname>Muri</surname><given-names>Raphaela</given-names></name><xref rid="aff0001" ref-type="aff">a</xref></contrib><contrib contrib-type="author" id="au0008"><name><surname>Rummel</surname><given-names>Christian</given-names></name><xref rid="aff0001" ref-type="aff">a</xref></contrib><contrib contrib-type="author" id="au0009"><name><surname>Verma</surname><given-names>Rajeev</given-names></name><xref rid="aff0002" ref-type="aff">b</xref></contrib><contrib contrib-type="author" id="au0010"><name><surname>Weisstanner</surname><given-names>Christian</given-names></name><xref rid="aff0003" ref-type="aff">c</xref></contrib><contrib contrib-type="author" id="au0011"><name><surname>Wiestler</surname><given-names>Benedikt</given-names></name><xref rid="aff0007" ref-type="aff">g</xref></contrib><contrib contrib-type="author" id="au0012"><name><surname>Berger</surname><given-names>Christoph</given-names></name><xref rid="aff0009" ref-type="aff">i</xref></contrib><contrib contrib-type="author" id="au0013"><name><surname>Eichinger</surname><given-names>Paul</given-names></name><xref rid="aff0007" ref-type="aff">g</xref></contrib><contrib contrib-type="author" id="au0014"><name><surname>Muhlau</surname><given-names>Mark</given-names></name><xref rid="aff0008" ref-type="aff">h</xref></contrib><contrib contrib-type="author" id="au0015"><name><surname>Reyes</surname><given-names>Mauricio</given-names></name><xref rid="aff0005" ref-type="aff">e</xref></contrib><contrib contrib-type="author" id="au0016"><name><surname>Salmen</surname><given-names>Anke</given-names></name><xref rid="aff0004" ref-type="aff">d</xref></contrib><contrib contrib-type="author" id="au0017"><name><surname>Chan</surname><given-names>Andrew</given-names></name><xref rid="aff0004" ref-type="aff">d</xref></contrib><contrib contrib-type="author" id="au0018"><name><surname>Wiest</surname><given-names>Roland</given-names></name><xref rid="aff0001" ref-type="aff">a</xref></contrib><contrib contrib-type="author" id="au0019"><name><surname>Wagner</surname><given-names>Franca</given-names></name><xref rid="aff0001" ref-type="aff">a</xref></contrib></contrib-group><aff id="aff0001"><label>a</label>Support Center for Advanced Neuroimaging, University Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, University of Bern, Switzerland</aff><aff id="aff0002"><label>b</label>Department of Neuroradiology, Spital Tiefenau, Switzerland</aff><aff id="aff0003"><label>c</label>Medizinisch Radiologischen Institut, Zurich, Switzerland</aff><aff id="aff0004"><label>d</label>Univeristy Clinic for Neurology, Inselspital, Bern University Hospital, University of Bern, Switzerland</aff><aff id="aff0005"><label>e</label>Insel Data Science Centre, Inselspital, Bern University Hospital, University of Bern, Switzerland</aff><aff id="aff0006"><label>f</label>Universit&#x000e4;tsklinik Balgrist, Zurich, Switzerland</aff><aff id="aff0007"><label>g</label>Diagnostic and Interventional Neuroradiology, Klinikum rechts der Isar der TU M&#x000fc;nchen, Munich, Germany</aff><aff id="aff0008"><label>h</label>Department of Neurology, Klinikum rechts der Isar der TU M&#x000fc;nchen, Munich, Germany</aff><aff id="aff0009"><label>i</label>Center for Translational Cancer Research (TranslaTUM), TU M&#x000fc;nchen, Munich, Germany</aff><pub-date pub-type="pmc-release"><day>09</day><month>12</month><year>2019</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.--><pub-date pub-type="collection"><year>2020</year></pub-date><pub-date pub-type="epub"><day>09</day><month>12</month><year>2019</year></pub-date><volume>25</volume><elocation-id>102104</elocation-id><history><date date-type="received"><day>8</day><month>4</month><year>2019</year></date><date date-type="rev-recd"><day>27</day><month>9</month><year>2019</year></date><date date-type="accepted"><day>18</day><month>11</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; 2019 Published by Elsevier Inc.</copyright-statement><copyright-year>2019</copyright-year><copyright-holder/><license license-type="CC BY-NC-ND" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p></license></permissions><abstract abstract-type="author-highlights" id="absh001"><title>Highlights</title><p><list list-type="simple" id="lst0001"><list-item id="lstitem0001"><label>&#x02022;</label><p id="p0001">We introduce a novel method, based on a neural network (DeepSCAN), for detecting lesion change in longitudinal MRI imaging in multiple sclerosis.</p></list-item><list-item id="lstitem0002"><label>&#x02022;</label><p id="p0002">The method had a sensitivity of 1.00 and a positive predictive value of 0.59 for detecting lesion load change, and an AUC of 0.999, when assessed on twenty-six MS patients with longitudinal imaging.</p></list-item><list-item id="lstitem0003"><label>&#x02022;</label><p id="p0003">This compares to a sensitivity of 0.69 and a PPV of 0.18 when lesion volume, as measured by our classifier, was used to assess lesion load change (AUC = 0.71)</p></list-item><list-item id="lstitem0004"><label>&#x02022;</label><p id="p0004">Change in lesion count (another commonly used metric) had a sensitivity of 0.57 and a PPV of 0.38 (AUC = 0.51).</p></list-item></list></p></abstract><abstract id="abs0001"><p>The detection of new or enlarged white-matter lesions is a vital task in the monitoring of patients undergoing disease-modifying treatment for multiple sclerosis. However, the definition of &#x02018;new or enlarged&#x02019; is not fixed, and it is known that lesion-counting is highly subjective, with high degree of inter- and intra-rater variability. Automated methods for lesion quantification, if accurate enough, hold the potential to make the detection of new and enlarged lesions consistent and repeatable. However, the majority of lesion segmentation algorithms are not evaluated for their ability to separate radiologically progressive from radiologically stable patients, despite this being a pressing clinical use-case. In this paper, we explore the ability of a deep learning segmentation classifier to separate stable from progressive patients by lesion volume and lesion count, and find that neither measure provides a good separation. Instead, we propose a method for identifying lesion changes of high certainty, and establish on an internal dataset of longitudinal multiple sclerosis cases that this method is able to separate progressive from stable time-points with a very high level of discrimination (AUC = 0.999), while changes in lesion volume are much less able to perform this separation (AUC = 0.71). Validation of the method on two external datasets confirms that the method is able to generalize beyond the setting in which it was trained, achieving an accuracies of 75 % and 85 % in separating stable and progressive time-points.</p></abstract><kwd-group id="keys0001"><title>Keywords</title><kwd>Deep Learning</kwd><kwd>Multiple Sclerosis</kwd><kwd>MRI</kwd><kwd>Longitudinal Imaging</kwd></kwd-group></article-meta></front><body><sec id="sec0001"><label>1</label><title>Introduction</title><p id="p0005">Magnetic resonance imaging is the most important imaging method for diagnosis and monitoring of multiple sclerosis. The 2017 revised Mcdonald diagnostic criteria for the diagnosis of multiple sclerosis require the dissemination of lesions in both space and time. Lesion load change is also crucial for the assessment of disease activity, since patients who are assigned with disease modifying therapies and no evidence of disease activity (NEDA) harbor a better prognosis <xref rid="bib0001" ref-type="bibr">Arnold et&#x000a0;al. (2014)</xref>; <xref rid="bib0009" ref-type="bibr">Havrdova, Galetta, Hutchinson, Stefoski, Bates, Polman, O&#x02019;Connor, Giovannoni, Phillips, Lublin, Pace, Kim, Hyde, 2009</xref>, <xref rid="bib0010" ref-type="bibr">Havrdova, Giovannoni, Stefoski, Forster, Umans, Mehta, Greenberg, Elkins, 2014</xref>; <xref rid="bib0019" ref-type="bibr">Nixon et&#x000a0;al. (2014)</xref>. Radiological progression can be separated into new or enlarged lesions in T2 weighted imaging, and new enhancing lesions on T1 weighted imaging with Gadolinium-based contrast agents (GBCA). While standard imaging protocols for multiple sclerosis have included GBCA, there is increasing evidence that high resolution 3D unenhanced MRI is sufficient to detect the presence of new or enlarged lesions <xref rid="bib0005" ref-type="bibr">Eichinger et&#x000a0;al. (2019)</xref>.</p><p id="p0006">Detection of new and enlarged lesions in multiple sclerosis imaging by human raters is time-consuming and limited by inter- and intra-rater variability&#x000a0;<xref rid="bib0006" ref-type="bibr">Erbayat&#x000a0;Altay et&#x000a0;al. (2013)</xref>. As a consequence, manual lesion volumetry and lesion counting has limited sensitivity for new lesion detection. Delineation of new and enlarged lesions can be improved by working on subtraction MRI, but this still requires substantial human user interaction and judgement, as well as manual intensity normalization. A recent study showed that FLAIR subtraction MRI had a sensitivity of 80% for detecting new or enlarged lesions.&#x000a0;<xref rid="bib0023" ref-type="bibr">Rudie et&#x000a0;al. (2019)</xref>. Registration errors, flow artifacts and lesion signal intensity differences can result in the detection of false-positive &#x0201d;lesions&#x0201d; on subtraction images&#x000a0;<xref rid="bib0017" ref-type="bibr">Moraal et&#x000a0;al. (2009)</xref>.</p><p id="p0007">Several groups have proposed automated methods for multiple sclerosis lesion segmentation, mostly validated in a cross-sectional fashion.&#x000a0;<xref rid="bib0007" ref-type="bibr">Fartaria et&#x000a0;al. (2018)</xref>; <xref rid="bib0016" ref-type="bibr">McKinley et&#x000a0;al. (2016)</xref>; <xref rid="bib0026" ref-type="bibr">Valverde, Cabezas, Roura, Gonzalez-Villa, Pareto, Vilanova, Ramio-Torrenta, Rovira, Oliver, Llado, 2017</xref>, <xref rid="bib0027" ref-type="bibr">Valverde, Salem, Cabezas, Pareto, Vilanova, Rami&#x000f3;-Torrent&#x000e0;, Rovira, Salvi, Oliver, Llad&#x000f3;, 2018</xref> Even where longitudinal data was used to assess the performance of classifiers, consistency of segmentations over time, or the ability to detect new lesions were not investigated&#x000a0;<xref rid="bib0002" ref-type="bibr">Carass et&#x000a0;al. (2017)</xref>. Since MR contrast will differ between time-points, even on the same scanner, and since the borders of MS lesions are often not well defined, automated methods will typically show small differences in the boundaries of lesions at different time-points, even if no lesion growth has taken place. Since even the best automated methods also make false positive and false negative lesion identifications, lesion counts may also not be reliable in a longitudinal setting. Several researchers have proposed methods to harmonize segmentations across two or more time-points. Jain et al propose a joint expectation-maximization (EM) framework for two time-point white matter (WM) lesion segmentation, and the Lesion Segmentation Toolkit, a tool integrated in SPM, has a longitudinal pipeline which adapts existing segmentations across multiple time-points <xref rid="bib0012" ref-type="bibr">Jain et&#x000a0;al. (2016)</xref>; <xref rid="bib0025" ref-type="bibr">Schmidt et&#x000a0;al. (2012)</xref>. Meanwhile, Salem et al proposed a logistic regression classifier for detected new and enlarged lesions showing &#x0201d;considerable growth&#x0201d; using features derived from subtraction imaging and deformation fields derived from registration of two time-points. <xref rid="bib0024" ref-type="bibr">Salem et&#x000a0;al. (2018)</xref>.</p><p id="p0008">In a companion paper, we have introduced a novel method (DeepSCAN MS) based on convolutional neural networks (CNNs), for multiple sclerosis lesion segmentation, which we demonstrated to outperform previous methods. <xref rid="bib0015" ref-type="bibr">McKinley et&#x000a0;al. (2019)</xref> In this paper, we demonstrate that changes in lesion count and volume change, estimated using our method, do not perform well as a method for separating stable and progressive MS cases. Simultaneous lesion growth and lesion resolution may occur at a single time-point, which will not be apparent from simply observing volume changes. Further, variations in image contrast between acquisitions can lead to substantial volumetric changes in automated lesion delineation, even when using &#x02018;state-of-the-art&#x02019; classification methods. Lesion counts are also only approximate measures of activity, since lesions may be missed or undersegmented, false positives may give the impression of lesion growth where none exists, and lesions may become confluent, leading to an increase in lesion tissue but a decrease in lesion count.</p><p id="p0009">As a potential solution to this issue, we instead propose to identify new and missing lesion tissue by using the <italic>confidence</italic> of an automated classifier in its own segmentation. Measures of segmentation uncertainty have previously been proposed as a method of rejecting false positive MS lesion identifications.&#x000a0;<xref rid="bib0018" ref-type="bibr">Nair et&#x000a0;al. (2018)</xref> To our knowledge, our method is the first to leverage segmentation confidence in the detection of longitudinal change. Our recently introduced MS lesion classifier, DeepSCAN, produces for each tissue map a &#x02019;label-flip probability&#x02019;, which is a measure of uncertainty derived from the training data. We use the segmentation of the classifier and the label-flip map to distinguish between patients with no new or enlarged lesions (those satisfying that component of the NEDA criteria) and those with genuinely new or enlarged lesions. We identify as new lesion tissue only those voxels that were confidently not present at time-point t=0 but that are confidently lesion tissue at time-point t=1. The method requires T1, FLAIR and T2 imaging adhering to modern best-practice imaging standards in MS (specifically, a 3D FLAIR and 3D T1 acquisition), such as those specified in the OFSEP minimal MRI protocol. &#x000a0;<xref rid="bib0004" ref-type="bibr">Cotton et&#x000a0;al. (2015)</xref>.</p></sec><sec id="sec0002"><label>2</label><title>Methods</title><p id="p0010">In this paper, we study the ability of a previously trained deep learning classifier to detect longitudinal changes in T2 lesion load, by several means: lesion counting, overall lesion volume, detecting voxel-by-voxel change using coregistration, detecting voxel-by-voxel <italic>confident</italic> change using a method which incorporates classifier confidence. We describe the patient cohorts, the deep learning method, and the methods for detecting lesion growth. We utilise data from three sources. The first are MRI datasets of patients with remitting-relapsing multiple sclerosis that were identified from the MS cohort databank of the University of Bern. Use of data for this study was approved by the local ethics committee (Cantonal Ethics Commission Bern, Switzerland &#x02019;MS segmentation disease monitoring&#x02019;, approval number 2016-02035) and all patients gave general consent for data storage and analysis of their MRI datasets. This data was from the same centre and scanner as that used for the training of our fully convolutional deep learning classifier (DeepSCAN).</p><p id="p0011">Additional anonymized datasets were provided by Radiology Center Bethanien, (which we subsequently refer to as the Zurich dataset), and from the Klinikum Rechts der Isar, Munich, Germany (which we subsequently refer to as the Munich dataset).</p><sec id="sec0003"><label>2.1</label><title>Patient cohorts and MR imaging</title><p id="p0012">Patients from the Bernese MS cohort were included in the Bern dataset if they had at least three consecutive MRI datasets, and were not among the 50 casesused in training of the DeepSCAN classifier.&#x000a0;<xref rid="bib0015" ref-type="bibr">McKinley et&#x000a0;al. (2019)</xref> All patients fulfilled the revised McDonald criteria of 2010 for relapsing-remitting multiple sclerosis.<xref rid="bib0020" ref-type="bibr">Polman et&#x000a0;al. (2011)</xref>.</p><p id="p0013">MR images from the Bern dataset were acquired on a 3T MRI (Siemens Verio, Siemens, Erlangen, Germany). The protocol settings were i) T1 weighted MP-RAGE pre- and post gadobutrol i.v. (TR 2530 ms, TE 2.96 ms, averages 1, FoV read 250 mm, FoV phase 87.5 % voxel size 1.0 x 1.0 x 1.0 mm, flip angle 7<sup>&#x02218;</sup>, acquisition time 4:30 min. slices per slab 160, slice thickness of 1.0 mm) ii) T2- weighted imaging (TR 6580 ms, TE 85 ms, averages 2, FoV read 220 mm, FoV phase 87.5 %, voxel size 0.7 x 0.4 x 3.0 mm, flip angle 150<sup>&#x02218;</sup>, acquisition time 6:03 min, 42 parallel images were acquired with a slice thickness of 3.0 mm,) iii) 3D FLAIR imaging (TR 5000 ms, TE 395 ms, averages 1, FoV read 250 mm, FoV phase 100 %, voxel size 1.0 x 1.0 x 1.0 mm, acquisition time 6:27 min. A total of 176 parallel images were acquired with a slice thickness of 1.0 mm). All patients received Gadobutrol (Gadovist) 0.1 ml/kg bodyweight immediately after the acquisition of the unenhanced T1w sequence.</p><p id="p0014">MR images from the Zurich dataset were acquired using a standardized acquisition protocol on a 3T MRI (Siemens Skyra, Siemens, Erlangen, Germany), including: i) T1 weighted MP-RAGE precontrast (TR 2300 ms, TE 2.9 ms, TI 900 ms, averages 1, FoV read 250 mm, FoV phase 93.75 % voxel size 1.0 x 1.0 x 1.0 mm, flip angle 9<sup>&#x02218;</sup>, acquisition time 05:12 min.) ii) T2- weighted imaging (TR 4790 ms, TE 100 ms, averages 1, FoV read 220 mm, FoV phase 100 %, voxel size 0.7 x 0.4 x 3.0 mm, flip angle 150<sup>&#x02218;</sup>, acquisition time 02:16 min iii) 3D FLAIR imaging (TR 5000 ms, TE 398 ms, TI 1800 ms, averages 1, FoV read 250 mm, FoV phase 100 %, voxel size 1.0 x 1.0 x 1.0 mm, flip angle 120<sup>&#x02218;</sup>, acquisition time 04:17 min.).</p><p id="p0015">MR images from the Munich dataset were acquired with a 3T MRI (Achieva; Philips Healthcare, Best, the Netherlands) including: i) 3D T1 gradient-echo imaging, performed before and at least 5 minutes after administration of 0.1 mmol/kg gadolinium-based contrast material : voxel size 1.0 x 1.0 x 1.0 mm; acquisition time, 6 minutes ii) a three-dimensional fluid-attenuated inversion-recovery (FLAIR) sequence, voxel size, 1.03 x 1.03 x 1.5 mm3; acquisition time, 5 minutes iii) T2-weighted imaging: voxel size, 1.03 1.03 1.5 mm; TR 40006000 ms (variable); TE 35 ms; acquisition time 5 min.</p></sec><sec id="sec0004"><label>2.2</label><title>The DeepSCAN MS lesion classifier</title><p id="p0016">In a previous paper on brain tumor segmentation <xref rid="bib0013" ref-type="bibr">McKinley et&#x000a0;al. (2019)</xref>, we proposed a hybrid of U-net <xref rid="bib0022" ref-type="bibr">Ronneberger et&#x000a0;al. (2015)</xref> and Densenet <xref rid="bib0011" ref-type="bibr">Huang et&#x000a0;al. (2017)</xref>, in which the bottleneck layer of the Unet is a single dense block, and in which some of the pooling and upscaling is replaced by dilated convolutions. In a subsequent paper, we introduced a new loss function (label-flip loss), in which the probability that classification output differs from the ground truth used for supervision is used to anneal gradients coming uncertain datapoints, and demonstrated that this loss function leads to improved results in brain segmentation.<xref rid="bib0014" ref-type="bibr">McKinley et&#x000a0;al. (2019)</xref>. In a companion paper to this paper, we trained a classifier, which we call DeepSCAN MS, on fifty cases from the Bernese MS cohort databank <xref rid="bib0015" ref-type="bibr">McKinley et&#x000a0;al. (2019)</xref>. In this section, we first summarize the procedure for training the DeepSCAN MS classifier, and then describe its application in detecting longitudinal changes in MS.</p><p id="p0017">The DeepSCAN MS classifier is shown in <xref rid="fig0001" ref-type="fig">Figure&#x000a0;1</xref>: it is a fully-convolutional neural network trained on fifty cases from the Bernese MS cohort databank, which provides segmentations of white-matter lesions, together with segmentations of the cerebellum, subcortical grey matter structures, and cortical grey and white matter, in MS patients. (In this study we only use the lesion segmentations produced by the classifier.) The network was trained using a combination of <italic>focal loss</italic> and our previously defined <italic>label-flip loss</italic>, on lesion labels provided by manual raters, and brain anatomy labels provided by Freesurfer. In label flip loss, for each voxel, and tissue class, the network outputs two probabilities: the probability p that voxel contains the tissue class, and the probability q that the label predicted does not correspond to the label in the ground-truth annotation (i.e., the probability of a &#x02019;label flip&#x02019;). IF BCE stands for the standard binary cross-entropy loss, and y is the target label, then the label-uncertainty loss is:<disp-formula id="eq0001"><label>(1)</label><mml:math id="M1" altimg="si1.svg"><mml:mrow><mml:mi>B</mml:mi><mml:mi>C</mml:mi><mml:mi>E</mml:mi><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="goodbreak">&#x02212;</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>*</mml:mo><mml:mi>q</mml:mi><mml:mo linebreak="goodbreak">+</mml:mo><mml:mi>x</mml:mi><mml:mo linebreak="goodbreak">*</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="goodbreak">&#x02212;</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mi>C</mml:mi><mml:mi>E</mml:mi><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula> where<disp-formula id="eq0002"><label>(2)</label><mml:math id="M2" altimg="si2.svg"><mml:mrow><mml:mi>z</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo linebreak="goodbreak">&#x0003e;</mml:mo><mml:mn>0.5</mml:mn><mml:mo>)</mml:mo><mml:mo>*</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="goodbreak">&#x02212;</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo linebreak="goodbreak">&#x0003c;</mml:mo><mml:mn>0.5</mml:mn><mml:mo>)</mml:mo><mml:mo>*</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></disp-formula><fig id="fig0001"><label>Fig. 1</label><caption><p>The DeepSCAN architecture used in this paper for lesion and brain-structure segmentation.</p></caption><alt-text id="at0001">Fig. 1</alt-text><graphic xlink:href="gr1"/></fig></p><p id="p0018">If q is close to zero, and the label is correct, the first term is approximately the ordinary BCE loss: if q is close to 0.5 (representing total uncertainty as to the correct label) the first term tends to zero. This loss therefore attenuates loss in areas of high uncertainty (i.e., where the network is likely to disagree with the ground truth) during training, and indicates areas where segmentation reliability may be poor when applied to new data.</p><p id="p0019">On an internal dataset of 32 patients, the DeepSCAN classifier achieved a mean Dice coefficient of 0.60 versus a manual consensus ground truth for the task of segmenting MS lesions, compared to a mean Dice coefficient of 0.58 between two independent manual raters. This result was sustained when we examined external data from the MSSEG challenge&#x000a0;<xref rid="bib0003" ref-type="bibr">Commowick et&#x000a0;al. (2018)</xref>. This dataset consists of fifteen cases, from two centres and three scanners, each rated by seven independent manual raters. Imaging quality is of a similar standard to that used in the Bernese MS cohort. &#x000a0;<xref rid="bib0004" ref-type="bibr">Cotton et&#x000a0;al. (2015)</xref>. Versus the independent raters, mean Dice coefficient with the output of DeepSCAN (without retraining on the external data) ranged between 0.56 and 0.61. For comparison, the mean Dice coefficient between the MSSEG raters on the training data ranged between 0.54 and 0.75.</p><p id="p0020">As we have already discussed, manual segmentations of MS lesions have large inter- and intra-rater variability, and so we must accept that this &#x02019;ground-truth&#x02019; may, for lesion segmentation, contain many inconsistencies: missed or under-segmented lesions, and false identifications or over-segmented lesions. For example, a retrospective analysis of the 32 manual lesion segmentations used to validate the DeepSCAN classifier found an average of 18 false positive lesions and 4 missed lesions per subject.</p><p id="p0021">For full details of the training and validation of the DeepSCAN MS classifier, please see McKinley et. al <xref rid="bib0015" ref-type="bibr">McKinley et&#x000a0;al. (2019)</xref>.</p></sec><sec id="sec0005"><label>2.3</label><title>Dichotomization of imaging data: progressive vs stable</title><p id="p0022">For each patient and each time-point, a decision was made by an experienced neuroradiologist if that time-point represented, from an imaging standpoint, progressive disease (PD, if any new FLAIR- or contrast-enhancing lesions was detected) or stable disease (SD, if the number of lesions remained stable or reduced over time),based on visual analysis by one of the authors (LG for cases from Bern, CW for cases from Zurich, PE for cases from Munich). In each case, the full clinical sequence (including T1 post-contrast for all sites, and Double Inversion Recovery for Munich) was included in the analysis.</p></sec><sec id="sec0006"><label>2.4</label><title>Automated Segmentation by DeepSCAN convolutional neural network</title><p id="p0023">For each patient and time-point we used the DeepSCAN classifier to generate lesion masks and label-flip maps for MS lesions lesions, using the T1-weighted, T2-weighted, and T2 FLAIR imaging as input. To aid in comparison between time-points, these maps were resampled to 1<italic>mm</italic><sup>3</sup> isotropic resolution. The classifier also returns a 1<italic>mm</italic><sup>3</sup> isotropic skull-stripped FLAIR image in the same space as the lesion and label-flip maps.</p></sec><sec id="sec0007"><label>2.5</label><title>Coregistration</title><p id="p0024">In order to compare cases across time-points, it was necessary to register all imaging for each patient to a common space. To avoid biases inherent in registering to a particular time-point, we applied a robust registration technique (the Robust Template method from Freesurfer) to the skull-stripped FLAIR images produced by our CNN tool, in which all time-points are registered to a common patient-specific template.&#x000a0;<xref rid="bib0021" ref-type="bibr">Reuter et&#x000a0;al. (2012)</xref> After construction of the template, lesion masks and lesion confidence maps were rigidly registered to the template space using the transforms output by the robust template method.</p></sec><sec id="sec0008"><label>2.6</label><title>Lesion change detection by classification uncertainty</title><p id="p0025">We describe here the decision procedure for labelling a voxel as &#x02019;new lesion&#x02019;, given lesion mask and label-flip maps at time-points A and B in a common, coregistered space, and a threshold <italic>q</italic> determining acceptable confidence. For each time-point, a voxel is labelled as &#x02019;confident lesion&#x02019; if it is in the lesion mask, and if the label-flip probability is less than <italic>q</italic>. A voxel is labelled &#x02019;confident non-lesion&#x02019; if it is not in the lesion mask, and if the label-flip probability is less than <italic>q</italic>. A voxel is labelled as &#x02019;new lesion&#x02019; at time-point B, if it is labelled as &#x02019;confident non-lesion&#x02019; at time-point A, and &#x02019;confident lesion&#x02019; at time-point B. It is labelled &#x02019;missing lesion&#x02019; at time-point B, if it is labelled as &#x02019;confident lesion&#x02019; at time-point A, and &#x02019;confident non-lesion&#x02019; at time-point B. Finally, connected components of the &#x02019;new lesion&#x02019; and &#x02019;missing lesion&#x02019; maps were calculated.</p><p id="p0026">We subsequently identified all connected components of &#x0201d;new lesion&#x0201d; tissue. To improve robustness to coregistration artifacts, all connected components of the new lesion map containing fewer than 12 voxels were deleted.</p><p id="p0027">For the purposes of our initial investigation, we set the value of <italic>q</italic> to be 0.05: i.e., we determine a voxel to be classified with confidence if the model predicts a 5% or lower chance of the predicted label disagreeing with the manual rater.</p></sec><sec id="sec0009"><label>2.7</label><title>Lesion change detection by threshold margin</title><p id="p0028">A more simplistic methodology for labelling lesions as confidently or uncertainly classified is to set a margin around the ordinary decision threshold, 0.5, and to label all voxels outside of this margin as &#x02019;confident&#x02019;. This method has the advantage that it may be applied to classifiers which do not output a label-flip probability: however, in general the output of modern neural networks is not well calibrated: the scores output by deep networks do not correspond to observed probabilities and are typically overconfident <xref rid="bib0008" ref-type="bibr">Guo et&#x000a0;al. (2017)</xref>.</p><p id="p0029">Concretely, we set a margin 0&#x000a0;&#x0003c;&#x000a0;<italic>m</italic>&#x000a0;&#x0003c;&#x000a0;0.5, and classify every voxel with <inline-formula><mml:math id="M3" altimg="si3.svg"><mml:mrow><mml:mi>p</mml:mi><mml:mo linebreak="goodbreak">&#x0003c;</mml:mo><mml:mn>0.5</mml:mn><mml:mo linebreak="goodbreak">&#x02212;</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> as confident nonlesion, while every voxel with <inline-formula><mml:math id="M4" altimg="si4.svg"><mml:mrow><mml:mi>p</mml:mi><mml:mo linebreak="goodbreak">&#x0003e;</mml:mo><mml:mi>m</mml:mi><mml:mo linebreak="goodbreak">+</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> is classified as confident lesion. The measure of new lesion tissue is then as above: a voxel is new lesion if it is labelled as &#x02019;confident lesion&#x02019; at time-point A, and &#x02019;confident non-lesion&#x02019; at time-point B. As above, connected components below 12 voxels were deleted.</p><p id="p0030">For the purposes of our initial investigation, we set the value of <italic>m</italic> to be 0.45: i.e., we determine a voxel to be classified as confident lesion if the model predicts a score of.95 or greater and to be classified as confident non-lesion if the model predicts a score of 0.05 or less.</p></sec><sec id="sec0010"><label>2.8</label><title>Evaluation</title><p id="p0031">We compared our proposed methods to four other methods on our internal (Bernese) test set: absolute change in lesion volume, relative change in lesion volume, change in lesion count, and total new lesion volume (equivalent to our method with <inline-formula><mml:math id="M5" altimg="si5.svg"><mml:mrow><mml:mi>q</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>). To test the power of these measures to separate progressive and stable time-points, we plotted the receiver-operating characteristic (ROC) curves for each of the above methods. While ROC-AUC analysis gauges the ability of a metric to separate positive and negative examples across all operating thresholds, clinical applicability required that a particular threshold is chosen..We therefore tested the performance of our metrics at an operating threshold corresponding to &#x02018;no lesion change&#x02019; (i.e. lesion count &#x000a0;&#x0003e;&#x000a0;0, lesion volume change &#x000a0;&#x0003e;&#x000a0;0, and new lesion volume &#x000a0;&#x0003e;&#x000a0;0).</p><p id="p0032">We assessed the sensitivity of our method to its parameters, by comparing the ROC curves of the method at different values of uncertainty threshold <italic>q</italic>, margin m, and small-growth threshold.</p></sec></sec><sec id="sec0011"><label>3</label><title>Results</title><p id="p0033">Twenty-six patients from the Bernese MS databank satisfied the inclusion criteria, of which 16 were judged from radiological reports to have no lesion changes in any of the time-points, and so were labelled as having stable disease (SD). The remaining 10 cases were judged to have progressive disease (PD). The mean number of time-points per patient was 4.4 for the progressive patients, and 4.9 for the stable patients. Among the ten progressive patients, there were a total of 13 time-points where the radiological reports indicated progression, meaning that approximately 30% of the time-points in those patients showed lesion progression. Mean time between examinations for 223 days, with a standard deviation of 98 days.</p><sec id="sec0012"><label>3.1</label><title>ROC-AUC analysis</title><p id="p0034">For each proposed method, we computed the area under the receiver-operating characteristic for the bernese dataset: see <xref rid="fig0002" ref-type="fig">Figure&#x000a0;2</xref>. Lesion counting performed worst, with a ROC-AUC of 0.51, while absolute and relative volume change performed comparably, with ROC-AUCs of 0.70 and 0.71 respectively. The proposed method using score margins had an AUC of 0.77. Meanwhile, the proposed method using network-derived uncertainty had a ROC-AUC of 0.999.<fig id="fig0002"><label>Fig. 2</label><caption><p>Receiver operating curves for the detection of lesion progression using DeepSCAN, on our internal validation set, via absolute lesion volume change (AUC=0.70), relative volume change (AUC = 0.71), lesion count change (AUC = 0.51), the proposed method using a score margin of.45 (AUC=0.77) and the proposed method using an uncertainty threshold of 0.05 (AUC &#x000a0;&#x02248;&#x000a0;1). The star on each curve represents a cutoff where the patient is labelled as stable if the considered metric is less than or equal to zero.</p></caption><alt-text id="at0002">Fig. 2</alt-text><graphic xlink:href="gr2"/></fig></p></sec><sec id="sec0013"><label>3.2</label><title>Performance at meaningful thresholds</title><p id="p0035">Results of this analysis are shown in <xref rid="tbl0001" ref-type="table">Table&#x000a0;1</xref>.<table-wrap position="float" id="tbl0001"><label>Table 1</label><caption><p>Ability to distinguish progressive vs stable MS at thresholds corresponding to no lesion change, on internal test set, showing the number of true negatives (TN), false positives (FP), false negatives (FN) and true positives (TP), together with accuracy, positive predictive value and recall. Metrics are shown for the label-flip method (Confidence method) and the margin-based method (Margin method), together with new lesion volume, lesion volume change and lesion count change.</p></caption><alt-text id="at0006">Table 1</alt-text><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top"/><th align="left" valign="top">TN</th><th align="left" valign="top">FP</th><th align="left" valign="top">FN</th><th align="left" valign="top">TP</th><th align="left" valign="top">Accuracy</th><th align="left" valign="top">Sensitivity</th><th align="left" valign="top">PPV</th><th align="left" valign="top">FPR</th></tr></thead><tbody><tr><td valign="top">Confidence method&#x000a0;&#x0003e;&#x000a0;0</td><td valign="top">74</td><td valign="top">9</td><td valign="top">0</td><td valign="top">13</td><td valign="top">0.91</td><td valign="top">1.00</td><td valign="top">0.59</td><td valign="top">0.11</td></tr><tr><td valign="top">Margin method &#x000a0;&#x0003e;&#x000a0;0</td><td valign="top">83</td><td valign="top">0</td><td valign="top">6</td><td valign="top">7</td><td valign="top">0.94</td><td valign="top">0.54</td><td valign="top">1.00</td><td valign="top">0.00</td></tr><tr><td valign="top">New lesion volume &#x000a0;&#x0003e;&#x000a0;0</td><td valign="top">8</td><td valign="top">75</td><td valign="top">0</td><td valign="top">13</td><td valign="top">0.22</td><td valign="top">1.00</td><td valign="top">0.15</td><td valign="top">0.90</td></tr><tr><td valign="top">Volume change&#x000a0;&#x0003e;&#x000a0;0</td><td valign="top">41</td><td valign="top">42</td><td valign="top">4</td><td valign="top">9</td><td valign="top">0.52</td><td valign="top">0.69</td><td valign="top">0.18</td><td valign="top">0.51</td></tr><tr><td valign="top">Lesion count change &#x000a0;&#x0003e;&#x000a0;0</td><td valign="top">50</td><td valign="top">33</td><td valign="top">8</td><td valign="top">5</td><td valign="top">0.57</td><td valign="top">0.38</td><td valign="top">0.13</td><td valign="top">0.40</td></tr></tbody></table></table-wrap></p><p id="p0036">For lesion counting, this metric leads to a total of 33 time-points being identified as progressive, when in fact they were stable according to radiological reports. For lesion volumetry, 42 time-points were falsely identified as being stable. For the proposed method, nine stable time-points were labelled as progressive. Meanwhile, the proposed method based on uncertainty successfully identified all progressive time-points. By comparison, the lesion volume metric failed to find four of the progressive time-points, and lesion counting failed to find eight progressive time-points. The proposed method based on a margin around the decision boundary made no false positive identifications, but failed to find six of the progressive time-points.</p></sec><sec id="sec0014"><label>3.3</label><title>Sensitivity to uncertainty threshold, score-margin and small-growth threshold</title><p id="p0037">The best-performing method according to area under the ROC curve, according to our initial analysis, was achieved using our uncertainty-based method with an uncertainty threshold of 0.05: i.e. voxels which had a flip-probability greater than 0.05 at either time-point are not used to calculate lesion change. At a fixed operating threshold, meanwhile, our two proposed methods performed similarly in terms of accuracy, but the method derived from label-flip confidence had perfect sensitivity and lower PPV, while the method derived from a margin around the threshold had perfect PPV and lower sensitivity.</p><p id="p0038">Both of these methods rely on a parameter which can be varied, with an effect on the performance. In this section we investigate the effect of changing those parameters.</p><sec id="sec0015"><label>3.3.1</label><title>Effect of changing uncertainty threshold</title><p id="p0039">For uncertainty threshold values lower than the one we initially selected (0.0005, 0.001 and 0.01), the AUC was slightly reduced, at 0.92. At larger uncertainty thresholds than initially selected, the AUC was also slightly lower: a threshold of 0.1 gave an AUC of 0.99, and a threshold of 0.2 gave an AUC of 0.96.</p></sec><sec id="sec0016"><label>3.3.2</label><title>Effect of changing classification margin</title><p id="p0040">The effect of changing the classification margin was much more drastic. By setting a narrower classification margin (0.15), we were able to achieve an AUC close to the performance of the uncertainty-based method (AUC = 0.998). A slightly larger margin of 0.2 gave worse performance (AUC = 0.96), while a slightly narrower margin of 0.1 led to a smaller decrease in performance (AUC = 0.996).</p></sec><sec id="sec0017"><label>3.3.3</label><title>Effect of changing threshold for growth</title><p id="p0041">In the method as described, areas of growth below 12 voxels do not count towards lesion growth. The method is reasonably robust to changes in this lesion-growth threshold. A larger threshold of 24 voxels led to an AUC of 0.96, while a smaller threshold of 6 voxels led to an AUC of 0.997. Not applying a threshold yielded an AUC of 0.98.</p></sec></sec><sec id="sec0018"><label>3.4</label><title>Performance on external data</title><p id="p0042">Several authors have reported difficulties of automated methods for MS lesion segmentation to perform on out-of-sample data.<xref rid="bib0003" ref-type="bibr">Commowick et&#x000a0;al. (2018)</xref>; <xref rid="bib0027" ref-type="bibr">Valverde et&#x000a0;al. (2018)</xref> In our previous paper, we already validated that performance of the DeepSCAN MS classifier is not substantially degraded when applied to data adhering to similar protocol standards from different centres<xref rid="bib0015" ref-type="bibr">McKinley et&#x000a0;al. (2019)</xref>. In this section, we report the ability of the uncertainty-based method, as described above to identify progressive time-points in external data. The method was applied to data from eight patients, each having four consecutive time-points (thirty-two datsets, twenty-four after baseline) from the Zurich dataset. This data was supplied full anonymized. In a second test of generalization, the full lesion segmentation algorithm and uncertainty-based method was containerized using Docker, and provided to the co-authors from Munich (BW, CB, PE, MM), who applied the classifier to cases from their centre.</p><p id="p0043">The Zurich dataset consisted of four consecutive time-points (thirty-two datasets, twenty-four after baseline imaging). Of the twenty-four follow-up time-points, five were judged by the rater (CW) to have new or enlarged lesions. The proposed method successfully identified three of the five progressive time-points (sensitivity of 60%) and labelled an additional three incorrectly as being progressive. (PPV of 84%), Overall accuracy on this dataset was 75%.</p><p id="p0044">The Munich dataset consisted of 53 pairs of baseline and followup image, of which 24 were judged progressive, and 29 judged stable. The method successfully identified 16 of the 22 progressive time-points (Sensitivity of 72%) and correctly identified all of the stable time-points. (PPV of 100 %) Overall accuracy on this dataset was 85%. A summary of the performance of the confidence-based method on al three datasets studied is shown in <xref rid="tbl0001" ref-type="table">Tables 1</xref> and <xref rid="tbl0002" ref-type="table">2</xref>.<table-wrap position="float" id="tbl0002"><label>Table 2</label><caption><p>Performance of the confidence-based method on the three datasets studied in this paper, showing Accuracy, Sensitivity, and Positive Predicative Value (PPV).</p></caption><alt-text id="at0007">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top"/><th align="left" valign="top">Accuracy</th><th align="left" valign="top">Sensitivity</th><th align="left" valign="top">PPV</th><th align="left" valign="top"/></tr></thead><tbody><tr><td valign="top">Zurich</td><td valign="top">0.75</td><td valign="top">0.60</td><td valign="top">0.84</td><td/></tr><tr><td valign="top">Munich</td><td valign="top">0.85</td><td valign="top">0.72</td><td valign="top">1.00</td><td/></tr><tr><td valign="top">Bern</td><td valign="top">0.91</td><td valign="top">1.00</td><td valign="top">0.59</td><td/></tr></tbody></table></table-wrap></p></sec></sec><sec id="sec0019"><label>4</label><title>Discussion</title><p id="p0045">MRI is the method of choice to determine lesion load evolution in patients with multiple sclerosis. The accurate detection of new or enlarged white-matter lesions in multiple sclerosis patients is a pivotal task of the disease monitoring process in patients who receive disease-modifying treatment. However, the definition of &#x02019;new or enlarged&#x02019; remains ill-defined, and lesion counting remains subjective with a considerable degree of inter- and intra-rater variability depending on the level of experience of the reporting expert. Automated methods for lesion quantification, if accurate, hold the potential to make the detection of new and grown lesions consistent and repeatable. Until now, the majority of lesion segmentation algorithms are not well evaluated for their ability to accurately separate radiologically progressive disease course from radiologically stable patients during follow-up. Despite this being the pressing clinical use-case and information for the clinicians with impact on further treatment regime selection for the MS patients. We demonstrate that measures of new lesion load derived from label-flip uncertainty outperform lesion counting as well as absolute and relative volume change detection in the longitudinal analysis of MS lesions. The major advantage of the proposed approach is to identify the time-point during follow-up where lesion progression was evident with a very high accuracy and positive predictive value. The method is fully automated, and therefore offers the benefit of being objective and independent from user bias, thus leading to more trustful longitudinal evaluations.</p><p id="p0046">The method developed relies on a minimum standard of MR imaging corresponding to a modern MRI protocol for imaging of demyelinating disease: in particular a 3D T1 and 3D FLAIR acquisition (with approximately 1<italic>mm</italic><sup>3</sup> or better voxels). The recommended protocol is in keeping with the 2016 Consortium of MS Centers Task Force recommendations and can be executed in approximately 20 minutes. In particular, the method does not rely on the availability of a post-contrast T1 sequence: recent research suggests that modern 3D imaging at 3T can reduce or eliminate the need for contrast-enhanced sequences. <xref rid="bib0005" ref-type="bibr">Eichinger et&#x000a0;al. (2019)</xref>; <xref rid="bib0023" ref-type="bibr">Rudie et&#x000a0;al. (2019)</xref>.</p><p id="p0047">The method in this paper proposes to track changes in lesion load by leveraging measures of uncertainty in the location of lesion boundaries, based on the predictions of a deep learning convolutional neural network classifier, DeepSCAN. This method has already been shown to perform well at lesion segmentation in a cross-sectional setting: the classifier was more than twice as effective in lesion detection as both previous generations of CNN-based segmentation tools and freely-available lesion segmentation SPM toolboxes.&#x000a0;<xref rid="bib0015" ref-type="bibr">McKinley et&#x000a0;al. (2019)</xref> In this paper, we sought to demonstrate the same classifier&#x02019;s ability to detect lesion change: by considering as new lesion tissue only those voxels which are classified confidently by DeepSCAN, progressive time-points were detected with an accuracy of 0.91 and a recall of 1.0, when applied to data from the same centre as those used to train the classifier. By comparison with standard metrics, such as lesion count progression or volume changes, no progressive time-points were falsely identified as stable, and the risk of false positive results decreased by more than a factor of three, in comparison with lesion counting, and a factor of eight compared to simply counting new lesion tissue voxels. An alternative method, relying on a margin around the decision boundary rather than uncertainty, performed similarly to the label-flip confidence method, but only after the correct margin was found. We therefore tend to prefer the uncertainty-based method.</p><p id="p0048">Furthermore, our method (trained on fifty cases from a single institution) also performs well when applied to two datasets from external centres. While detection of progression was perfect on the internal validation set, the method failed to identify progression at two time-points in the Zurich dataset and eight time-points from the Munich data set. This was caused by small new lesions which were correctly identified, but too small to be identified confidently. For example, the two cases mislabelled as stable in the Zurich dataset each had a single, small new lesion. In the first case this was a small faint lesion in deep white matter, and in the second it was a small periventricular lesion. In both cases these lesions were correctly segmented by DeepSCAN, but not at a sufficient level of confidence to deem them confident new lesion tissue. Representative slices from these two cases are shown in <xref rid="fig0003" ref-type="fig">Figures&#x000a0;3</xref> and <xref rid="fig0004" ref-type="fig">4</xref>. A representative slice from a further case from the external dataset, showing two correctly identified instances of lesion growth, is shown in <xref rid="fig0005" ref-type="fig">Figure&#x000a0;5</xref>. We can hope that detection of missed lesions can be improved by training on larger, more diverse datasets, or by the inclusion of more sensitive sequences. In the case of the Munich dataset, a Double Inversion Recovery sequence was used by human raters in addition to FLAIR to identify lesions. Detection of lesions on FLAIR only was shown in a recent study to miss 27.6 % of new or grown lesions, compared to DIR.<xref rid="bib0005" ref-type="bibr">Eichinger et&#x000a0;al. (2019)</xref> It is therefore perhaps not surprising that some time-points labelled as stable were judged as progressive by the human raters, as the new lesions may not have been visible in the FLAIR sequence. This suggests that it would be worthwhile to extend our approach to incorporate DIR imaging. This would, however, limit the applicability of the technique in clinical practice. Alternatively, the proposed method could be used by a reader, in conjunction with segmentations from the separate time-points, to streamline semi-automatic detection of new lesions. Semi-automated methods for MS lesion segmentation provide a simple method to assess the change in lesion load of an MS patient. Simple FLAIR image subtraction methods or background subtractions of binarized image have been used to manually identify new lesion tissue with high accuracy and low error rates. Other methods included graph cuts, i.e. graph-based segmentation techniques that employ seed points set by the user and a cost function or active contouring using prior information. These methods still require a degree of human interaction, are time consuming and require an expert-in-the-loop. Currently, substantial effort is being invested in the development of fully-automated lesion annotation methods, and results indicate that advances in model architecture and training techniques, together with increasing availability of expert-labelled data, have brought us close to, or even allow us to exceed, the performance of expert human raters <xref rid="bib0003" ref-type="bibr">Commowick et&#x000a0;al. (2018)</xref>; <xref rid="bib0015" ref-type="bibr">McKinley et&#x000a0;al. (2019)</xref>. However, in the study at hand, we could demonstrate that despite the effectiveness of automated lesion segmentation, automatically detected <italic>changes</italic> in lesion volume in MS patients alone is not a sufficient method for performing separation between radiologically progressive course from radiologically stable patients. Instead, we propose a method for identifying lesion changes of high certainty. We conclude that, while solitary lesion volume or total lesion load - together with clinical disease course / EDSS of MS patients - are strong predictors of disease course across a reference MS population, in the individual MS patient changes in these measures are not an adequate means to clear differentiate progressive disease course from no disease activity.<fig id="fig0003"><label>Fig. 3</label><caption><p>Two time-points from the external dataset, showing a missed new lesion. (A) coregistered FLAIR, (B) lesion segmentations, (C) Label-flip maps. New lesion is correctly detected by DeepSCAN at TP2, but not labelled as confident new lesion. Small, faint lesions are more likely to be labelled as uncertain than large, clear lesions.</p></caption><alt-text id="at0003">Fig. 3</alt-text><graphic xlink:href="gr3"/></fig><fig id="fig0004"><label>Fig. 4</label><caption><p>Two time-points from the external dataset, showing a missed new periventricular lesion. (A) coregistered FLAIR, (B) lesion segmentations, (C) Label-flip maps. Lesion is detected by DeepSCAN at TP2, but location of new lesion is uncertain at TP1. Owing to the similar appearance of periventricular lesions and subependymal gliosis, label confidence is typically low in this region.</p></caption><alt-text id="at0004">Fig. 4</alt-text><graphic xlink:href="gr4"/></fig><fig id="fig0005"><label>Fig. 5</label><caption><p>A case from the Zurich dataset. Top Row: FLAIR imaging at baseline and three subsequent time-points. A: FLAIR images with lesion masks as provided by the DeepSCAN classifier. B: FLAIR images with masks indicating naive lesion change (lesion is absent at previous time-point but present at current time-point). time-points 3 and 4 show new lesion tissue due to differences in imaging, rather than genuine lesion growth. C: Regions where DeepSCAN flip probability &#x000a0;&#x0003e;&#x000a0;0.05 highlighted in blue. D: Confident new lesion tissue maps as provided by the method, showing correctly detected new lesion tissue at time-point 2, and no change at time-points 3 and 4.</p></caption><alt-text id="at0005">Fig. 5</alt-text><graphic xlink:href="gr5"/></fig></p><p id="p0049">We believe that the performance shown by our method will encourage the MS community to investigate its use in different clinical settings. The benefits of automated methods lie not only in terms of the accuracy in differentiation of progressive versus stable disease course on MR imaging but also in the related reductions in time and economic costs derived from manual lesion labelling. While there is an increasing level of evidence that CNNs are comparable to human rater&#x02019;s performance in cross-sectional studies, only longitudinal clinical follow-up studies will demonstrate the utility of these methods for identifying patients who remain stable under DMT.</p></sec></body><back><ref-list id="bib001"><title>References</title><ref id="bib0001"><element-citation publication-type="journal" id="sbref0001"><person-group person-group-type="author"><name><surname>Arnold</surname><given-names>D.L.</given-names></name><name><surname>Calabresi</surname><given-names>P.A.</given-names></name><name><surname>Kieseier</surname><given-names>B.C.</given-names></name><name><surname>Sheikh</surname><given-names>S.I.</given-names></name><name><surname>Deykin</surname><given-names>A.</given-names></name><name><surname>Zhu</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>You</surname><given-names>X.</given-names></name><name><surname>Sperling</surname><given-names>B.</given-names></name><name><surname>Hung</surname><given-names>S.</given-names></name></person-group><article-title>Effect of peginterferon beta-1a on MRI measures and achieving no evidence of disease activity: results from a randomized controlled trial in relapsing-remitting multiple sclerosis</article-title><source>BMC Neurology</source><volume>14</volume><issue>1</issue><year>2014</year><fpage>240</fpage><pub-id pub-id-type="pmid">25551571</pub-id></element-citation></ref><ref id="bib0002"><element-citation publication-type="journal" id="sbref0002"><person-group person-group-type="author"><name><surname>Carass</surname><given-names>A.</given-names></name><name><surname>Roy</surname><given-names>S.</given-names></name><name><surname>Jog</surname><given-names>A.</given-names></name><name><surname>Cuzzocreo</surname><given-names>J.L.</given-names></name><name><surname>Magrath</surname><given-names>E.</given-names></name><name><surname>Gherman</surname><given-names>A.</given-names></name><name><surname>Button</surname><given-names>J.</given-names></name><name><surname>Nguyen</surname><given-names>J.</given-names></name><name><surname>Prados</surname><given-names>F.</given-names></name><name><surname>Sudre</surname><given-names>C.H.</given-names></name><name><surname>Cardoso</surname><given-names>M.J.</given-names></name><name><surname>Cawley</surname><given-names>N.</given-names></name><name><surname>Ciccarelli</surname><given-names>O.</given-names></name><name><surname>Wheeler-Kingshott</surname><given-names>C.A.</given-names></name><name><surname>Ourselin</surname><given-names>S.</given-names></name><name><surname>Catanese</surname><given-names>L.</given-names></name><name><surname>Deshpande</surname><given-names>H.</given-names></name><name><surname>Maurel</surname><given-names>P.</given-names></name><name><surname>Commowick</surname><given-names>O.</given-names></name><name><surname>Barillot</surname><given-names>C.</given-names></name><name><surname>Tomas-Fernandez</surname><given-names>X.</given-names></name><name><surname>Warfield</surname><given-names>S.K.</given-names></name><name><surname>Vaidya</surname><given-names>S.</given-names></name><name><surname>Chunduru</surname><given-names>A.</given-names></name><name><surname>Muthuganapathy</surname><given-names>R.</given-names></name><name><surname>Krishnamurthi</surname><given-names>G.</given-names></name><name><surname>Jesson</surname><given-names>A.</given-names></name><name><surname>Arbel</surname><given-names>T.</given-names></name><name><surname>Maier</surname><given-names>O.</given-names></name><name><surname>Handels</surname><given-names>H.</given-names></name><name><surname>Iheme</surname><given-names>L.O.</given-names></name><name><surname>Unay</surname><given-names>D.</given-names></name><name><surname>Jain</surname><given-names>S.</given-names></name><name><surname>Sima</surname><given-names>D.M.</given-names></name><name><surname>Smeets</surname><given-names>D.</given-names></name><name><surname>Ghafoorian</surname><given-names>M.</given-names></name><name><surname>Platel</surname><given-names>B.</given-names></name><name><surname>Birenbaum</surname><given-names>A.</given-names></name><name><surname>Greenspan</surname><given-names>H.</given-names></name><name><surname>Bazin</surname><given-names>P.-L.</given-names></name><name><surname>Calabresi</surname><given-names>P.A.</given-names></name><name><surname>Crainiceanu</surname><given-names>C.M.</given-names></name><name><surname>Ellingsen</surname><given-names>L.M.</given-names></name><name><surname>Reich</surname><given-names>D.S.</given-names></name><name><surname>Prince</surname><given-names>J.L.</given-names></name><name><surname>Pham</surname><given-names>D.L.</given-names></name></person-group><article-title>Longitudinal multiple sclerosis lesion segmentation: Resource and challenge</article-title><source>NeuroImage</source><volume>148</volume><year>2017</year><fpage>77</fpage><lpage>102</lpage><pub-id pub-id-type="pmid">28087490</pub-id></element-citation></ref><ref id="bib0003"><element-citation publication-type="journal" id="sbref0003"><person-group person-group-type="author"><name><surname>Commowick</surname><given-names>O.</given-names></name><name><surname>Istace</surname><given-names>A.</given-names></name><name><surname>Kain</surname><given-names>M.</given-names></name><name><surname>Laurent</surname><given-names>B.</given-names></name><name><surname>Leray</surname><given-names>F.</given-names></name><name><surname>Simon</surname><given-names>M.</given-names></name><name><surname>Pop</surname><given-names>S.</given-names></name><name><surname>Girard</surname><given-names>P.</given-names></name><name><surname>Am&#x000e9;li</surname><given-names>R.</given-names></name><name><surname>Ferr&#x000e9;</surname><given-names>J.</given-names></name><name><surname>Kerbrat</surname><given-names>A.</given-names></name><name><surname>Tourdias</surname><given-names>T.</given-names></name><name><surname>Cervenansky</surname><given-names>F.</given-names></name><name><surname>Glatard</surname><given-names>T.</given-names></name><name><surname>Beaumont</surname><given-names>J.</given-names></name><name><surname>Doyle</surname><given-names>S.</given-names></name><name><surname>Forbes</surname><given-names>F.</given-names></name><name><surname>Knight</surname><given-names>J.</given-names></name><name><surname>Khademi</surname><given-names>A.</given-names></name><name><surname>Mahbod</surname><given-names>A.</given-names></name><name><surname>Wang</surname><given-names>C.</given-names></name><name><surname>McKinley</surname><given-names>R.</given-names></name><name><surname>Wagner</surname><given-names>F.</given-names></name><name><surname>Muschelli</surname><given-names>J.</given-names></name><name><surname>Sweeney</surname><given-names>E.</given-names></name><name><surname>Roura</surname><given-names>E.</given-names></name><name><surname>Llad&#x000f3;</surname><given-names>X.</given-names></name><name><surname>Santos</surname><given-names>M.</given-names></name><name><surname>Santos</surname><given-names>W.</given-names></name><name><surname>Silva-Filho</surname><given-names>A.</given-names></name><name><surname>Tomas-Fernandez</surname><given-names>X.</given-names></name><name><surname>Urien</surname><given-names>H.</given-names></name><name><surname>Bloch</surname><given-names>I.</given-names></name><name><surname>Valverde</surname><given-names>S.</given-names></name><name><surname>Cabezas</surname><given-names>M.</given-names></name><name><surname>Vera-Olmos</surname><given-names>F.</given-names></name><name><surname>Malpica</surname><given-names>N.</given-names></name><name><surname>Guttmann</surname><given-names>C.</given-names></name><name><surname>Vukusic</surname><given-names>S.</given-names></name><name><surname>Edan</surname><given-names>G.</given-names></name><name><surname>Dojat</surname><given-names>M.</given-names></name><name><surname>Styner</surname><given-names>M.</given-names></name><name><surname>Warfield</surname><given-names>S.</given-names></name><name><surname>Cotton</surname><given-names>F.</given-names></name><name><surname>Barillot</surname><given-names>C.</given-names></name></person-group><article-title>Objective evaluation of multiple sclerosis lesion segmentation using a data management and processing infrastructure</article-title><source>Scientific Reports</source><volume>8</volume><issue>1</issue><year>2018</year></element-citation></ref><ref id="bib0004"><element-citation publication-type="journal" id="sbref0004"><person-group person-group-type="author"><name><surname>Cotton</surname><given-names>F.</given-names></name><name><surname>Kremer</surname><given-names>S.</given-names></name><name><surname>Hannoun</surname><given-names>S.</given-names></name><name><surname>Vukusic</surname><given-names>S.</given-names></name><name><surname>Dousset</surname><given-names>V.</given-names></name></person-group><article-title>OFSEP, a nationwide cohort of people with multiple sclerosis: Consensus minimal MRI protocol</article-title><source>Journal of Neuroradiology</source><volume>42</volume><issue>3</issue><year>2015</year><fpage>133</fpage><lpage>140</lpage></element-citation></ref><ref id="bib0005"><element-citation publication-type="journal" id="sbref0005"><person-group person-group-type="author"><name><surname>Eichinger</surname><given-names>P.</given-names></name><name><surname>Schn</surname><given-names>S.</given-names></name><name><surname>Pongratz</surname><given-names>V.</given-names></name><name><surname>Wiestler</surname><given-names>H.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Bussas</surname><given-names>M.</given-names></name><name><surname>Hoshi</surname><given-names>M.-M.</given-names></name><name><surname>Kirschke</surname><given-names>J.</given-names></name><name><surname>Berthele</surname><given-names>A.</given-names></name><name><surname>Zimmer</surname><given-names>C.</given-names></name><name><surname>Hemmer</surname><given-names>B.</given-names></name><name><surname>Mhlau</surname><given-names>M.</given-names></name><name><surname>Wiestler</surname><given-names>B.</given-names></name></person-group><article-title>Accuracy of unenhanced MRI in the detection of new brain lesions in multiple sclerosis</article-title><source>Radiology</source><volume>291</volume><issue>2</issue><year>2019</year><fpage>429</fpage><lpage>435</lpage><pub-id pub-id-type="pmid">30860448</pub-id></element-citation><note><p>PMID: 30860448.</p></note></ref><ref id="bib0006"><element-citation publication-type="journal" id="sbref0006"><person-group person-group-type="author"><name><surname>Erbayat Altay</surname><given-names>E.</given-names></name><name><surname>Fisher</surname><given-names>E.</given-names></name><name><surname>Jones</surname><given-names>S.</given-names></name><name><surname>Hara-Cleaver</surname><given-names>C.</given-names></name><name><surname>Lee</surname><given-names>J.-C.</given-names></name><name><surname>Rudick</surname><given-names>R.</given-names></name></person-group><article-title>Reliability of classifying multiple sclerosis disease activity using magnetic resonance imaging in a multiple sclerosis clinic</article-title><source>JAMA Neurol.</source><volume>70</volume><year>2013</year><fpage>338</fpage><lpage>344</lpage><pub-id pub-id-type="pmid">23599930</pub-id></element-citation></ref><ref id="bib0007"><element-citation publication-type="journal" id="sbref0007"><person-group person-group-type="author"><name><surname>Fartaria</surname><given-names>M.</given-names></name><name><surname>Todea</surname><given-names>A.</given-names></name><name><surname>Kober</surname><given-names>T.</given-names></name><name><surname>O&#x02019;brien</surname><given-names>K.</given-names></name><name><surname>Krueger</surname><given-names>G.</given-names></name><name><surname>Meuli</surname><given-names>R.</given-names></name><name><surname>Granziera</surname><given-names>C.</given-names></name><name><surname>Roche</surname><given-names>A.</given-names></name><name><surname>Bach Cuadra</surname><given-names>M.</given-names></name></person-group><article-title>Partial volume-aware assessment of multiple sclerosis lesions</article-title><source>NeuroImage : Clinical</source><volume>18</volume><year>2018</year><fpage>245</fpage><lpage>253</lpage><pub-id pub-id-type="pmid">29868448</pub-id></element-citation></ref><ref id="bib0008"><element-citation publication-type="book" id="sbref0008"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>C.</given-names></name><name><surname>Pleiss</surname><given-names>G.</given-names></name><name><surname>Sun</surname><given-names>Y.</given-names></name><name><surname>Weinberger</surname><given-names>K.Q.</given-names></name></person-group><chapter-title>On calibration of modern neural networks</chapter-title><source>Proceedings, ICML, 2017</source><year>2017</year></element-citation></ref><ref id="bib0009"><element-citation publication-type="journal" id="sbref0009"><person-group person-group-type="author"><name><surname>Havrdova</surname><given-names>E.</given-names></name><name><surname>Galetta</surname><given-names>S.</given-names></name><name><surname>Hutchinson</surname><given-names>M.</given-names></name><name><surname>Stefoski</surname><given-names>D.</given-names></name><name><surname>Bates</surname><given-names>D.</given-names></name><name><surname>Polman</surname><given-names>C.H.</given-names></name><name><surname>O&#x02019;Connor</surname><given-names>P.W.</given-names></name><name><surname>Giovannoni</surname><given-names>G.</given-names></name><name><surname>Phillips</surname><given-names>J.T.</given-names></name><name><surname>Lublin</surname><given-names>F.D.</given-names></name><name><surname>Pace</surname><given-names>A.</given-names></name><name><surname>Kim</surname><given-names>R.</given-names></name><name><surname>Hyde</surname><given-names>R.</given-names></name></person-group><article-title>Effect of natalizumab on clinical and radiological disease activity in multiple sclerosis: a retrospective analysis of the natalizumab safety and efficacy in relapsing-remitting multiple sclerosis (AFFIRM) study</article-title><source>The Lancet Neurology</source><volume>8</volume><issue>3</issue><year>2009</year><fpage>254</fpage><lpage>260</lpage><pub-id pub-id-type="pmid">19201654</pub-id></element-citation></ref><ref id="bib0010"><element-citation publication-type="journal" id="sbref0010"><person-group person-group-type="author"><name><surname>Havrdova</surname><given-names>E.</given-names></name><name><surname>Giovannoni</surname><given-names>G.</given-names></name><name><surname>Stefoski</surname><given-names>D.</given-names></name><name><surname>Forster</surname><given-names>S.</given-names></name><name><surname>Umans</surname><given-names>K.</given-names></name><name><surname>Mehta</surname><given-names>L.</given-names></name><name><surname>Greenberg</surname><given-names>S.</given-names></name><name><surname>Elkins</surname><given-names>J.</given-names></name></person-group><article-title>Disease-activity-free status in patients with relapsing remitting multiple sclerosis treated with daclizumab high-yield process in the select study</article-title><source>Multiple Sclerosis Journal</source><volume>20</volume><issue>4</issue><year>2014</year><fpage>464</fpage><lpage>470</lpage><pub-id pub-id-type="pmid">24022270</pub-id></element-citation><note><p>PMID: 24022270.</p></note></ref><ref id="bib0011"><element-citation publication-type="book" id="sbref0011"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>G.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>van der Maaten</surname><given-names>L.</given-names></name><name><surname>Weinberger</surname><given-names>K.Q.</given-names></name></person-group><chapter-title>Densely connected convolutional networks</chapter-title><source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017</source><year>2017</year></element-citation></ref><ref id="bib0012"><element-citation publication-type="journal" id="sbref0012"><person-group person-group-type="author"><name><surname>Jain</surname><given-names>S.</given-names></name><name><surname>Ribbens</surname><given-names>A.</given-names></name><name><surname>Sima</surname><given-names>D.M.</given-names></name><name><surname>Cambron</surname><given-names>M.</given-names></name><name><surname>De Keyser</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>C.</given-names></name><name><surname>Barnett</surname><given-names>M.H.</given-names></name><name><surname>Van Huffel</surname><given-names>S.</given-names></name><name><surname>Maes</surname><given-names>F.</given-names></name><name><surname>Smeets</surname><given-names>D.</given-names></name></person-group><article-title>Two time point ms lesion segmentation in brain MRI: An expectation-maximization framework</article-title><source>Frontiers in Neuroscience</source><volume>10</volume><year>2016</year><fpage>576</fpage><pub-id pub-id-type="pmid">28066162</pub-id></element-citation></ref><ref id="bib0013"><element-citation publication-type="book" id="sbref0013"><person-group person-group-type="author"><name><surname>McKinley</surname><given-names>R.</given-names></name><name><surname>Maier</surname><given-names>R.</given-names></name><name><surname>Wiest</surname><given-names>R.</given-names></name></person-group><chapter-title>Ensembles of densely-connected cnns with label-uncertainty for brain tumor segmentation</chapter-title><person-group person-group-type="editor"><name><surname>Crimi</surname><given-names>A.</given-names></name><name><surname>Bakas</surname><given-names>S.</given-names></name><name><surname>Kuijf</surname><given-names>H.</given-names></name><name><surname>Menze</surname><given-names>B.</given-names></name><name><surname>Reyes</surname><given-names>M.</given-names></name></person-group><source>Proc Brainles 2018</source><year>2019</year><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc><fpage>456</fpage><lpage>465</lpage></element-citation></ref><ref id="bib0014"><element-citation publication-type="book" id="sbref0014"><person-group person-group-type="author"><name><surname>McKinley</surname><given-names>R.</given-names></name><name><surname>Rebsamen</surname><given-names>M.</given-names></name><name><surname>Meier</surname><given-names>R.</given-names></name><name><surname>Reyes</surname><given-names>M.</given-names></name><name><surname>Rummel</surname><given-names>C.</given-names></name><name><surname>Wiest</surname><given-names>R.</given-names></name></person-group><chapter-title>Few-shot brain segmentation from weakly labeled data with deep heteroscedastic multi-task networks</chapter-title><year>2019</year></element-citation><note><p>arXiv e-print, available at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1904.02436" id="intrrf0001">https://arxiv.org/abs/1904.02436</ext-link>.</p></note></ref><ref id="bib0015"><element-citation publication-type="book" id="sbref0015"><person-group person-group-type="author"><name><surname>McKinley</surname><given-names>R.</given-names></name><name><surname>Wepfer</surname><given-names>R.</given-names></name><name><surname>Aschwanden</surname><given-names>F.</given-names></name><name><surname>Grunder</surname><given-names>L.</given-names></name><name><surname>Muri</surname><given-names>R.</given-names></name><name><surname>Rummel</surname><given-names>C.</given-names></name><name><surname>Verma</surname><given-names>R.</given-names></name><name><surname>Weisstanner</surname><given-names>C.</given-names></name><name><surname>Reyes</surname><given-names>M.</given-names></name><name><surname>Salmen</surname><given-names>A.</given-names></name><name><surname>Chan</surname><given-names>A.</given-names></name><name><surname>Wagner</surname><given-names>F.</given-names></name><name><surname>Wiest</surname><given-names>R.</given-names></name></person-group><chapter-title>Simultaneous lesion and neuroanatomy segmentation in multiple sclerosis using deep neural network</chapter-title><year>2019</year></element-citation><note><p>eprint, available at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1901.07419" id="intrrf0002">https://arxiv.org/abs/1901.07419</ext-link>.</p></note></ref><ref id="bib0016"><element-citation publication-type="book" id="sbref0016"><person-group person-group-type="author"><name><surname>McKinley</surname><given-names>R.</given-names></name><name><surname>Wepfer</surname><given-names>R.</given-names></name><name><surname>Gundersen</surname><given-names>T.</given-names></name><name><surname>Wagner</surname><given-names>F.</given-names></name><name><surname>Chan</surname><given-names>A.</given-names></name><name><surname>Wiest</surname><given-names>R.</given-names></name><name><surname>Reyes</surname><given-names>M.</given-names></name></person-group><chapter-title>Nabla-net: A deep dag-like convolutional architecture for biomedical image segmentation</chapter-title><source>Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries</source><year>2016</year><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc><fpage>119</fpage><lpage>128</lpage></element-citation></ref><ref id="bib0017"><element-citation publication-type="journal" id="sbref0017"><person-group person-group-type="author"><name><surname>Moraal</surname><given-names>B.</given-names></name><name><surname>Meier</surname><given-names>D.S.</given-names></name><name><surname>Poppe</surname><given-names>P.A.</given-names></name><name><surname>Geurts</surname><given-names>J.J.G.</given-names></name><name><surname>Vrenken</surname><given-names>H.</given-names></name><name><surname>Jonker</surname><given-names>W.M.A.</given-names></name><name><surname>Knol</surname><given-names>D.L.</given-names></name><name><surname>van Schijndel</surname><given-names>R.A.</given-names></name><name><surname>Pouwels</surname><given-names>P.J.W.</given-names></name><name><surname>Pohl</surname><given-names>C.</given-names></name><name><surname>Bauer</surname><given-names>L.</given-names></name><name><surname>Sandbrink</surname><given-names>R.</given-names></name><name><surname>Guttmann</surname><given-names>C.R.G.</given-names></name><name><surname>Barkhof</surname><given-names>F.</given-names></name></person-group><article-title>Subtraction MR images in a multiple sclerosis multicenter clinical trial setting.</article-title><source>Radiology</source><volume>250 2</volume><year>2009</year><fpage>506</fpage><lpage>514</lpage><pub-id pub-id-type="pmid">19037018</pub-id></element-citation></ref><ref id="bib0018"><element-citation publication-type="book" id="sbref0018"><person-group person-group-type="author"><name><surname>Nair</surname><given-names>T.</given-names></name><name><surname>Precup</surname><given-names>D.</given-names></name><name><surname>Arnold</surname><given-names>D.L.</given-names></name><name><surname>Arbel</surname><given-names>T.</given-names></name></person-group><chapter-title>Exploring uncertainty measures in deep networks for multiple sclerosis lesion detection and segmentation</chapter-title><source>Proc. MICCAI 2018</source><year>2018</year></element-citation></ref><ref id="bib0019"><element-citation publication-type="book" id="sbref0019"><person-group person-group-type="author"><name><surname>Nixon</surname><given-names>R.</given-names></name><name><surname>Bergvall</surname><given-names>N.</given-names></name><name><surname>Tomic</surname><given-names>D.</given-names></name><name><surname>Sfikas</surname><given-names>N.</given-names></name><name><surname>Cutter</surname><given-names>G.</given-names></name><name><surname>Giovannoni</surname><given-names>G.</given-names></name></person-group><chapter-title>no evidence of disease activity: Indirect comparisons of oral therapies for the treatment of relapsing-remitting multiple sclerosis</chapter-title><year>2014</year></element-citation></ref><ref id="bib0020"><element-citation publication-type="journal" id="sbref0020"><person-group person-group-type="author"><name><surname>Polman</surname><given-names>C.H.</given-names></name><name><surname>Reingold</surname><given-names>S.C.</given-names></name><name><surname>Banwell</surname><given-names>B.</given-names></name><name><surname>Clanet</surname><given-names>M.</given-names></name><name><surname>Cohen</surname><given-names>J.A.</given-names></name><name><surname>Filippi</surname><given-names>M.</given-names></name><name><surname>Fujihara</surname><given-names>K.</given-names></name><name><surname>Havrdova</surname><given-names>E.</given-names></name><name><surname>Hutchinson</surname><given-names>M.</given-names></name><name><surname>Kappos</surname><given-names>L.</given-names></name><name><surname>Lublin</surname><given-names>F.D.</given-names></name><name><surname>Montalban</surname><given-names>X.</given-names></name><name><surname>O&#x02019;Connor</surname><given-names>P.</given-names></name><name><surname>Sandberg-Wollheim</surname><given-names>M.</given-names></name><name><surname>Thompson</surname><given-names>A.J.</given-names></name><name><surname>Waubant</surname><given-names>E.</given-names></name><name><surname>Weinshenker</surname><given-names>B.</given-names></name><name><surname>Wolinsky</surname><given-names>J.S.</given-names></name></person-group><article-title>Diagnostic criteria for multiple sclerosis: 2010 revisions to the McDonald criteria</article-title><source>Annals of Neurology</source><volume>69</volume><issue>2</issue><year>2011</year><fpage>292</fpage><lpage>302</lpage><pub-id pub-id-type="pmid">21387374</pub-id></element-citation><note><p><ext-link ext-link-type="uri" xlink:href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/ana.22366" id="intrrf0003">https://onlinelibrary.wiley.com/doi/pdf/10.1002/ana.22366</ext-link>.</p></note></ref><ref id="bib0021"><element-citation publication-type="journal" id="sbref0021"><person-group person-group-type="author"><name><surname>Reuter</surname><given-names>M.</given-names></name><name><surname>Schmansky</surname><given-names>N.J.</given-names></name><name><surname>Rosas</surname><given-names>H.D.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name></person-group><article-title>Within-subject template estimation for unbiased longitudinal image analysis</article-title><source>NeuroImage</source><volume>61</volume><issue>4</issue><year>2012</year><fpage>1402</fpage><lpage>1418</lpage><pub-id pub-id-type="pmid">22430496</pub-id></element-citation></ref><ref id="bib0022"><element-citation publication-type="journal" id="sbref0022"><person-group person-group-type="author"><name><surname>Ronneberger</surname><given-names>O.</given-names></name><name><surname>Fischer</surname><given-names>P.</given-names></name><name><surname>Brox</surname><given-names>T.</given-names></name></person-group><article-title>U-Net: Convolutional Networks for Biomedical Image Segmentation</article-title><source>Medical Image Computing and Computer-Assisted Intervention&#x02013;MICCAI 2015</source><year>2015</year><fpage>234</fpage><lpage>241</lpage></element-citation></ref><ref id="bib0023"><element-citation publication-type="journal" id="sbref0023"><person-group person-group-type="author"><name><surname>Rudie</surname><given-names>J.D.</given-names></name><name><surname>Mattay</surname><given-names>R.R.</given-names></name><name><surname>Schindler</surname><given-names>M.</given-names></name><name><surname>Steingall</surname><given-names>S.</given-names></name><name><surname>Cook</surname><given-names>T.S.</given-names></name><name><surname>Loevner</surname><given-names>L.A.</given-names></name><name><surname>Schnall</surname><given-names>M.D.</given-names></name><name><surname>Mamourian</surname><given-names>A.C.</given-names></name><name><surname>Bilello</surname><given-names>M.</given-names></name></person-group><article-title>An initiative to reduce unnecessary gadolinium-based contrast in multiple sclerosis patients</article-title><source>Journal of the American College of Radiology</source><volume>16</volume><issue>9, Part A</issue><year>2019</year><fpage>1158</fpage><lpage>1164</lpage><pub-id pub-id-type="pmid">31092348</pub-id></element-citation></ref><ref id="bib0024"><element-citation publication-type="journal" id="sbref0024"><person-group person-group-type="author"><name><surname>Salem</surname><given-names>M.</given-names></name><name><surname>Cabezas</surname><given-names>M.</given-names></name><name><surname>Valverde</surname><given-names>S.</given-names></name><name><surname>Pareto</surname><given-names>D.</given-names></name><name><surname>Oliver</surname><given-names>A.</given-names></name><name><surname>Salvi</surname><given-names>J.</given-names></name><name><surname>lex Rovira</surname></name><name><surname>Llad</surname><given-names>X.</given-names></name></person-group><article-title>A supervised framework with intensity subtraction and deformation field features for the detection of new t2-w lesions in multiple sclerosis</article-title><source>NeuroImage: Clinical</source><volume>17</volume><year>2018</year><fpage>607</fpage><lpage>615</lpage><pub-id pub-id-type="pmid">29234597</pub-id></element-citation></ref><ref id="bib0025"><element-citation publication-type="journal" id="sbref0025"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>P.</given-names></name><name><surname>Gaser</surname><given-names>C.</given-names></name><name><surname>Arsic</surname><given-names>M.</given-names></name><name><surname>Buck</surname><given-names>D.</given-names></name><name><surname>F&#x000f6;rschler</surname><given-names>A.</given-names></name><name><surname>Berthele</surname><given-names>A.</given-names></name><name><surname>Hoshi</surname><given-names>M.</given-names></name><name><surname>Ilg</surname><given-names>R.</given-names></name><name><surname>Schmid</surname><given-names>V.J.</given-names></name><name><surname>Zimmer</surname><given-names>C.</given-names></name><name><surname>Hemmer</surname><given-names>B.</given-names></name><name><surname>M&#x000fc;hlau</surname><given-names>M.</given-names></name></person-group><article-title>An automated tool for detection of flair-hyperintense white-matter lesions in multiple sclerosis</article-title><source>NeuroImage</source><volume>59</volume><year>2012</year><fpage>3774</fpage><lpage>3783</lpage><pub-id pub-id-type="pmid">22119648</pub-id></element-citation></ref><ref id="bib0026"><element-citation publication-type="journal" id="sbref0026"><person-group person-group-type="author"><name><surname>Valverde</surname><given-names>S.</given-names></name><name><surname>Cabezas</surname><given-names>M.</given-names></name><name><surname>Roura</surname><given-names>E.</given-names></name><name><surname>Gonzalez-Villa</surname><given-names>S.</given-names></name><name><surname>Pareto</surname><given-names>D.</given-names></name><name><surname>Vilanova</surname><given-names>J.C.</given-names></name><name><surname>Ramio-Torrenta</surname><given-names>L.</given-names></name><name><surname>Rovira</surname><given-names>A.</given-names></name><name><surname>Oliver</surname><given-names>A.</given-names></name><name><surname>Llado</surname><given-names>X.</given-names></name></person-group><article-title>Improving automated multiple sclerosis lesion segmentation with a cascaded 3D convolutional neural network approach</article-title><source>Neuroimage</source><volume>155</volume><year>2017</year><fpage>159</fpage><lpage>168</lpage><pub-id pub-id-type="pmid">28435096</pub-id></element-citation></ref><ref id="bib0027"><element-citation publication-type="journal" id="sbref0027"><person-group person-group-type="author"><name><surname>Valverde</surname><given-names>S.</given-names></name><name><surname>Salem</surname><given-names>M.</given-names></name><name><surname>Cabezas</surname><given-names>M.</given-names></name><name><surname>Pareto</surname><given-names>D.</given-names></name><name><surname>Vilanova</surname><given-names>J.C.</given-names></name><name><surname>Rami&#x000f3;-Torrent&#x000e0;</surname><given-names>L.</given-names></name><name><surname>Rovira</surname><given-names>A.</given-names></name><name><surname>Salvi</surname><given-names>J.</given-names></name><name><surname>Oliver</surname><given-names>A.</given-names></name><name><surname>Llad&#x000f3;</surname><given-names>X.</given-names></name></person-group><article-title>One-shot domain adaptation in multiple sclerosis lesion segmentation using convolutional neural networks</article-title><source>NeuroImage. Clinical</source><year>2018</year><fpage>101638</fpage><pub-id pub-id-type="pmid">30555005</pub-id></element-citation></ref></ref-list><ack id="ack0001"><title>Acknowledgements</title><p>This research was supported by the Swiss Multiple Sclerosis Society (&#x0201c;Automatic segmentation of MS lesions, brain volumetry and morphometry: Proposal of a diagnostic tool for disease monitoring&#x0201d;), a Freenovation grant from the Novartis Forschungsstiftung (DeepSCAN cortex) and a reserach agreement with Biogen (Study CHE-TYS-18-11316, An automated tool for surface-based regional morphometry in individualized longitudinal assessment of RRMS patients on Natalizumab).</p></ack></back></article>