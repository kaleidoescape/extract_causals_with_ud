<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Heliyon</journal-id><journal-id journal-id-type="iso-abbrev">Heliyon</journal-id><journal-title-group><journal-title>Heliyon</journal-title></journal-title-group><issn pub-type="epub">2405-8440</issn><publisher><publisher-name>Elsevier</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">31938750</article-id><article-id pub-id-type="pmc">6953713</article-id><article-id pub-id-type="publisher-id">S2405-8440(20)30017-7</article-id><article-id pub-id-type="doi">10.1016/j.heliyon.2020.e03172</article-id><article-id pub-id-type="publisher-id">e03172</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>ASGOP: An aggregated similarity-based greedy-oriented approach for relational DDBSs design</article-title></title-group><contrib-group><contrib contrib-type="author" id="au1"><name><surname>Amer</surname><given-names>Ali A.</given-names></name><email>aliaaa2004@yahoo.com</email><email>aliaaa2004@gmail.com</email><xref rid="aff1" ref-type="aff">a</xref><xref rid="cor1" ref-type="corresp">&#x02217;</xref></contrib><contrib contrib-type="author" id="au2"><name><surname>Mohamed</surname><given-names>Marghny H.</given-names></name><xref rid="aff2" ref-type="aff">b</xref></contrib><contrib contrib-type="author" id="au3"><name><surname>Al_Asri</surname><given-names>Khaled</given-names></name><xref rid="aff3" ref-type="aff">c</xref></contrib></contrib-group><aff id="aff1"><label>a</label>Taiz University, Yemen</aff><aff id="aff2"><label>b</label>Assiut University, Egypt</aff><aff id="aff3"><label>c</label>Hajjah University, Yemen</aff><author-notes><corresp id="cor1"><label>&#x02217;</label>Corresponding author. <email>aliaaa2004@yahoo.com</email><email>aliaaa2004@gmail.com</email></corresp></author-notes><pub-date pub-type="pmc-release"><day>09</day><month>1</month><year>2020</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.--><pub-date pub-type="collection"><month>1</month><year>2020</year></pub-date><pub-date pub-type="epub"><day>09</day><month>1</month><year>2020</year></pub-date><volume>6</volume><issue>1</issue><elocation-id>e03172</elocation-id><history><date date-type="received"><day>6</day><month>4</month><year>2019</year></date><date date-type="rev-recd"><day>30</day><month>6</month><year>2019</year></date><date date-type="accepted"><day>2</day><month>1</month><year>2020</year></date></history><permissions><copyright-statement>&#x000a9; 2020 The Author(s)</copyright-statement><copyright-year>2020</copyright-year><license license-type="CC BY" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p></license></permissions><abstract id="abs0010"><p>In the literature of distributed database system (DDBS), several methods sought to meet the satisfactory reduction on transmission cost (TC) and were seen substantially effective. Data Fragmentation, site clustering, and data distribution have been considered the major leading TC-mitigating influencers. Sites clustering, on one hand, aims at grouping sites appropriately according to certain similarity metrics. On the other hand, data distribution seeks to allocate the fragmented data into clusters/sites properly. The combination of these methods, however, has been shown fruitful concerning TC reduction along with network overheads. In this work, hence, a heuristic clustering-based approach for vertical fragmentation and data allocation is meticulously designed. The focus is directed on proposing an influential solution for improving relational DDBS throughputs across an aggregated similarity-based fragmentation procedure, an effective site clustering and a greedy algorithm-driven data allocation model. Moreover, the data replication is also considered so TC is further minimized. Through the delineated-below evaluation, the findings of experimental implementation have been observed to be promising.</p></abstract><abstract abstract-type="teaser" id="abs0015"><p>Information science; Computer science; Vertical fragmentation; Clustering; Data allocation; Data replication; DDBS; Greedy algorithms; ASGOP</p></abstract><kwd-group id="kwrds0010"><title>Keywords</title><kwd>Information science</kwd><kwd>Computer science</kwd><kwd>Vertical fragmentation</kwd><kwd>Clustering</kwd><kwd>Data allocation</kwd><kwd>Data replication</kwd><kwd>DDBS</kwd><kwd>Greedy algorithms</kwd><kwd>ASGOP</kwd></kwd-group></article-meta></front><body><sec id="sec1"><label>1</label><title>Introduction</title><p id="p0010">Over the past forty years, numerous approaches have been evolved in DDBS literature to functionally manage the ever-growing data. Nevertheless, several issues for improving DDBS design quality are still open-ended challenges. Particularly speaking, the relational distributed database which is still growing in popularity. Consequently, the continuous interest is also still emphasized towards finding the well-designed approaches to keep the sustainability of DDBS performance. On the other hand, the most critical contributor in performance is that how much amount of data is being transmitted over the network when distributed queries are under processing. This dominant contributor has widely known as Transmission Costs (TC) for which most of the previous DDBS works had come to find a solution of influential impact. Moreover, it has been noted that almost the majority of earlier works have never been recorded to come up with a clear definition for this contributor by which performance is set to be graded (<xref rid="bib6" ref-type="bibr">Amer et&#x000a0;al., 2018a</xref>, <xref rid="bib7" ref-type="bibr">b</xref>).</p><p id="p0015">In the meantime, the wealthy existence of design approaches leads to more confusion when it comes to select certain approach to design DDBS. Fortunately, to lessen this burden, a consensus on the principles and concepts which ground these approaches still exist (<xref rid="bib6" ref-type="bibr">Amer et&#x000a0;al., 2018a</xref>, <xref rid="bib7" ref-type="bibr">b</xref>). Additionally, the ever-progressing researches in DDBS and distributed computing domains are still in the development now and then to tackle the DDBS design challenges. Some of these approaches are subtly optimized or well extended to incorporate other techniques straightforwardly to sustain DDBS throughput (<xref rid="bib18" ref-type="bibr">Raouf et&#x000a0;al., 2018</xref>; <xref rid="bib13" ref-type="bibr">Luong et&#x000a0;al., 2018</xref>; <xref rid="bib22" ref-type="bibr">Wiese et&#x000a0;al., 2016</xref>; <xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib5" ref-type="bibr">Amer, 2018</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>). The findings of these approaches have been reinforced by placing them directly under the test on either synthesized data in a simulated environment or on real datasets. In this work, therefore, we seek to present a new approach with the major purpose of significantly decreasing TC. The proposed approach was essentially designed to involve and develop: (1) an aggregated similarity between queries to fragment data using the single-linkage Agglomerative Hierarchical Clustering (AHC) process, (2) a greedy-based data allocation model to allocate the resulted fragments, and (3) integrate the site clustering procedure which was drawn in (<xref rid="bib4" ref-type="bibr">Amer et&#x000a0;al., 2017</xref>). It is worth indicating that the choice of the single-linkage has been on purpose as our work seeks to join each cluster pair based on the maximum similarity value between the cluster pair. In other words, the closest distance is adopted to define the similarity between each cluster pair. Data allocation, on the other hand, was made using a greedy-based algorithm which is highly contingent on the dynamic programming (Knapsack problem, in this work). That is, data allocation was being treated as an optimization problem. Moreover, a theoretical comparison and empirical evaluation for the proposed work of this paper is made with state-of-art approaches. In fact, the evaluation results have been promising in terms of the sustainability of DDBS performance and TC reduction.</p><p id="p0020">The main contributions of this paper are listed as follows: (1) leveraging data fragmentation algorithm based on an aggregated similarity. The similarity measure is anticipated to reduce the number of iterations needed to perform AHC and then find solution space of smaller size comparing with the state-of-art. Moreover, the proposed approach does not need the query frequency matrix to perform fragmentation, nor affinity matrix or even attribute usage matrix which makes our work the best option to design DDBS at the initial stage of design; (2) drawing the site clustering process to produce minimum number of highly balanced clusters. The clustering process of queries, on the other extreme, struggles to find the balanced cluster as each cluster must have at least (&#x0221a;N) query to help distributing the workload over network sites/clusters while distributed queries are being handled; (3) suggesting a greedy-based data allocation algorithm to contribute in minimizing TC. That is, dealing with data allocation as an optimization problem and finding a model to address this problem. Finally, along this paper, for the sake of readability and simplicity, the proposed approach is given an acronym named &#x0201c;ASGOP&#x0201d;. This acronym, on the other hand, is found by taking the first letters of each word of paper's title as follows; An Aggregated &#x0201c;A&#x0201d;; Similarity-based &#x0201c;S&#x0201d;; Greedy-Oriented &#x0201c;GO&#x0201d; and Approach &#x0201c;P&#x0201d;.</p><p id="p0025">The remaining of this paper is structured as follows; in section <xref rid="sec2" ref-type="sec">(2)</xref>, a deeply-made investigation for the earlier works which are closely related is presented. Section <xref rid="sec3" ref-type="sec">(3)</xref> holds the proposed methodology including data fragmentation procedure, the proposed aggregated similarity measure, AHC review in a brief, fragmentation evaluator, site clustering process and data allocation cost model foundations and algorithms. Section <xref rid="sec4" ref-type="sec">(4)</xref> elegantly provides experimental setup of ASGOP, datasets descriptions, the running example to draw the proposed work mechanism and performance evaluation. An experimental implementation along with the discussion of findings are drawn in section <xref rid="sec5" ref-type="sec">(5)</xref>. Finally, in section <xref rid="sec6" ref-type="sec">(6)</xref>, the conclusions and future work directions are given.</p></sec><sec id="sec2"><label>2</label><title>Related work</title><sec id="sec2.1"><label>2.1</label><title>Data fragmentation</title><p id="p0030">Data fragmentation (Vertical, Horizontal or Mixed) has long seen to play the key role in DDBS performance enhancement. As a matter of fact, it is commonly agreed upon that the proper the data fragmentation and allocation (including replication) are, the highly likely that the overall performance of DDBS is sustainably satisfied (<xref rid="bib16" ref-type="bibr">Nashat and Amer, 2018</xref>). In (<xref rid="bib16" ref-type="bibr">Nashat and Amer, 2018</xref>), a fine-grained taxonomy was drawn. This taxonomy was extensively examined that more than one hundred references (Chapters, Papers, Reports, Books, etc) were investigated in both static and dynamic environments. The key drive behind this taxonomy was to find the drawbacks and shortcomings from which most of earlier works were observed to be suffering. Data fragmentation, data allocation and replication were all studied and then classified according to taxonomy-centric metrics. The concern was sought to specify these defects so a more effective methods for DDBS performance improvement are set to be designed. The reduction of TC (including communication costs and response time) was the major motivators for which a good number of previous works sought to quench. Data locality maximization and data remote access mitigation were observed to be crucial issues that always need to be tackled wisely so TC is decreased.</p><p id="p0035"><xref rid="bib18" ref-type="bibr">Raouf et&#x000a0;al. (2018)</xref> developed a cloud-based architecture for DDBS design. Data allocation for the resulted fragments along with the data replication at the run time were also considered so DDBSMs were able to work in parallel to process the queries of client's. The work had also studied the clustering of sites to further increase DDBS throughputs by maximizing locality of concerned data. Nevertheless, some drawbacks are recorded such as the selection of leaders of clusters which was intuitive and impractical to be considered in an efficient environment since almost most of DDBSs today have the same specifications for all sites, specifically in peer-two-peer network. In the meanwhile, <xref rid="bib22" ref-type="bibr">Wiese et&#x000a0;al. (2016)</xref> studied data replication problem (DRP) deeply that DRP was presented as an integer linear problem with the assumption of having the overlapping horizontally-split fragments. That is, the replication problem was treated as an optimization problem to gain the intended aim of having fragments' copies at the less number of sites of network. In the same line, <xref rid="bib14" ref-type="bibr">Mahi et&#x000a0;al. (2018)</xref> proposed a method based on Particle Swarm Optimization (PSO) algorithm to lessen TC through solving data allocation problem (DAP) by using PSO algorithm. Work's performance was observed and graded on 20 different test problems.</p><p id="p0040">On the other hand (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib5" ref-type="bibr">Amer, 2018</xref>), came to incorporate site clustering and the cost-effective model of data allocation and replication into one individual work. The results obtained were highly encouraging. Moreover, the authors in (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>) drew the results in both cases, with site clustering and without site clustering to draw the impact of site clustering on DDBS performance. On the same page (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>), came to present an enhanced version of (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>). This works was evaluated against (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>) and shown to behave slightly better in most cases. A small-scale experimental study was conducted to exhibit the effectiveness of enhanced approach. A different data allocation scenarios were addressed, and the data replication was carried out using the replication model proposed in (<xref rid="bib22" ref-type="bibr">Wiese et&#x000a0;al., 2016</xref>). A significant enhancement was recorded in terms of overall DDBSs performance through TC mitigation. The constraints of clusters and sites were maintained to stimulate the real-world DDBS and tightened the proposed work's effectiveness.</p><p id="p0045">Lastly, <xref rid="bib13" ref-type="bibr">Luong et&#x000a0;al. (2018)</xref> proposed k-Means rough clustering technique for vertical fragmentation. The distance and similarity were combined together with the upper and lower approximations to better proposed algorithm. The error average cost was seen to be high as both upper and lower approximations were addressed during the process of updating the new concentration.</p></sec><sec id="sec2.2"><label>2.2</label><title>Data allocation</title><p id="p0050">In order for DAP problem to be solved, a good number of approaches were proposed in literature, and profoundly studied for both redundant and non-redundant states. In (<xref rid="bib15" ref-type="bibr">Mukherjee, 2011</xref>), a cost model for data distribution over sites was presented to lessen communication costs. On the other hand (<xref rid="bib21" ref-type="bibr">Tonini and Siqueira, 2013</xref>), came with an algorithm to find a distributed allocation schema so query performance was improved based on query history and data patterns analysis. A large biological database, as case study, was used for algorithm evaluation and promising results were observed.</p><p id="p0055">However, static data allocation was consensually seen ineffectual in terms of DDBS performance in the ever-changing environment. So, to tackle this deficit, a well-structured approaches of dynamic nature are needed for data allocation in dynamic environment. A holistic data allocation approach was first proposed in (<xref rid="bib8" ref-type="bibr">Apers, 1988</xref>), to find a solution for the problem of dynamically assigning data over network sites. In fact, this approach has been the core upon which many existing algorithms for dynamic data allocation have been built. For the same purpose, in <xref rid="bib23" ref-type="bibr">Wolfson et&#x000a0;al. (1997)</xref>, a dynamic algorithm (named, adaptive data replication, ADR) was developed within a framework for dynamic data allocation. A genetic algorithm-based method was provided in (<xref rid="bib17" ref-type="bibr">Rahmani et&#x000a0;al., 2009</xref>) to solve data allocation problem in two steps. Firstly, site clusters was formed based on communication costs; secondly, the targeted data were scattered over clusters using GA.</p><p id="p0060">By the same token (<xref rid="bib20" ref-type="bibr">Singh, 2016</xref>), proposed a data allocation framework for non-replicated dynamic DDBS using the threshold and time constraint algorithms (TTCA). TTCA performance was experimentally compared with threshold algorithm on the basis of the total cost of reallocation and the number of fragment migrations over network. The findings illustrated that TTCA is more effective (in terms of performance promotion) than threshold algorithm chiefly as access frequency pattern changes swiftly. In (<xref rid="bib10" ref-type="bibr">Kamali et&#x000a0;al., 2011</xref>), an algorithm for tackling data allocation in replicated DDBS was evolved. Several aspects were included such as replication strategy and &#x0201c;non-uniform&#x0201d; distance between sites of network. The results obtained had shown that this algorithm yielded a good solution to data allocation in DDS. Some flaws, on the other hand, were noted like its being incapable of determining the number of fragment replica.</p><p id="p0065">In the same line, a dynamic approach for fragment allocation was drawn in (<xref rid="bib15" ref-type="bibr">Mukherjee, 2011</xref>). Time constraints, threshold value and the transmitted volume of data were taken into account. The problem of data allocation in the ever-changing environment was studied in (<xref rid="bib11" ref-type="bibr">Li and Wong, 2013</xref>). Firstly, problem was defined and the use of time series models was enabled to perform short-term load forecasting. That is, the node number adjustment and fragment reallocation could be determined in advance. Subsequently, the nodes&#x02019; over-loadings and performance deterioration could be evaded particularly when fragment migrations is grown steadily. The load balancing was observed under the assumption that the future workloads can be modelled when time series was noted. In essence, the algorithm was presented to prove that the time series-based work outweighed threshold-based.</p><p id="p0070">By the same token, a non-replicated data allocation approach was drawn in (<xref rid="bib1" ref-type="bibr">Abdalla et&#x000a0;al., 2014</xref>) in a dynamic environment. The given algorithm called &#x0201c;Performance Optimality Enhancement Algorithm&#x0201d; (POEA). It was destined to comprehensively integrate some concepts used in earlier algorithms. The time and sites constraints and the changing patterns of data access were taken into account. Moreover, the shortest path problem between sites was incorporated into POEA to be used when migration decision was being made. This step led to significant decrease in data migration. The experimental results draw a solid evidence that &#x0201c;POEA&#x0201d; had efficiently contributed in transmission costs and response time mitigation. Finally, to solve DAP problem (<xref rid="bib12" ref-type="bibr">Lotfi, 2019</xref>), proposed a hybrid strategy using the differential evolution (DE) algorithm and variable neighborhood search (VNS) technique. The author sought to raise DE performance across the selection and crossover operators. The proposed approach aimed to navigate the search space via DE and performed further navigation using the neighborhood search technique. This approach was experimentally tested against state-of-the-art techniques and shown effective.</p></sec></sec><sec id="sec3"><label>3</label><title>The proposed methodology</title><p id="p0075">In this section we present our methodology for data fragmentation and allocation, as shown in Figures&#x000a0;<xref rid="fig1" ref-type="fig">1</xref> and <xref rid="fig2" ref-type="fig">2</xref>.<fig id="fig1"><label>Figure&#x000a0;1</label><caption><p>ASGOP diagram.</p></caption><alt-text id="alttext0010">Figure&#x000a0;1</alt-text><graphic xlink:href="gr1"/></fig><fig id="fig2"><label>Figure&#x000a0;2</label><caption><p>The schemes filtering process.</p></caption><alt-text id="alttext0015">Figure&#x000a0;2</alt-text><graphic xlink:href="gr2"/></fig></p><sec id="sec3.1"><label>3.1</label><title>Data fragmentation procedure</title><p id="p0080">The aggregated similarity measure is basically proposed to discover the hidden ties between queries. These ties would be effectively used to fragment database under consideration. Distance Matrix (DM) is found using the aggregated similarity and then passed into the agglomerative hierarchical clustering (AHC) process. The results of AHC, which are the overlapping clusters, would then be fed into the filtering process as depicted in <xref rid="fig2" ref-type="fig">Figure&#x000a0;2</xref> to produce the non-overlapping schemes. After that, schemes would be moved into the proposed fragmentation evaluator (FE). FE (presented in section <xref rid="sec3.5" ref-type="sec">3.5</xref>) seeks to find the survival schema based on the minimum remote access and maximum local access patterns. That is, the survival schema has the least remote access and the highest local access patterns. The overall process is visualized in <xref rid="fig1" ref-type="fig">Figure&#x000a0;1</xref>.</p><p id="p0085"><xref rid="fig1" ref-type="fig">Figure&#x000a0;1</xref> briefly exhibits the heuristics of ASGOP starting with collecting requirements (represented by dataset and queries). Then, the aggregated similarity function (see <xref rid="fd5" ref-type="disp-formula">Eqn 5</xref>) would be directly applied on queries to provide distance matrix (similarity matrix in ASGOP). This matrix is then passed into AHC to provide data fragments (query clusters). Query clusters (as overlapping schemes) are set to be contained in a solution space. Space in its turn are placed into the filtering process (see <xref rid="fig2" ref-type="fig">Figure&#x000a0;2</xref>). The outputs of filtering process are the disjointed fragments which would be already drawn in the survival schema based on the results of fragmentation evaluator (see section <xref rid="sec3.5" ref-type="sec">3.5</xref>.). After that, the sites of network is set to be clustered to yield cluster of sites and pave the way to starting process of data allocation. The final step is the approach evaluation which has been done in the discussion section below.</p></sec><sec id="sec3.2"><label>3.2</label><title>Similarity measure</title><p id="p0090">The similarity measures have long been defined in literature and as the metrics using which how much alike two data points are set to be recognized. On the other hand, in the context of database, data mining, pattern recognition and almost all scientific fields, the similarity measure is used inversely as a distance (dis) between dimensions/features. Normally, if &#x02018;dis&#x02019; is small, it is set to reflect the high degree of similarity. Conversely, if &#x02018;dis&#x02019; is large, this similarity is low. Strictly speaking, similarity measure is basically contingent on the domain at hand. As a matter of fact, similarity has to be computed accurately when it is being considered across unrelated dimensions (features). Furthermore, the absolute values of similarity should be normalized (smoothed) to give the relative values so the dominance problem by features of higher values is eliminated. Simply put, similarity are set to be in the range [0, 1] as shown in <xref rid="fd1" ref-type="disp-formula">Eq. (1)</xref>.<disp-formula id="fd1"><label>(1)</label><mml:math id="M1" altimg="si1.svg" alttext="Equation 1."><mml:mrow><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>V</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo linebreak="badbreak">&#x0003c;</mml:mo><mml:mi>V</mml:mi><mml:mo linebreak="badbreak">&#x0003c;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02201;</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02201;</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow><mml:mo>;</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">&#x02229;</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mo linebreak="badbreak">&#x02260;</mml:mo><mml:mo linebreak="goodbreak">&#x02205;</mml:mo></mml:mrow></mml:math></disp-formula>Where P<sub>i</sub> and P<sub>j</sub> are two queries (represented as two points in the space of dimensions), i and j are just indices, and &#x0201c;V&#x0201d; is the value of similarity. In case (1), if both queries are equal, this means that these queries are equal, or one query is being duplicated. In case (2) either one query is being fully or partially contained within the other, their similarity is dependent on the degree of attributes containment. For example, if we have Q<sub>1</sub> (A<sub>1</sub>, A<sub>2</sub>) and Q<sub>2</sub> (A<sub>1</sub>, A<sub>2</sub>, A<sub>6</sub>), the value of V would be 2 out of 3, and Q1 is fully contained in Q2. Case (3), on the other hand, draw a zero similarity when both queries share non attribute. In this paper, thus, two similarity measures are being combined to produce an aggregated similarity as follows;</p><sec id="sec3.2.1"><label>3.2.1</label><title>Problem formulation</title><p id="p0095">Provided that we have a set of &#x0201c;A&#x0201d; attributes A = {A<sub>1</sub>, A<sub>2</sub>, ..., A<sub>n</sub>} required by a set of &#x0201c;Q&#x0201d; queries, Qs = {Q<sub>1</sub>, Q<sub>2</sub>, ..., Q<sub>q</sub>}. For each query pair Q<sub>i</sub> and Q<sub>j</sub>, both queries are treated as a string and the similarity measure is applied directly on attributes &#x0201c;As&#x0201d; of both queries. Following the fragmentation procedure described in section <xref rid="sec3.1" ref-type="sec">(3.1.)</xref>, these queries would be already grouped into Cn clusters Cq<sub>1</sub>,Cq<sub>2</sub>&#x02026;., Cq<sub>cn</sub>. These clusters would represent the overlapping data fragments, Fs = {F<sub>1</sub>, F<sub>2</sub>, &#x02026;, F<sub>fn</sub>}.</p></sec><sec id="sec3.2.2"><label>3.2.2</label><title>Hamming similarity measure (HS)</title><p id="p0100">It has long been observed as an effective measure to find the match between strings. In its simplest definition, HS is computed using hamming distance (HD) which gives the number of shared digits between two string numbers (<xref rid="bib9" ref-type="bibr">Hamming, 1950</xref>). For instance, given Q<sub>1</sub> (1101) and Q<sub>2</sub> (1010) as two queries represented by attribute existence in both queries (either &#x0201c;1&#x0201d; present attribute or &#x0201c;0&#x0201d; absent attribute) which are represented as string numbers; HD would have the difference value of (3) which will be then normalized by the number of all attributes (4 attributes) to give (3/4 = 0.75). However, as ASGOP seeks to find similarity, the similarity value of HD is (1&#x02013;0.75) which is (0.25) because only the first digit in both numbers is being shared. Driven by this idea, this measure was combined in ASGOP with the nearby measure to produce an aggregated similarity measure which has been applied on queries directly. Queries are treated as strings and the major focus is to find the common attributes (seen as letters) between each query pair (seen as strings). The computation of HD as similarity measure is given in Eqs. <xref rid="fd2" ref-type="disp-formula">(2)</xref> and <xref rid="fd3" ref-type="disp-formula">(3)</xref>. The similarity is sought to be firstly found using HD and is then aggregated with similarity value of nearby measure.<disp-formula id="fd2"><label>(2)</label><mml:math id="M2" altimg="si2.svg" alttext="Equation 2."><mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mo linebreak="badbreak">&#x02212;</mml:mo><mml:mi>H</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.25em"/><mml:mi>q</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>O</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>Where &#x02018;Dis&#x02019; represents the value of distance (difference) between different queries, and Q<sub>i</sub> and Q<sub>j</sub> are two different queries. However, since ASGOP seeks to find similarity, <xref rid="fd3" ref-type="disp-formula">Eq. (3)</xref> is proposed.<disp-formula id="fd3"><label>(3)</label><mml:math id="M3" altimg="si3.svg" alttext="Equation 3."><mml:mrow><mml:mi>H</mml:mi><mml:mi>S</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mspace width="0.25em"/><mml:mn>1</mml:mn><mml:mo linebreak="goodbreak">&#x02212;</mml:mo><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mfrac><mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mo linebreak="badbreak">&#x02212;</mml:mo><mml:mi>H</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>&#x02018;Na&#x02019; in <xref rid="fd3" ref-type="disp-formula">Eq. (3)</xref> is the number of all considered attributes, and is used as normalization factor as done in the given-above &#x0201c;toy&#x0201d; example.</p></sec><sec id="sec3.2.3"><label>3.2.3</label><title>Nearby similarity measure (NM)</title><p id="p0105">This measure is used to emphasize the similarity found by HD. In other words, whenever HD similarity value is found weak, NM would struggle to reinforce similarity between queries in two dimension space, <xref rid="fd4" ref-type="disp-formula">Eq. (4)</xref>.<disp-formula id="fd4"><label>(4)</label><mml:math id="M4" altimg="si4.svg" alttext="Equation 4."><mml:mrow><mml:mi>N</mml:mi><mml:mi>M</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mn>2</mml:mn><mml:mo linebreak="badbreak">&#x000d7;</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>Where Q<sub>i</sub>, Q<sub>j</sub> and Q<sub>ij</sub> represents the number of attributes involved in both queries Q<sub>i</sub> and Q<sub>j</sub> severally, and the common attributes which are shared by both queries Q<sub>i</sub> and Q<sub>j</sub> respectively.</p><p id="p0110"><bold>Nearby measure example</bold>: recall the same queries that are already drawn in HD example (Q<sub>1</sub> and Q<sub>2</sub>), the value Q<sub>ij</sub> is &#x02018;2&#x02019; as both queries only share two attributes and the similarity measure is (4/6) which is 0.67.</p></sec><sec id="sec3.2.4"><label>3.2.4</label><title>Aggregated similarity measure</title><p id="p0115">As a combination of both HD and NM, the aggregated similarity is drawn in <xref rid="fd5" ref-type="disp-formula">Eq. (5)</xref>:<disp-formula id="fd5"><label>(5)</label><mml:math id="M5" altimg="si5.svg" alttext="Equation 5."><mml:mrow><mml:mi>A</mml:mi><mml:mi>g</mml:mi><mml:mi>g</mml:mi><mml:mo linebreak="badbreak">&#x02212;</mml:mo><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mspace width="0.25em"/><mml:mn>0.5</mml:mn><mml:mo linebreak="badbreak">&#x02217;</mml:mo><mml:mi>H</mml:mi><mml:mi>S</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mn>0.5</mml:mn><mml:mo linebreak="goodbreak">&#x02217;</mml:mo><mml:mspace width="0.25em"/><mml:mi>N</mml:mi><mml:mi>M</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="p0120">Using this Equation, the optimal similarity is met if both queries were like each other, and similarity would have the value of &#x0201c;1&#x0201d;. Looking back at the given-above examples (1 and 2), the aggregated similarity is 0.74, which is still bigger than cosine measure (0.67), and have a reasonable &#x0201c;unexaggerated&#x0201d; maximization. Finally, we need to stress that the selection of weight (0.50) for each part of <xref rid="fd5" ref-type="disp-formula">Eq. (5)</xref> is not an ad-hoc chosen. Essentially, we did process the aggregate similarity in three cases. Case (1): giving the first part a weight of 0.67 and the second part a 0.33 weight. Second case, giving first part a weight of 0.33 and second part a 0.67 weight. The third case was to give both weights the value of (0.50). The third case has been seen super competitive compared to the previous cases, and hence counted for our aggregated measure.</p></sec></sec><sec id="sec3.3"><label>3.3</label><title>The hierarchical clustering (HC)</title><p id="p0125">Generally speaking, HC aims at finding the nested sequence of clusters, with a single, all-inclusive cluster at the top and singleton clusters of individual items at the bottom. Then, each pair of clusters are combined in each intermediate level from the next lower grade or partitioning a cluster from the next higher grade. The result of a hierarchical clustering can be graphically drawn as tree, called a dendogram. Visually speaking, this dendogram depicts the combining process and the intermediate clusters. <xref rid="fig3" ref-type="fig">Figure&#x000a0;3</xref> shows an instance of dendogram of nine points that were clustered into a single cluster. Furthermore, dendogram can provide a clear and easy query clustering and even a taxonomy, or hierarchical index. For HC approaches, there are two basic approaches to producing a hierarchical clustering:<list list-type="simple" id="olist0010"><list-item id="o0010"><label>(1)</label><p id="p0130">Agglomerative HC: it is the most widely used in literature. It starts with all data as single clusters and, at each successive step, the most similar or closest pair of clusters are combined together. The cluster similarity or distance definition is unavoidably required in order for the process to be completed.</p></list-item><list-item id="o0015"><label>(2)</label><p id="p0135">Divisive HC: starts with one, all-inclusive cluster and, at each successive step, the concerned cluster is constantly divided until only the singleton clusters of individual data are drawn. In each clustering step, it has to decide which cluster is going to be split and how the division will be performed.</p></list-item></list><fig id="fig3"><label>Figure&#x000a0;3</label><caption><p>HC clustering Dendogram.</p></caption><alt-text id="alttext0020">Figure&#x000a0;3</alt-text><graphic xlink:href="gr3"/></fig></p><p id="p0140">In the proposed ASGOP, the single linkage agglomerative HC approach is used as follows: (1) the similarity between all pairs of data/points is computed, <italic>i.e.</italic>, compute the similarity matrix whose IJ<sup>th</sup> cell refers to the similarity between the I<sup>th</sup> and J<sup>th</sup> points; (2) then, the most similar (closest) points are combined; (3) the similarity matrix is updated in each clustering step to reflect the new pairwise similarity between the new points and the original points; (4) finally, steps (2) and (3) are iterated till only a single cluster is found.</p></sec><sec id="sec3.4"><label>3.4</label><title>Query clustering</title><p id="p0145">Our work comes in an attempt to eliminate the need to produce the numerical patterns of queries while ensuring the best design of DDBS. Out of saving computation time, the averaged distances between considered queries are computed directly as queries are processed as strings. In other words, the query numerical patterns that were presented in both (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) are no longer needed. To compute the difference values between queries, the hamming distance metric (<xref rid="fd3" ref-type="disp-formula">Eqn 3</xref>) and nearby measure (<xref rid="fd4" ref-type="disp-formula">Eqn 4</xref>) have been used as a combination of both metrics to produce the aggregated similarity (<xref rid="fd5" ref-type="disp-formula">Eqn 5</xref>) which resulted in the building of distance matrix. This matrix is then passed into AHC algorithm to create the initial overlapping schemes.</p></sec><sec id="sec3.5"><label>3.5</label><title>Fragmentation evaluator (FE)</title><p id="p0150">FE consists of: 1. the Relevant Remote Access (RRM) which is the cost of access for remote attributes that are allocated at a site other than the site from which the concerned query is released (see <xref rid="fd6" ref-type="disp-formula">Eqn 6</xref>); 2. The Irrelevant Local Access (ILA) which is concerned with attributes that are locally accessed (see <xref rid="fd7" ref-type="disp-formula">Eqn 7</xref>). In FE evaluation, the lower FE result value is, the best DDBS performance is and vice versa.<disp-formula id="fd6"><label>(6)</label><mml:math id="M6" altimg="si6.svg" alttext="Equation 6."><mml:mrow><mml:mi>R</mml:mi><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mspace width="0.25em"/><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mi>Q</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">&#x02217;</mml:mo><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">&#x02212;</mml:mo><mml:mspace width="0.25em"/><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>Where AN is the number of targeted attributes in the targeted fragment, K is an index for query set, I is an index for fragments, FQ is the frequency of query (how many times query is being released over network) that accesses data and W<sub>ik</sub> is the number of attributes in fragment F<sub>i</sub> which is locally accessed by Q<sub>k</sub>. Suppose that we have F (A<sub>1</sub>, A<sub>3</sub>, A<sub>6</sub>) and query Q (A<sub>1</sub>, A<sub>2</sub>, A<sub>3</sub>,A<sub>5</sub>) which has FQ of 10. Then, AN is 3 as F consist of three attributes. For the value of W<sub>ik</sub>, there has been two cases, if Q and F are existed in the same site, W<sub>ik</sub> is 2 attributes (A<sub>1</sub> and A<sub>3</sub>). Otherwise, W<sub>ik</sub> in PRM Equation is zero as the query is a remote query with respect to F.<disp-formula id="fd7"><label>(7)</label><mml:math id="M7" altimg="si7.svg" alttext="Equation 7."><mml:mrow><mml:mi>I</mml:mi><mml:mi>L</mml:mi><mml:mi>A</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mspace width="0.25em"/><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:mi>F</mml:mi><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo linebreak="badbreak">&#x02217;</mml:mo><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow><mml:mo linebreak="badbreak">&#x02217;</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mspace width="0.25em"/><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>Where m is the number of remote sites, |Z<sub>ik</sub>| is the number of targeted A<sub>k</sub> attribute(s) in fragment F<sub>i</sub> which is remotely reached by Q<sub>k</sub> with regard to the local fragment F<sub>h</sub> which is already allocated in the same site (S<sub>j</sub>) of F<sub>i</sub>. NA<sub>iqk</sub> is the entire number of attributes in fragment F<sub>i</sub> distantly accessed, in regard to F<sub>j</sub>, by Q<sub>k</sub>. If we suppose query Q (A<sub>1</sub>, A<sub>2</sub>, A<sub>3</sub>, A<sub>5</sub>) is a remote query with respect to F (A<sub>1</sub>, A<sub>3</sub>, A<sub>6</sub>), then Z<sub>ik</sub> would have a value of 2 attributes (A<sub>1</sub> and A<sub>3</sub>) and NA<sub>iqk</sub> has a value of 3 which is the number of all attributes of F. On the other hand, nf, Q and k are the number of considered fragments, queries, and attributes of queries respectively. I, q, and j are indices for these variables, though. Lastly, FE is being accumulated in <xref rid="fd8" ref-type="disp-formula">Eq. (8)</xref> using these two components (PRM and ILA) as follows;<disp-formula id="fd8"><label>(8)</label><mml:math id="M8" altimg="si8.svg" alttext="Equation 8."><mml:mrow><mml:mi>F</mml:mi><mml:mi>E</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>R</mml:mi><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mo linebreak="goodbreak">+</mml:mo><mml:mi>I</mml:mi><mml:mi>L</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:math></disp-formula></p></sec><sec id="sec3.6"><label>3.6</label><title>Site clustering</title><p id="p0155">The presented algorithm of site clustering (See <xref rid="enun_Algorithm_1" ref-type="statement">Algorithm 1</xref>) combines the nature of hierarchical clustering and the behaviour of the algorithm designed in (<xref rid="bib4" ref-type="bibr">Amer et&#x000a0;al., 2017</xref>). This process is mainly accomplished on the basis of the concept of Least Difference Value (LDV). LDV concept works similarly to the single-linkage hierarchical clustering. Each pair of sites has not been grouped in one cluster unless they have the minimum communication costs. According to the conducted evaluation, better results are satisfied in terms of TC reduction due to this combination.<statement id="enun_Algorithm_1"><label>Algorithm 1</label><p id="p0160"><table-wrap position="float" id="undtbl1"><table frame="hsides" rules="groups"><tbody><tr><td rowspan="29">Input:</td><td>1.</td><td>Input: Network Sites; Communication Cost Matrix</td></tr><tr><td>2.</td><td>Output: Site Clusters; Communication Cost Matrix between Clusters</td></tr><tr><td>3.</td><td>Begin</td></tr><tr><td>4.</td><td>Let m &#x02192; the number of network sites; Cm&#x02192; the number of site clusters</td></tr><tr><td>5.</td><td>Select all pairs of sites of the same lowest costs to be the newly-formed clusters</td></tr><tr><td>6.</td><td>Initialize Cm&#x02192; the number of the newly-formed clusters</td></tr><tr><td>7.</td><td>For all of these clusters, find their centeroid individually</td></tr><tr><td>8.</td><td>&#x000a0;Let Flag &#x02192; True</td></tr><tr><td>9.</td><td>&#x000a0;For I &#x02192; 1 to m</td></tr><tr><td>10.</td><td>&#x000a0;{ For J &#x02192; 1 to Cm</td></tr><tr><td>11.</td><td>&#x000a0;If S(I) &#x020ac; C(J) let Flag &#x02192; Flase</td></tr><tr><td>12.</td><td>&#x000a0;If Flag &#x02192; True</td></tr><tr><td>13.</td><td>&#x000a0;{Let h &#x02192; 2; k&#x02192; 0;</td></tr><tr><td>14.</td><td>&#x000a0;For J &#x02192; 1 to C<sub>m</sub></td></tr><tr><td>15.</td><td>&#x000a0;{If Distance (S(I), C(J).centeroid) &#x0003c; Distance (S(I), C(h).centeroid)</td></tr><tr><td>16.</td><td>&#x000a0;Mark S(I) to be added to C(J) and Let k &#x02192; J</td></tr><tr><td>17.</td><td>&#x000a0;Else Mark S(I) to be added to C(h) and Let k &#x02192; h</td></tr><tr><td>18.</td><td>&#x000a0;h++;}</td></tr><tr><td colspan="2">//to ensure that each site would join cluster/site of minimum cost, execute the follows:</td></tr><tr><td>19.</td><td>&#x000a0;Let g &#x02192;1; Flag-Site &#x02192; True;</td></tr><tr><td>20.</td><td>&#x000a0;For s &#x02192; 1 to m</td></tr><tr><td>21.</td><td>&#x000a0;If Distance (S(I), S(s)) &#x0003c; Distance (S(I), C(k).centeroid) and (I &#x0003c; &#x0003e; s)</td></tr><tr><td>22.</td><td>&#x000a0;{let Flag-Site &#x02192; Flase; g = s;</td></tr><tr><td>23.</td><td>&#x000a0;Keep S(s).counter;}</td></tr><tr><td>24.</td><td>If Flag-Site &#x02192; Flase form new cluster (S(I),S(g))</td></tr><tr><td>25.</td><td>Else add S(I) to C(k);</td></tr><tr><td colspan="2">}//if</td></tr><tr><td>26.</td><td>Go back to step 9</td></tr><tr><td colspan="2">}//For I</td></tr><tr><td>Output:</td><td colspan="2">Cluster of Sites</td></tr></tbody></table></table-wrap></p></statement></p></sec><sec id="sec3.7"><label>3.7</label><title>Data allocation strategy</title><p id="p0165">To improve DDBS performance, data allocation must be carefully addressed with the basic aim of distributing data fragments into their relative clusters/sites from which they are constantly accessed. However, the complexity embedded in this procedure, due to the challenging mission of discovering the place for each data fragment, still impacts the overall performance profoundly. In ASGOP, therefore, a greedy oriented algorithm is proposed to find an acceptable solution. This algorithm seeks to minimize the objective function of the proposed model which is basically aimed at TC minimization. This function is crucially drawn with the aim of shrinking TC among network clusters. In this algorithm, each fragment would be tentatively given to each cluster/site and exposed on TC function at the same time. After that, the cluster/site with the least costs, depending on this function in terms of the targeted fragment, is the primary candidate to contain that fragment providing that cluster/site's constraints are preserved. Moreover, using this greedy algorithm, fragments are anticipated to be near-optimally allocated and replicated at the same time. That is, the algorithm strives to perform a simultaneous task represented in data allocation and replication on the fly. This algorithm is meant to have a high contribution with respect to DDBS performance promotion. Strictly speaking, the data allocation problem is treated as an optimization problem with the sole aim of further minimizing TC and rising performance. In other words, each fragment is allocated/replicated to cluster/site in which TC is kept at a minimum.</p><sec id="sec3.7.1"><label>3.7.1</label><title>Problem formulation</title><p id="p0170">Provided that we have a set of &#x0201c;A&#x0201d; attributes A = {A<sub>1</sub>, A<sub>2</sub>, ..., A<sub>n</sub>} required by a set of &#x0201c;Q&#x0201d; queries, Qs = {Q<sub>1</sub>, Q<sub>2</sub>, ..., Q<sub>q</sub>}, and Qs is already grouped into Cn clusters {Cq<sub>1</sub>,Cq<sub>2</sub>&#x02026;., Cq<sub>cn</sub>} using the proposed fragmentation technique. Then, the query clusters are scattered over a set of M sites S = {S<sub>1</sub>, S<sub>2</sub>, &#x02026;., S<sub>m</sub>} which are also gathered into Cm clusters of sites {Cs<sub>1</sub>, Cs<sub>2</sub>, &#x02026;., CS<sub>cm</sub>} in a fully connected network. The data allocation model primarily aims at finding the optimal distribution of each query cluster (Cq<sub>i</sub>) over clusters Cs<sub>j</sub>, and consequently over all sites of each concerned cluster. The optimal distribution is the case in which the minimum interaction between sites is obtained to answer distributed queries with the minimum TC.</p></sec><sec id="sec3.7.2"><label>3.7.2</label><title>The proposed data allocation model (DAM)</title><p id="p0175">The key idea of this model is that the data fragment should be assigned to the site in which the lowest TC is secured. This model led to a greedy strategy for data allocation and shown to perform well in practice through the empirical experiments. That is, using this model, fragments are allocated into their respective sites with the aim of obtaining the lowest interaction between sites of each cluster, and subsequently between clusters of the whole network. This objective led to obtaining the lowest Transmission Costs (TC) incurred over the entire network due to the distribution process of queries. The Objective function of this model is given by the next Eqs. <xref rid="fd9" ref-type="disp-formula">(9)</xref>, <xref rid="fd10" ref-type="disp-formula">(10)</xref>, and <xref rid="fd11" ref-type="disp-formula">(11)</xref><disp-formula id="fd9"><label>(9)</label><mml:math id="M9" altimg="si9.svg" alttext="Equation 9."><mml:mrow><mml:mi>T</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mspace width="0.25em"/><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mi>F</mml:mi><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">&#x02217;</mml:mo><mml:mspace width="0.25em"/><mml:mi>X</mml:mi><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">&#x02217;</mml:mo><mml:mi>C</mml:mi><mml:mi>O</mml:mi><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo linebreak="badbreak">&#x02217;</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">&#x02217;</mml:mo><mml:mspace width="0.25em"/><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mrow><mml:mo linebreak="badbreak">&#x02217;</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="fd10"><label>(10)</label><mml:math id="M10" altimg="si10.svg" alttext="Equation 10."><mml:mrow><mml:mi>T</mml:mi><mml:mi>C</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mspace width="0.25em"/><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mi>m</mml:mi><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mspace width="0.25em"/><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.25em"/><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mspace width="0.25em"/><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="fd11"><label>(11)</label><mml:math id="M11" altimg="si11.svg" alttext="Equation 11."><mml:mrow><mml:mi>T</mml:mi><mml:mi>C</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mspace width="0.25em"/><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>C</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mi>C</mml:mi><mml:mi>m</mml:mi><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mspace width="0.25em"/><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>k</mml:mi><mml:mspace width="0.25em"/><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:math></disp-formula>Where TC represents transmission costs that have been sought to be minimized while answering the distributed query, FQ is the total frequency of each released query and COM represents the communication costs between clusters/sites. This cost is either between sites (<italic>i.e.</italic> from site S<sub>i</sub> to S<sub>j</sub>) or between clusters. The Sel (Q) is the selectivity percentage which refers to the data conveyed (actual data) by query as it has been answered. While the size of the fragment is referred to by Size (F), M indicates the number of sites which are involved in answering relative query. The smaller M value is, the smaller TC is, and vice versa. On the other hand, (k, j, h and f) are just indices to queries, sites, clusters, and fragments respectively. Finally XF is a binary variable indicates whether fragment allocated in the relative site (1) or not (0). While <xref rid="fd9" ref-type="disp-formula">Eq. (9)</xref> seeks to minimize TC incurred over sites of each concerned cluster, Eqs. <xref rid="fd10" ref-type="disp-formula">(10)</xref> and <xref rid="fd11" ref-type="disp-formula">(11)</xref> struggle to accumulate these costs over each cluster and then over the whole network. This model is subjected to:<disp-formula id="fd12"><label>(12)</label><mml:math id="M12" altimg="si12.svg" alttext="Equation 12."><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.25em"/><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="fd13"><label>(13)</label><mml:math id="M13" altimg="si13.svg" alttext="Equation 13."><mml:mrow><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>#</mml:mo><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">&#x02265;</mml:mo><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mi>h</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="fd14"><label>(14)</label><mml:math id="M14" altimg="si14.svg" alttext="Equation 14."><mml:mrow><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mo linebreak="badbreak">&#x02264;</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mi>l</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>#</mml:mo><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="fd15"><label>(15)</label><mml:math id="M15" altimg="si15.svg" alttext="Equation 15."><mml:mrow><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mo linebreak="badbreak">&#x02264;</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mi>j</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>..</mml:mn><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>;</mml:mo><mml:mspace width="0.25em"/><mml:mi>l</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>#</mml:mo><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="fd16"><label>(16)</label><mml:math id="M16" altimg="si16.svg" alttext="Equation 16."><mml:mrow><mml:mi mathvariant="italic">Xhi</mml:mi><mml:mo linebreak="badbreak">&#x02208;</mml:mo><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mn>0,1</mml:mn></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mi>h</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>C</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.25em"/><mml:mo>;</mml:mo><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>&#x02026;</mml:mo><mml:mspace width="0.25em"/><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mo>#</mml:mo><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="fd17"><label>(17)</label><mml:math id="M17" altimg="si17.svg" alttext="Equation 17."><mml:mrow><mml:mi mathvariant="italic">Yil</mml:mi><mml:mo linebreak="badbreak">&#x02208;</mml:mo><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mn>0,1</mml:mn></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>#</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mspace width="0.25em"/><mml:mo>;</mml:mo><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>&#x02026;</mml:mo><mml:mspace width="0.25em"/><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>#</mml:mo><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:math></disp-formula></p><p id="p0180">While <xref rid="fd12" ref-type="disp-formula">Eq. (12)</xref> minimizes the fragment allocation in clusters/sites, <xref rid="fd13" ref-type="disp-formula">Eq. (13)</xref> indicates that each fragment F<sub>i</sub> must be allocated to all site clusters &#x0201c;Cm&#x0201d; in a replication scenario. In each cluster C<sub>h</sub>, fragment F<sub>i</sub> was allowed to be replicated over several sites when it is needed. While nf and q refer to the number of fragments and queries already allocated in the concerned cluster/site respectively, Eqs. <xref rid="fd14" ref-type="disp-formula">(14)</xref> and <xref rid="fd15" ref-type="disp-formula">(15)</xref> ensure that cluster/site capacity has not been violated. In other words, Eqs. <xref rid="fd14" ref-type="disp-formula">(14)</xref> and <xref rid="fd15" ref-type="disp-formula">(15)</xref> enforce the capacity of each cluster/site as it must be kept unviolated. Finally, the variables (X and Y) are used as a binary (0, 1) in the last four Equations.</p></sec><sec id="sec3.7.3"><label>3.7.3</label><title>The proposed greedy-based solution</title><p id="p0185">To satisfy the desired reduction in TC, the data allocation solution addresses DAP based on the greedy -nature algorithm which is similar to the backpack problem so the objective function is optimized (minimized). The fragments represent the objects in the bag, and sites of the whole network represent the weights with respect to their accumulated TC incurred as each fragment is supposedly allocated into its relative site. The comparison process which involved examining the allocation of the intended fragment into the site based on TC is accomplished in the same procedure knapsack problem which is being solved, as given in the drawn-below illustrative example. Moreover, the intended fragment is replicated in the same process based on the calculated threshold. This model thus strives to simultaneously allocate and replicate each fragment into its respective site without extra complexity is being observed.</p><p id="p0190">In its turn, a greedy algorithm always finds the solution that appears to be locally optimal at that time. This optimal-locality solution aims to find a globally-optimal solution. As mentioned earlier, the proposed model basically aimed at optimizing the drawn objective function by minimizing TC over the whole network on the basis of requirements given to the model. This optimization would be met through the greedy selection taken by dynamic programming represented in the knapsack-inspired algorithm. In fact, through experimental study drawn in this work, we found that this greedy algorithm elegant to be implemented and have a comparable results compared to the cost models (<italic>i.e.</italic> those models proposed in (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>)). Moreover, its run time more appealing and easier to be analyzed.</p><p id="p0195">In ASGOP, on the other hand, the proposed solution has been working as follows: for each fragment (F<sub>i</sub>), F<sub>i</sub> is listed along with its TC values over the considered sites of target clusters (C<sub>j</sub>). Those sites are given as input requirements to construct the dynamic programming table. This Table&#x000a0;would handle F<sub>i</sub> allocation process in the same way knapsack is being processed. After solving the knapsack-like table for the whole network clusters, the proposed model would extract a mini-matrix (<xref rid="fd18" ref-type="disp-formula">Eqn 18</xref>) for only the concerned sites of the targeted cluster. This step is repeated each time F<sub>i</sub> would be handled for allocation purpose over all clusters. In order for fragment to be replicated, a threshold value is computed based on values drawn in mini-matrix (see <xref rid="fd19" ref-type="disp-formula">Eqn 19</xref>) and then the fragment would be replicated based on its TC on the relative sites of concerned cluster as drawn in <xref rid="fd20" ref-type="disp-formula">Eq. (20)</xref>. The final results of F<sub>i</sub> would result in a simultaneous allocation and replication of fragments.<disp-formula id="fd18"><label>(18)</label><mml:math id="M18" altimg="si18.svg" alttext="Equation 18."><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">&#x02212;</mml:mo><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mspace width="0.25em"/><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">&#x02208;</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:munderover><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo linebreak="goodbreak">&#x02212;</mml:mo><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>Where m and Q stand for the number of sites and queries over the whole network. This Equation draws the mini-matrix of each cluster which is basically extracted from Max-Matrix. The Max-Matrix is the matrix that contains the whole network information with respect to transmission costs (see <xref rid="tbl2" ref-type="table">Table&#x000a0;2</xref>, below).<disp-formula id="fd19"><label>(19)</label><mml:math id="M19" altimg="si19.svg" alttext="Equation 19."><mml:mrow><mml:mi>T</mml:mi><mml:mi>H</mml:mi><mml:mi>V</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="fd20"><label>(20)</label><mml:math id="M20" altimg="si20.svg" alttext="Equation 20."><mml:mrow><mml:mi>A</mml:mi><mml:mi>R</mml:mi><mml:mo linebreak="badbreak">&#x02212;</mml:mo><mml:mi>D</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>T</mml:mi><mml:mi>C</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">&#x02264;</mml:mo><mml:mspace width="0.25em"/><mml:mi>T</mml:mi><mml:mi>H</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>O</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>Where both the Max (mini-matrix) and the Min (mini-matrix) are taken from Max-Matrix (see <xref rid="tbl2" ref-type="table">Table&#x000a0;2</xref>) as the maximum and minimum values of the matrix. On the other hand, the THV and AR-Decision stand for threshold value and fragment allocation and replication decision respectively. Finally, i and j are just indices. It is worth indicating that when TC of the respective fragment is less than THV that means fragment is being allocated/replicated in cluster/site in which TC is being reduced to a minimum, and vice versa.</p></sec><sec id="sec3.7.4"><label>3.7.4</label><title>Data allocation algorithms</title><p id="p0200"><statement id="enun_Algorithm_2"><label>Algorithm 2</label><p id="p0205"><table-wrap position="float" id="undtbl2"><table frame="hsides" rules="groups"><tbody><tr><td rowspan="26">Input:</td><td colspan="2"><bold>The most-used</bold> Query List; Query original site List (sites from which queries are most released); Cluster communication cost matrix; Site communication cost matrix; Selectivity matrix; Fragments information, Fragment number, Cluster number, Sites, FSTC.</td></tr><tr><td colspan="2"><bold>Begin</bold></td></tr><tr><td>1.</td><td>{</td></tr><tr><td>2.</td><td>For (f = 0 to Fn) V [0,f] = 0;</td></tr><tr><td/><td>//Fn number of fragment; V refers to value of TC for each fragment f. when there</td></tr><tr><td/><td>is no f in respective site, value is 0.//</td></tr><tr><td/><td>//steps 4&#x02013;13 to draw Max-Matrix (see <xref rid="tbl2" ref-type="table">Table&#x000a0;2</xref>)</td></tr><tr><td>3.</td><td>&#x000a0;For (i = 1 to m)//number of sites of the whole network</td></tr><tr><td>4.</td><td>&#x000a0;For (f = 0 to F)//number of fragment</td></tr><tr><td>5.</td><td>&#x000a0;If ((f [i] &#x0003c;=f) and (v [i]+V [i-1, f-f [i]] &#x0003e; V [i-1,f]))</td></tr><tr><td>6.</td><td>&#x000a0;{V [i,f] = v [i] + V [i-1, f-f [i]]];</td></tr><tr><td>7.</td><td>&#x000a0;Keep [i,f] = 1;</td></tr><tr><td>8.</td><td>&#x000a0;}</td></tr><tr><td>9.</td><td>&#x000a0;else</td></tr><tr><td>10.</td><td>&#x000a0;{V [i,f] = V [i-1,f];</td></tr><tr><td>11.</td><td>&#x000a0;Keep [i,f] = 0;</td></tr><tr><td>12.</td><td>&#x000a0;}</td></tr><tr><td>13.</td><td>&#x000a0;K=F</td></tr><tr><td>14.</td><td>&#x000a0;For (i = m down to 1)//backtracking to retrieve sites in which TC is produced</td></tr><tr><td>15.</td><td>&#x000a0;If (keep [I,k] = = 1)</td></tr><tr><td>16.</td><td>&#x000a0;{Output I;</td></tr><tr><td>17.</td><td>&#x000a0;K=K-f [i]</td></tr><tr><td>18.</td><td>&#x000a0;}</td></tr><tr><td>19.</td><td>Return V [m,F]</td></tr><tr><td/><td>//M is the number of returned sites in target cluster that will be holding F list.</td></tr><tr><td colspan="2">}//<bold>End</bold></td></tr><tr><td>Output:</td><td colspan="2">Fragments Allocation over Clusters</td></tr></tbody></table></table-wrap></p></statement><statement id="enun_Algorithm_3"><label>Algorithm 3</label><p id="p0210"><table-wrap position="float" id="undtbl3"><table frame="hsides" rules="groups"><tbody><tr><td rowspan="23">Input:</td><td colspan="2"><bold>Begin</bold></td></tr><tr><td/><td/></tr><tr><td>1.</td><td>For I &#x02192; 1 to F<sub>n</sub>//number of fragments</td></tr><tr><td>2.</td><td>&#x000a0;For K &#x02192; 1 to C<sub>m</sub>//Cm is number of clusters</td></tr><tr><td>3.</td><td>&#x000a0;{Temporarily allocate fragment F(I) into site (1) of cluster K C(k). S (1);</td></tr><tr><td/><td>//S (1) is the first site in Cluster (k)</td></tr><tr><td>4.</td><td>&#x000a0;For J &#x02192; 2 to m//m number of sites in cluster C(k)</td></tr><tr><td/><td>//we start from site (2) as site (1) is already buffered with F(I) in step 3</td></tr><tr><td>5.</td><td>&#x000a0;{Temporarily re-allocate F(I) into S(J);</td></tr><tr><td>6.</td><td>&#x000a0;If TC (F(I), S(J)) &#x0003c; TC (F(I), S (1));//to find site of minimum TC</td></tr><tr><td/><td>//step 6: to find which site has the minimum TC in regard to F(I)</td></tr><tr><td>7.</td><td>&#x000a0;let H &#x02192; J</td></tr><tr><td>8.</td><td>&#x000a0;Else let H &#x02192; 1;</td></tr><tr><td/><td>//H is index to the survival site of minimum TC</td></tr><tr><td>9.</td><td>&#x000a0;}//For J</td></tr><tr><td>10.</td><td>&#x000a0;Permanently allocate (F(I) into S(H));</td></tr><tr><td/><td>//allocate F into site of minimum TC</td></tr><tr><td>11.</td><td>&#x000a0;}//for Cn</td></tr><tr><td>12.</td><td>&#x000a0;Go back For I loop</td></tr><tr><td>13.</td><td>&#x000a0;}//for I</td></tr><tr><td/><td/></tr><tr><td colspan="2"><bold>End</bold></td></tr><tr><td/><td/></tr><tr><td>Output:</td><td/><td>Fragments Allocation over Sites in each Cluster</td></tr></tbody></table></table-wrap></p><p id="p0215">Moreover, as an abstract flow diagram, <xref rid="fig4" ref-type="fig">Figure&#x000a0;4</xref> further clarifies all have-to-be-done steps of data allocation of the proposed work.<fig id="fig4"><label>Figure&#x000a0;4</label><caption><p>Abstract level view of data allocation process.</p></caption><alt-text id="alttext0025">Figure&#x000a0;4</alt-text><graphic xlink:href="gr4"/></fig></p></statement></p></sec><sec id="sec3.7.5"><label>3.7.5</label><title>Illustrative example for the mechanism of greedy-based algorithm</title><p id="p0220">Assuming that we have nine sites that are already clustered using the site clustering algorithm proposed in section <xref rid="sec3.6" ref-type="sec">(3.6.)</xref>. Suppose that Cluster C<sub>1</sub> consists of (S<sub>1</sub>, S<sub>5</sub>, S<sub>3</sub>, and S<sub>4</sub>) and TC values of fragment F<sub>1</sub> are listed along with each respective site as drawn in <xref rid="tbl1" ref-type="table">Table 1</xref>. These values are drawn based on computing TC function given in section <xref rid="sec3.7.2" ref-type="sec">(3.7.2.)</xref> and F<sub>1</sub> is randomly allocated to each site once. In each random allocation, F<sub>1</sub> is being allocated to a different site so its&#x02019; TC is examined to record the site(s) in which F<sub>1</sub> yields the minimum TC.<table-wrap position="float" id="tbl1"><label>Table&#x000a0;1</label><caption><p>Fragment F1 list along with its TC values over considered sites of C1.</p></caption><alt-text id="alttext0095">Table&#x000a0;1</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Fragment</th><th>TC</th><th>Site</th></tr></thead><tbody><tr><td>F<sub>1</sub></td><td>12%</td><td>S1</td></tr><tr><td>F<sub>1</sub></td><td>8%</td><td>S5</td></tr><tr><td>F<sub>1</sub></td><td>7%</td><td>S3</td></tr><tr><td>F<sub>1</sub></td><td>4%</td><td>S4</td></tr></tbody></table></table-wrap></p><p id="p0225">Using <xref rid="tbl1" ref-type="table">Table&#x000a0;1</xref> as input requirement, <xref rid="tbl2" ref-type="table">Table&#x000a0;2</xref> as Max-Matrix is constructed to run dynamic programming (as described in section <xref rid="sec3.7.4" ref-type="sec">3.7.4</xref>.) on &#x0201c;F<sub>1</sub>&#x0201c; list so the most suitable sites for F<sub>1</sub> are selected based on the minimum interaction between each site in C<sub>1</sub> and the whole network.<table-wrap position="float" id="tbl2"><label>Table&#x000a0;2</label><caption><p>Max-Matrix for fragment F1 allocation.</p></caption><alt-text id="alttext0100">Table&#x000a0;2</alt-text><table frame="hsides" rules="groups"><thead><tr><th colspan="2">S</th><th>S<sub>1</sub></th><th>S<sub>2</sub></th><th>S<sub>3</sub></th><th>S<sub>4</sub></th><th>S<sub>5</sub></th><th>S<sub>6</sub></th><th>S<sub>7</sub></th><th>S<sub>8</sub></th><th>S<sub>9</sub></th></tr></thead><tbody><tr><td>F</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>F<sub>1</sub></td><td>1</td><td>12</td><td>12</td><td>12</td><td>12</td><td>12</td><td>12</td><td>12</td><td>12</td><td>12</td></tr><tr><td>F<sub>1</sub></td><td>2</td><td>12</td><td>12</td><td>12</td><td>12</td><td>12</td><td>20</td><td>20</td><td>20</td><td>20</td></tr><tr><td>F<sub>1</sub></td><td>3</td><td>12</td><td>12</td><td>12</td><td>19</td><td>19</td><td>20</td><td>20</td><td>20</td><td>27</td></tr><tr><td>F<sub>1</sub></td><td>4</td><td>12</td><td>12</td><td>12</td><td>19</td><td>19</td><td>20</td><td>20</td><td>23</td><td>27</td></tr></tbody></table></table-wrap></p><p id="p0230">After that, the matrix of concerned cluster (contains only sites of cluster, C<sub>1</sub>) would be extracted from the whole matrix of the network (Max-Matrix). The extracted matrix, called mini-matrix, is drawn in <xref rid="tbl3" ref-type="table">Table&#x000a0;3</xref>.<table-wrap position="float" id="tbl3"><label>Table&#x000a0;3</label><caption><p>Mini-matrix of F<sub>1</sub>.</p></caption><alt-text id="alttext0105">Table&#x000a0;3</alt-text><table frame="hsides" rules="groups"><thead><tr><th colspan="2">S</th><th>S1</th><th>S3</th><th>S4</th><th>S5</th></tr></thead><tbody><tr><td>F</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>F<sub>1</sub></td><td>1</td><td><bold><underline>12</underline></bold></td><td>12</td><td>12</td><td>12</td></tr><tr><td>F<sub>1</sub></td><td>2</td><td>12</td><td>12</td><td>12</td><td>12</td></tr><tr><td>F<sub>1</sub></td><td>3</td><td>12</td><td>12</td><td>19</td><td>19</td></tr><tr><td>F<sub>1</sub></td><td>4</td><td>12</td><td>12</td><td>19</td><td><bold><underline>19</underline></bold></td></tr></tbody></table></table-wrap></p><p id="p0235">To avoid both the challenge in estimating threshold values by the user and the implication resulted in implementation difficulty, the threshold is loosened to be a problem-centric (data-defined) threshold. By taking threshold based on <xref rid="fd19" ref-type="disp-formula">Eq. (19)</xref> and <xref rid="tbl3" ref-type="table">Table&#x000a0;3</xref>, the threshold value is [(12 + 19)/2 = 16] in this example. That is because of that the value of (12) is the minimum value and the value of (19) is the maximum value in Mini-Matrix. We find that F<sub>1</sub> shall be allocated and replicated in S<sub>1</sub> and S<sub>3</sub> only as they produced the minimum averaged TC (minimum interaction) over cluster C<sub>1</sub>. In other words, their TC did not exceed threshold value which is (16). On the other hand, S<sub>4</sub> and S<sub>5</sub> are being excluded as they have conflict values. While the first two rows indicate that both sites have the value of (12), the last two rows indicate that both sites have the value of (19) which also exceeded threshold value. The value of TC of each site in regard to the concerned fragment must be decisive (always less than or equal threshold) so fragment would be considered for site allocation. This process is set to be repeated in each cluster for each fragment to be simultaneously allocated and replicated.</p></sec></sec></sec><sec id="sec4"><label>4</label><title>Results</title><p id="p0240">In this section we are going to: present experimental setup for ASGOP and its competitive peers, draw the datasets used in experiments conduction, give a demonstrative example to show the way in which ASGOP works, and finally, analyze ASGOP performance along with its peers.</p><sec id="sec4.1"><label>4.1</label><title>Experimental setup</title><p id="p0245">This work has been executed using a C++ programming language which runs on a processor of 1.7 GHz Intel (R) Dual-Core (TM) i3CPU with 2 GB of main memory and 80-GB hard drive. All requirements including queries and their frequencies over sites are assumed to be gathered from DDBS workload. The first experiment is exclusively conducted in an attempt to demonstrate ASGOP mechanism. On the other hand, performance evaluation is being carried out internally, and externally with (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) to show ASGOP supremacy. The virtual network is assumed to be fully-connected of six sites, as shown in <xref rid="fig5" ref-type="fig">Figure&#x000a0;5</xref>.<fig id="fig5"><label>Figure&#x000a0;5</label><caption><p>Network sites.</p></caption><alt-text id="alttext0030">Figure&#x000a0;5</alt-text><graphic xlink:href="gr5"/></fig></p></sec><sec id="sec4.2"><label>4.2</label><title>Datasets</title><sec id="sec4.2.1"><label>4.2.1</label><title>Ships dataset</title><p id="p0250"><xref rid="tbl4" ref-type="table">Table&#x000a0;4</xref> reveals the dataset description of the synthetically-proposed ships (with 400 records) in the first experiment for illustration purposes. In the evaluation section, dataset records have been diversified over several experiments.<table-wrap position="float" id="tbl4"><label>Table&#x000a0;4</label><caption><p>Ships database description.</p></caption><alt-text id="alttext0110">Table&#x000a0;4</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Attributes</th><th>Symbol</th><th>Type</th><th>Length (Bytes)</th></tr></thead><tbody><tr><td>Ship-no</td><td>A<sub>1</sub></td><td>Nominal</td><td>4</td></tr><tr><td>Ship-name</td><td>A<sub>2</sub></td><td>Categorical</td><td>30</td></tr><tr><td>Captain-id</td><td>A<sub>3</sub></td><td>Categorical</td><td>4</td></tr><tr><td>Captain-Wage</td><td>A<sub>4</sub></td><td>Numerical</td><td>3</td></tr><tr><td>Port</td><td>A<sub>5</sub></td><td>Categorical</td><td>5</td></tr><tr><td>Port-id</td><td>A<sub>6</sub></td><td>Nominal</td><td>4</td></tr></tbody></table></table-wrap></p><p id="p0255">On this dataset, for demonstration purposes, eight queries are identified in the first experiment as the most frequently running queries. While seven queries were supposed to be of retrieval type, one single query was supposed to be of update type. This was drawn intentionally to diversify the rate of queries from the first experiments. This diversity would be varied through all experiments. Actually, this step is meant to show the impact of query type on DDBS performance.</p><p id="p0260">Q<sub>1</sub>: Select A<sub>1</sub>, A<sub>3</sub>, A<sub>5</sub> from Ships where A<sub>1</sub> in (1234, 261, 1239) and A<sub>3</sub> = &#x0201c;M222&#x0201d;;</p><p id="p0265">Q2: Select A<sub>1</sub>, A<sub>2</sub>, A<sub>5</sub>, A<sub>6</sub> from Ships where A<sub>5</sub> in (&#x02018;site 1&#x02019;, &#x02018;site 3&#x02019;, &#x02018;site 6&#x02019;);</p><p id="p0270">Q3: Select A<sub>2</sub>, A<sub>3</sub>, A<sub>5</sub> from Ships;</p><p id="p0275">Q4: Select A<sub>1</sub>, A<sub>4</sub>, A<sub>6</sub> from Ships where A<sub>6</sub> = &#x02018;dept2&#x02019;;</p><p id="p0280">Q5: Select A<sub>2</sub>, A<sub>4</sub>, A<sub>5</sub> from Ships where A<sub>2</sub> = &#x0201c;Jane&#x0201d; and A<sub>5</sub> in (&#x02018;site 2&#x02019;,&#x02018;site 5&#x02019;);</p><p id="p0285">Q6: Select A<sub>2</sub>, A<sub>3</sub>, A<sub>4</sub>, A<sub>6</sub> from Ships where A<sub>4</sub> &#x0003e; 4500;</p><p id="p0290">Q7: Update Ships set A<sub>2</sub> = &#x02018;Ali&#x02019;, A<sub>6</sub> = 2 where A<sub>1</sub>&#x0003e;1234;</p><p id="p0295">Q8: Select A<sub>1</sub>, A<sub>3</sub>, A<sub>5</sub> from Ships;</p></sec><sec id="sec4.2.2"><label>4.2.2</label><title>Employee dataset</title><p id="p0300">For further analysis and discussion for ASGOP performance and its peers, the employee dataset is proposed based on the description drawn in <xref rid="tbl5" ref-type="table">Table&#x000a0;5</xref> which is basically taken from (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>). This dataset is mainly used to ensure a fair comparison for ASGOP with its peers. This dataset has six attributes and filled out with records ranges from 300 to 1200 records over all experiments as given in <xref rid="tbl16" ref-type="table">Table&#x000a0;16</xref>.<table-wrap position="float" id="tbl5"><label>Table&#x000a0;5</label><caption><p>Employee database.</p></caption><alt-text id="alttext0115">Table&#x000a0;5</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Attributes</th><th>Symbol</th><th>Type</th><th>Length (Bytes)</th></tr></thead><tbody><tr><td>Emp-no</td><td>A1</td><td>Nominal</td><td>4</td></tr><tr><td>Emp-name</td><td>A2</td><td>Categorical</td><td>30</td></tr><tr><td>Job-id</td><td>A3</td><td>Categorical</td><td>4</td></tr><tr><td>Salary</td><td>A4</td><td>Numerical</td><td>3</td></tr><tr><td>Loaction</td><td>A5</td><td>Categorical</td><td>5</td></tr><tr><td>Dept-id</td><td>A6</td><td>Nominal</td><td>4</td></tr></tbody></table></table-wrap></p><p id="p0305">Furthermore, for the first problem, it is supposed that we have eight queries under consideration as the sample for the most frequently-running queries against the Employee dataset.</p><p id="p0310">Q1: Select A<sub>2</sub>, A<sub>4</sub>, A<sub>6</sub> from Employee where A<sub>4</sub> between (1500, 3000);</p><p id="p0315">Q2: Select A<sub>1</sub>, A<sub>5</sub> from Employee where A<sub>5</sub> in (&#x02018;site 2&#x02019;, &#x02018;site 3&#x02019;);</p><p id="p0320">Q3: Select A<sub>1</sub>, A<sub>3</sub>, A<sub>6</sub> from Employee;</p><p id="p0325">Q4: Select A<sub>1</sub>, A<sub>2</sub>, A<sub>3</sub> from Employee where A<sub>3</sub> = &#x02018;manager&#x02019;;</p><p id="p0330">Q5: Select A<sub>3</sub>, A<sub>4</sub>, A<sub>5</sub> from Employee where A<sub>3</sub> = &#x0201c;worker&#x0201d; and A<sub>4</sub> &#x0003e; 1200;</p><p id="p0335">Q6: Select A<sub>2</sub>, A<sub>4</sub>, A<sub>5</sub> from Employee where A<sub>4</sub> &#x0003c; 2500;</p><p id="p0340">Q7: Select A<sub>3</sub>, A<sub>6</sub> from Employee where A<sub>6</sub> = &#x02018;dept2&#x02019;;</p><p id="p0345">Q8: Select A<sub>1</sub>, A<sub>4</sub>, A<sub>5</sub> from Employee;</p></sec></sec><sec id="sec4.3"><label>4.3</label><title>Running example</title><p id="p0350">In this example, using the listed-above queries in section <xref rid="sec4.2.1" ref-type="sec">(4.2.1.)</xref>, the behavior of ASGOP has been illustrated step by step along with the example that is already given in section <xref rid="sec3.7.5" ref-type="sec">(3.7.5)</xref>. First of all, the Query Attribute Incidence Matrix (QAIM) of the first experiment was formed in <xref rid="tbl6" ref-type="table">Table&#x000a0;6</xref>.<table-wrap position="float" id="tbl6"><label>Table&#x000a0;6</label><caption><p>Query attribute incidence matrix (QAIM).</p></caption><alt-text id="alttext0120">Table&#x000a0;6</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Q/A</th><th>A1</th><th>A2</th><th>A3</th><th>A4</th><th>A5</th><th>A6</th></tr></thead><tbody><tr><td>Q1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td></tr><tr><td>Q2</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td></tr><tr><td>Q3</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td></tr><tr><td>Q4</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td></tr><tr><td>Q5</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td></tr><tr><td>Q6</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td></tr><tr><td>Q7</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>Q8</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td></tr></tbody></table></table-wrap></p><p id="p0355">After that, using the procedure of fragmentation that was drawn in section <xref rid="sec3.2" ref-type="sec">(3.2)</xref>, all these requirements are fed into the fragmentation procedure including hierarchical clustering Process (HC), refinement process and fragmentation evaluator (FE) on the proposed dataset of Ships. By applying Eqs. <xref rid="fd2" ref-type="disp-formula">(2)</xref>, <xref rid="fd3" ref-type="disp-formula">(3)</xref>, <xref rid="fd4" ref-type="disp-formula">(4)</xref>, and <xref rid="fd5" ref-type="disp-formula">(5)</xref> on QAIM, Tables&#x000a0;<xref rid="tbl7" ref-type="table">7</xref>, <xref rid="tbl8" ref-type="table">8</xref>, <xref rid="tbl9" ref-type="table">9</xref> holds the values of these Equations.<table-wrap position="float" id="tbl7"><label>Table&#x000a0;7</label><caption><p>Hamming based similarity matrix.</p></caption><alt-text id="alttext0125">Table&#x000a0;7</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Q/A</th><th>Q1</th><th>Q2</th><th>Q3</th><th>Q4</th><th>Q5</th><th>Q6</th><th>Q7</th><th>Q8</th></tr></thead><tbody><tr><td>Q1</td><td>1.00</td><td>0.50</td><td>0.67</td><td>0.67</td><td>0.33</td><td>0.17</td><td>0.33</td><td>1.00</td></tr><tr><td>Q2</td><td>0.50</td><td>1.00</td><td>0.50</td><td>0.50</td><td>0.50</td><td>0.33</td><td>0.83</td><td>0.50</td></tr><tr><td>Q3</td><td>0.67</td><td>0.50</td><td>1.00</td><td>0.00</td><td>0.67</td><td>0.50</td><td>0.33</td><td>0.67</td></tr><tr><td>Q4</td><td>0.33</td><td>0.50</td><td>0.00</td><td>1.00</td><td>0.33</td><td>0.50</td><td>0.67</td><td>0.33</td></tr><tr><td>Q5</td><td>0.33</td><td>0.50</td><td>0.67</td><td>0.33</td><td>1.00</td><td>0.50</td><td>0.33</td><td>0.33</td></tr><tr><td>Q6</td><td>0.17</td><td>0.33</td><td>0.50</td><td>0.50</td><td>0.50</td><td>1.00</td><td>0.50</td><td>0.17</td></tr><tr><td>Q7</td><td>0.33</td><td>0.83</td><td>0.33</td><td>0.67</td><td>0.33</td><td>0.50</td><td>1.00</td><td>0.33</td></tr><tr><td>Q8</td><td>1.00</td><td>0.50</td><td>0.67</td><td>0.33</td><td>0.33</td><td>0.17</td><td>0.33</td><td>1.00</td></tr></tbody></table></table-wrap><table-wrap position="float" id="tbl8"><label>Table&#x000a0;8</label><caption><p>Nearby similarity matrix.</p></caption><alt-text id="alttext0130">Table&#x000a0;8</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Q/A</th><th>Q1</th><th>Q2</th><th>Q3</th><th>Q4</th><th>Q5</th><th>Q6</th><th>Q7</th><th>Q8</th></tr></thead><tbody><tr><td>Q1</td><td>1.00</td><td>0.57</td><td>0.67</td><td>0.67</td><td>0.33</td><td>0.29</td><td>0.33</td><td>1.00</td></tr><tr><td>Q2</td><td>0.57</td><td>1.00</td><td>0.57</td><td>0.57</td><td>0.57</td><td>0.50</td><td>0.86</td><td>0.57</td></tr><tr><td>Q3</td><td>0.67</td><td>0.57</td><td>1.00</td><td>0.00</td><td>0.67</td><td>0.57</td><td>0.33</td><td>0.67</td></tr><tr><td>Q4</td><td>0.33</td><td>0.57</td><td>0.00</td><td>1.00</td><td>0.33</td><td>0.57</td><td>0.67</td><td>0.33</td></tr><tr><td>Q5</td><td>0.33</td><td>0.57</td><td>0.67</td><td>0.33</td><td>1.00</td><td>0.57</td><td>0.33</td><td>0.33</td></tr><tr><td>Q6</td><td>0.29</td><td>0.50</td><td>0.57</td><td>0.57</td><td>0.57</td><td>1.00</td><td>0.57</td><td>0.29</td></tr><tr><td>Q7</td><td>0.33</td><td>0.86</td><td>0.33</td><td>0.67</td><td>0.33</td><td>0.57</td><td>1.00</td><td>0.33</td></tr><tr><td>Q8</td><td>1.00</td><td>0.57</td><td>0.67</td><td>0.33</td><td>0.33</td><td>0.29</td><td>0.33</td><td>1.00</td></tr></tbody></table></table-wrap><table-wrap position="float" id="tbl9"><label>Table&#x000a0;9</label><caption><p>The aggregated similarity matrix.</p></caption><alt-text id="alttext0135">Table&#x000a0;9</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Q/A</th><th>Q1</th><th>Q2</th><th>Q3</th><th>Q4</th><th>Q5</th><th>Q6</th><th>Q7</th><th>Q8</th></tr></thead><tbody><tr><td>Q1</td><td>1.00</td><td>0.54</td><td>0.67</td><td>0.67</td><td>0.33</td><td>0.23</td><td>0.33</td><td>1.00</td></tr><tr><td>Q2</td><td>0.54</td><td>1.00</td><td>0.54</td><td>0.54</td><td>0.54</td><td>0.42</td><td>0.85</td><td>0.54</td></tr><tr><td>Q3</td><td>0.67</td><td>0.54</td><td>1.00</td><td>0.00</td><td>0.67</td><td>0.54</td><td>0.33</td><td>0.67</td></tr><tr><td>Q4</td><td>0.33</td><td>0.54</td><td>0.00</td><td>1.00</td><td>0.33</td><td>0.54</td><td>0.67</td><td>0.33</td></tr><tr><td>Q5</td><td>0.33</td><td>0.54</td><td>0.67</td><td>0.33</td><td>1.00</td><td>0.54</td><td>0.33</td><td>0.33</td></tr><tr><td>Q6</td><td>0.23</td><td>0.42</td><td>0.54</td><td>0.54</td><td>0.54</td><td>1.00</td><td>0.54</td><td>0.23</td></tr><tr><td>Q7</td><td>0.33</td><td>0.85</td><td>0.33</td><td>0.67</td><td>0.33</td><td>0.54</td><td>1.00</td><td>0.33</td></tr><tr><td>Q8</td><td>1.00</td><td>0.54</td><td>0.67</td><td>0.33</td><td>0.33</td><td>0.23</td><td>0.33</td><td>1.00</td></tr></tbody></table></table-wrap></p><p id="p0360"><xref rid="tbl9" ref-type="table">Table&#x000a0;9</xref> is then fed into AHC to produce the final results (Clusters) and find solution space (<xref rid="tbl10" ref-type="table">Table&#x000a0;10</xref>).<table-wrap position="float" id="tbl10"><label>Table&#x000a0;10</label><caption><p>Solution space.</p></caption><alt-text id="alttext0140">Table&#x000a0;10</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Solution #</th><th>Cluster #</th><th>Queries contained</th></tr></thead><tbody><tr><td>Solution 1</td><td>Cq1</td><td>Q1573 Q2468</td></tr><tr><td>Solution 2</td><td>Cq2</td><td>Q1235 Q4678</td></tr><tr><td>Solution 3</td><td>Cq3</td><td>Q2578 Q1346</td></tr><tr><td>Solution 4</td><td>Cq4</td><td>Q13567 Q248</td></tr></tbody></table></table-wrap></p><p id="p0365">This space was set to be passed into the filtering process to remove attributes overlapping between the obtained schemes (as each query would be replaced by its contained attributes). The results were the disjointed schemes. By following the same procedure described in section <xref rid="sec3.2" ref-type="sec">(3.2)</xref>, the final schema is represented in <xref rid="tbl11" ref-type="table">Table&#x000a0;11</xref>.<table-wrap position="float" id="tbl11"><label>Table&#x000a0;11</label><caption><p>Survival schema.</p></caption><alt-text id="alttext0145">Table&#x000a0;11</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Fragments</th><th>F1</th><th>F2</th></tr></thead><tbody><tr><td>Contents</td><td>A<sub>1</sub>,A<sub>2</sub>,A<sub>4</sub>,A<sub>5</sub>,A<sub>6</sub></td><td>A<sub>3</sub></td></tr><tr><td>Size in Byte</td><td>18800</td><td>1600</td></tr></tbody></table></table-wrap></p><sec id="sec4.3.1"><label>4.3.1</label><title>Allocation process</title><p id="p0370">As mention earlier, fragments allocation is made in such a way that guarantees the allocation of each fragment to its perfect destination in keeping with TC minimalism. In the sense that based on the greedy-based data allocation algorithm of section <xref rid="sec4" ref-type="sec">(4)</xref>, each fragment would be temporarily placed into each site and exposed on TC at the same time. Whenever TC has been purely minimized as a result of fragment placement on the concerned site, the fragment is therefore permanently assigned to that site. According to evaluation results, this kind of data allocation contributed to lessening TC to a great extent as the distributed query was being processed. On the other hand, according to (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>), with which we draw an external evaluation, the best scenarios proved to be the best-fitting solution for DDBS design are replication and non-replication based scenarios. Consequently, the fragments allocation algorithm of ASGOP was made in these two scenarios as well. While the first scenario assumed that each fragment would be replicated over all clusters of sites; the second scenario assigned each fragment to a single cluster/site of minimum TC. Such a procedure of data allocation scenario made ASGOP comparable with all considered works in terms of both TC and DDBS performance, as shown in the evaluation section.</p></sec><sec id="sec4.3.2"><label>4.3.2</label><title>The first allocation scenario (fragments replicated over cluster of sites)</title><p id="p0375"><bold>Phase1</bold>: Fragments are directly allocated to all clusters using replication principle as shown in <xref rid="tbl12" ref-type="table">Table&#x000a0;12</xref>.<table-wrap position="float" id="tbl12"><label>Table&#x000a0;12</label><caption><p>Data fragment allocation (final step).</p></caption><alt-text id="alttext0150">Table&#x000a0;12</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Cluster<hr/></th><th colspan="4">C1<hr/></th><th colspan="2">C2<hr/></th></tr><tr><th>Fragment/Sites</th><th>S1</th><th>S2</th><th>S4</th><th>S6</th><th>S3</th><th>S5</th></tr></thead><tbody><tr><td>F1</td><td>398090</td><td>376940</td><td><bold>242990</bold></td><td>306440</td><td><bold>271190</bold></td><td>297510</td></tr><tr><td>F2</td><td>41100</td><td>41100</td><td><bold>15600</bold></td><td>35100</td><td>13800</td><td><bold>13200</bold></td></tr></tbody></table></table-wrap></p><p id="p0380"><bold>Phase</bold> 2: in each cluster, following the results of the greedy based algorithm, each fragment is assigned to site that satisfies TC minimalism, <xref rid="tbl13" ref-type="table">Table&#x000a0;13</xref>. The final allocation of data fragments (including replica) over clusters and sites is drawn in <xref rid="tbl13" ref-type="table">Table&#x000a0;13</xref>.<table-wrap position="float" id="tbl13"><label>Table&#x000a0;13</label><caption><p>Final allocation map.</p></caption><alt-text id="alttext0155">Table&#x000a0;13</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Cluster<hr/></th><th colspan="4">C1<hr/></th><th colspan="2">C2<hr/></th></tr><tr><th>Fragment/Sites</th><th>S1</th><th>S2</th><th>S4</th><th>S6</th><th>S3</th><th>S5</th></tr></thead><tbody><tr><td>F1</td><td/><td/><td>1</td><td/><td>1</td><td/></tr><tr><td>F2</td><td/><td/><td>1</td><td/><td/><td>1</td></tr></tbody></table></table-wrap></p><p id="p0385">From <xref rid="tbl12" ref-type="table">Table&#x000a0;12</xref>, by comparing TC measures of all sites for each cluster, it is clear that F<sub>1</sub> was assigned to S<sub>4</sub> in C<sub>1</sub> and S<sub>3</sub> in C<sub>2</sub>. While F<sub>2</sub> is allocated to S<sub>4</sub> of C<sub>1</sub> and S<sub>5</sub> of C<sub>2</sub> respectively (<xref rid="tbl13" ref-type="table">Table&#x000a0;13</xref>).</p></sec><sec id="sec4.3.3"><label>4.3.3</label><title>The second allocation scenario (no fragment replication)</title><p id="p0390"><bold>In this one-phase scenario,</bold> each fragment is placed into the site of minimum TC based on the proposed algorithm as shown in Tables&#x000a0;<xref rid="tbl14" ref-type="table">14</xref>, <xref rid="tbl15" ref-type="table">15</xref>.<table-wrap position="float" id="tbl14"><label>Table&#x000a0;14</label><caption><p>Data fragment allocation (final step).</p></caption><alt-text id="alttext0160">Table&#x000a0;14</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Cluster<hr/></th><th colspan="4">C1<hr/></th><th colspan="2">C2<hr/></th></tr><tr><th>Fragment/Sites</th><th>S1</th><th>S2</th><th>S4</th><th>S6</th><th>S3</th><th>S5</th></tr></thead><tbody><tr><td>F1</td><td>398090</td><td>376940</td><td><bold>242990</bold></td><td>306440</td><td>271190</td><td>297510</td></tr><tr><td>F2</td><td>41100</td><td>41100</td><td>15600</td><td>35100</td><td>13800</td><td><bold>13200</bold></td></tr></tbody></table></table-wrap><table-wrap position="float" id="tbl15"><label>Table&#x000a0;15</label><caption><p>Final allocation map.</p></caption><alt-text id="alttext0165">Table&#x000a0;15</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Cluster<hr/></th><th colspan="4">C1<hr/></th><th colspan="2">C2<hr/></th></tr><tr><th>Fragment/Sites</th><th>S1</th><th>S2</th><th>S4</th><th>S6</th><th>S3</th><th>S5</th></tr></thead><tbody><tr><td>F1</td><td/><td/><td>1</td><td/><td/><td/></tr><tr><td>F2</td><td/><td/><td/><td/><td/><td>1</td></tr></tbody></table></table-wrap></p><p id="p0395">The final allocation for fragments is drawn in <xref rid="tbl15" ref-type="table">Table&#x000a0;15</xref>.</p><p id="p0400">It is worth referring that we just drew the results of the final steps of proposed greedy-based algorithm. That is, Tables&#x000a0;<xref rid="tbl12" ref-type="table">12</xref>, <xref rid="tbl14" ref-type="table">14</xref> are the final outcomes.</p></sec></sec><sec id="sec4.4"><label>4.4</label><title>Performance evaluation</title><p id="p0405">In essence, like its counterparts, ASGOP comes in an attempt to improve DDBS performance through data locality maximization to a great possible extent as each fragment is given to the site from which it is frequently required. Moreover, the proposed data allocation procedure has been designed on the basis of greedy nature that tacitly guaranteed to minimize the network overheads and fragments migration. As a result of such design, TC has strongly been believed to be significantly reduced and DDBS productivity to be steadily increased. In a solid step to verify these claims, an internal and external evaluation has been made. Five experiments have been addressed, each of which constitutes of several problems and each problem has different requirements. For the first experiment, just the first problem (with eight queries and six sites) has exclusively been investigated in section <xref rid="sec4.3" ref-type="sec">(4.3)</xref>. The next problems, for all experiments, are treated in the same manner the first problem was being processed.</p><p id="p0410">Simply put, for the first problem of first experiments (shown in Figures&#x000a0;<xref rid="fig6" ref-type="fig">6</xref>, <xref rid="fig7" ref-type="fig">7</xref>, <xref rid="fig8" ref-type="fig">8</xref>, and <xref rid="fig9" ref-type="fig">9</xref>), every query, among those under consideration, was separately tested on the given dataset of ships in accordance to two scenarios: <bold>1</bold>. allocation scenario-1 in which all fragment were replicated over all clusters of sites; <bold>2</bold>. allocation scenario-2 in which fragments were allocated to sites of minimum TC values regardless of their clusters. On the other hand, as the closest works for ASGOP (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>), were involved in a competitive comparative process. All of these experiments have been conducted for all works: ASGOP (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>), and (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>). To be in parallel with experiments that were drawn in (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>) and (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>), all problems of all experiments considered a mixture of retrieval and update queries so that retrieval queries started to occupy large space from the first problem, and this space was being gradually reduced from one problem to the next problem in the favor of update queries. Such diversity in queries type was being purposefully done for the purpose of verifying technique's performance under several circumstances. The last two problems of the experiment were also a mixture of retrieval and update queries with update ones occupying larger space. Finally, for each problem, the minimization of (TC) has been monitored and recorded.<fig id="fig6"><label>Figure&#x000a0;6</label><caption><p>Replication scenario- TC</p></caption><alt-text id="alttext0035">Figure&#x000a0;6</alt-text><graphic xlink:href="gr6"/></fig><fig id="fig7"><label>Figure&#x000a0;7</label><caption><p>Average of TC - replication scenario.</p></caption><alt-text id="alttext0040">Figure&#x000a0;7</alt-text><graphic xlink:href="gr7"/></fig><fig id="fig8"><label>Figure&#x000a0;8</label><caption><p>Non-replication scenario - TC</p></caption><alt-text id="alttext0045">Figure&#x000a0;8</alt-text><graphic xlink:href="gr8"/></fig><fig id="fig9"><label>Figure&#x000a0;9</label><caption><p>The average of TC - non replication scenario.</p></caption><alt-text id="alttext0050">Figure&#x000a0;9</alt-text><graphic xlink:href="gr9"/></fig></p><p id="p0415">From <xref rid="fig6" ref-type="fig">Figure&#x000a0;6</xref> which depicts the results of the first problem's processed queries; it can be said that ASGOP (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>), and (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) were alternately behaving better in terms of replication-based scenario with ASGOP being slightly superior (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>). behaved slightly better than (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>), though. In other words, no significant superiority was observed for either one of them. However, when results are taken in total, <xref rid="fig7" ref-type="fig">Figure&#x000a0;7</xref> showed that ASGOP has a slight improvement in regard to TC minimization although all works were still close to each other. It is worth indicating that zero values of query execution costs in Figures&#x000a0;<xref rid="fig6" ref-type="fig">6</xref> and <xref rid="fig8" ref-type="fig">8</xref> mean that this query is accessed locally leading, as a result, to have a zero value for TC which is essentially dominated by the remote access.</p><p id="p0420">According to results obtained in <xref rid="fig6" ref-type="fig">Figure&#x000a0;6</xref>, ASGOP outperformed its counterparts with respect to Q<sub>2</sub>, Q<sub>3</sub>, Q<sub>5</sub>, Q<sub>6</sub>, and Q<sub>8</sub>. For Q<sub>4</sub> (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>), outweighed ASGOP significantly, though. However, ASGOP recorded the worst results in Q<sub>1</sub> and Q<sub>7</sub> for the next reasons. For Q<sub>1</sub>, the number of sites involved in processing query was bigger than it was in ASGOP's counterparts. On the other hand, due to the fact that Q<sub>7</sub> is of update type and allocation scenario is the replication-based, ASGOP recorded worst results in this scenario as updated data needs to be replicated in each site into where this data was already stored. In general, ASGOP does not work in the replication-based allocation scenario as good as it is drawn in the non-replication allocation scenario.</p><p id="p0425">On the other hand, when it comes to the non-replication scenario in <xref rid="fig8" ref-type="fig">Figure&#x000a0;8</xref>, ASGOP demonstrated its superiority over both (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) with the sole exception recorded for query7. Also (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>), still behaved much better than (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>). More evidently, as results would also be considered in total, the final results were also in favor of ASGOP as depicted in <xref rid="fig9" ref-type="fig">Figure&#x000a0;9</xref>.</p><p id="p0430">Finally, for problem (1) of the first experiment, as a reflection of Figures&#x000a0;<xref rid="fig7" ref-type="fig">7</xref> and <xref rid="fig9" ref-type="fig">9</xref> that depicted TC, <xref rid="fig10" ref-type="fig">Figure&#x000a0;10</xref> sought to clearly visualize DDBS performance of all works in terms of both the replication and the non-replication scenarios. For replication scenario, ASGOP showed a slight difference followed by (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>). However, ASGOP was proven to be more effective for the non-replicated scenario. It is worth indicating that axis y which is given the name &#x0201c;TC&#x0201d; in <xref rid="fig10" ref-type="fig">Figure&#x000a0;10</xref> refers to the minimization rate of TC each approach satisfied.<fig id="fig10"><label>Figure&#x000a0;10</label><caption><p>DDBS Performance- The first problem.</p></caption><alt-text id="alttext0055">Figure&#x000a0;10</alt-text><graphic xlink:href="gr10"/></fig></p></sec><sec id="sec4.5"><label>4.5</label><title>Employee dataset</title><p id="p0435">To affirm the performance of ASGOP under different circumstances for both scenarios, further experiments on employee dataset (dataset description along with a sample of eight queries used which are already given in section <xref rid="sec4.2.2" ref-type="sec">4.2.2</xref>) have also been conducted within the frame of the first experiment (the number of sites still six sites). It is worth indicating that the extended comparison has been restricted to be between ASGOP and work of (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>). That is due to the fact that the experiments that were drawn in (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) provided that (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) had outweighed (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>) substantially. Moreover, according to the first experiment of this paper (see Figures&#x000a0;<xref rid="fig6" ref-type="fig">6</xref>, <xref rid="fig7" ref-type="fig">7</xref>, <xref rid="fig8" ref-type="fig">8</xref>, <xref rid="fig9" ref-type="fig">9</xref>, and <xref rid="fig10" ref-type="fig">10</xref>), both ASGOP and (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) are superior to (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>). Given these facts and out of saving computation time (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>), is being excluded from any further examination. On the other hand, each problem (among all problems addressed in <xref rid="tbl16" ref-type="table">Table&#x000a0;16</xref>) has different requirements form one to another in terms of the number of records and queries under consideration as well as the percentage of query-type space.<table-wrap position="float" id="tbl16"><label>Table&#x000a0;16</label><caption><p>Problems requirements.</p></caption><alt-text id="alttext0170">Table&#x000a0;16</alt-text><table frame="hsides" rules="groups"><thead><tr><th colspan="5">#sites = 6<hr/></th></tr><tr><th>P#</th><th>Q#</th><th>Record#</th><th>Q-Read%</th><th>Q-Update%</th></tr></thead><tbody><tr><td>P1</td><td>8</td><td>300</td><td>100%</td><td>0%</td></tr><tr><td>P2</td><td>16</td><td>500</td><td>87.50%</td><td>12.50%</td></tr><tr><td>P3</td><td>24</td><td>650</td><td>85.00%</td><td>15.00%</td></tr><tr><td>P4</td><td>30</td><td>650</td><td>82.00%</td><td>18.00%</td></tr><tr><td>P5</td><td>36</td><td>800</td><td>82.00%</td><td>18.00%</td></tr><tr><td>P6</td><td>42</td><td>1100</td><td>80.00%</td><td>20.00%</td></tr><tr><td>P7</td><td>45</td><td>1200</td><td>75%</td><td>25%</td></tr></tbody></table></table-wrap></p><p id="p0440">The final results are vividly illustrated in Figures&#x000a0;<xref rid="fig11" ref-type="fig">11</xref> and <xref rid="fig12" ref-type="fig">12</xref>. Figures&#x000a0;showed that, over all problems, ASGOP outperforms (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) slightly in terms of replication scenario. However, for the non-replication scenario, <xref rid="fig14" ref-type="fig">Figure&#x000a0;14</xref> recorded that ASGOP outperforms (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) maximally, and these findings are strongly backed by <xref rid="fig15" ref-type="fig">Figure&#x000a0;15</xref> as all results were taken in averaged total.<fig id="fig11"><label>Figure&#x000a0;11</label><caption><p>TC Percentage over all five Problems.</p></caption><alt-text id="alttext0060">Figure&#x000a0;11</alt-text><graphic xlink:href="gr11"/></fig><fig id="fig12"><label>Figure&#x000a0;12</label><caption><p>TC percentage in Average Over all five problems.</p></caption><alt-text id="alttext0065">Figure&#x000a0;12</alt-text><graphic xlink:href="gr12"/></fig></p><p id="p0445">In fact, the final results of experiments on the Employee dataset come to fully confirm the conclusions of results on the Ship dataset (Figures&#x000a0;<xref rid="fig6" ref-type="fig">6</xref>, <xref rid="fig7" ref-type="fig">7</xref>, <xref rid="fig8" ref-type="fig">8</xref>, <xref rid="fig9" ref-type="fig">9</xref>, and <xref rid="fig10" ref-type="fig">10</xref>). These results concluded that ASGOP significantly dominates both works in almost all aspects of DDBS design.</p></sec></sec><sec id="sec5"><label>5</label><title>Discussion</title><p id="p0450">As a matter of fact, in ASGOP (or its counterparts), three parameters have altogether been contributing to the overall performance of DDBS. Data fragmentation, as the first parameter, is performed either using one measure (hamming distance in (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>)) or as a combined measure &#x0201c;an aggregated similarity measure&#x0201d; in ASGOP. The site clustering, as the second parameter, is done differently in ASGOP and its peers, and finally, the data allocation, as the third parameter, which is already made using either a cost model or the greedy based algorithm. All of these parameters are examined severally in this section to examine the single impact of each parameter. In doing so, we can observe which parameter would have the greatest impact on DDBS performance. The undeniable impact of all parameters severally or combined is depicted briefly within the context of the Employee dataset (see section <xref rid="sec4.5" ref-type="sec">4.5</xref>). Data fragmentation impact is implicitly drawn by the impact of similarity measures used to fragment data. This impact is explicitly represented by the number of clusters (data fragments) yielded by each work as given in <xref rid="tbl17" ref-type="table">Table&#x000a0;17</xref>. These statistics shows that ASGOP produces the minimum number of clusters (data fragments) comparing with (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) with almost 26% reduction in the number of clusters. Despite the fact that, as mentioned earlier in section <xref rid="sec4.5" ref-type="sec">(4.5)</xref> (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>), is being excluded as it was outperformed by (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>), we include it into <xref rid="tbl17" ref-type="table">Table&#x000a0;17</xref> to just report that both works (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) have the same number of clusters because they both used hamming distance to fragment data.<table-wrap position="float" id="tbl17"><label>Table&#x000a0;17</label><caption><p>Number of clusters (data fragments) produced by each work.</p></caption><alt-text id="alttext0175">Table&#x000a0;17</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Approach/Problem#</th><th>P1</th><th>P2</th><th>P3</th><th>P4</th><th>P5</th><th>P6</th><th>P7</th><th>Average</th></tr></thead><tbody><tr><td><xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al. (2017)</xref></td><td>2</td><td>3</td><td>6</td><td>6</td><td>7</td><td>7</td><td>8</td><td>5.57</td></tr><tr><td><xref rid="bib2" ref-type="bibr">Abdalla and Artoli (2019)</xref></td><td>2</td><td>3</td><td>6</td><td>6</td><td>7</td><td>7</td><td>8</td><td>5.57</td></tr><tr><td>ASGOP</td><td>2</td><td>3</td><td>4</td><td>4</td><td>5</td><td>5</td><td>6</td><td>4.14</td></tr></tbody></table></table-wrap></p><p id="p0455">On the other extreme, the achievement of this parameter in ASGOP is in fact attributed to the effective use of the combined measure (hamming + nearby) instead of using a standalone measure (hamming). The combined measure contributes remarkably in finding the highly-tightened clusters (data fragments) which in turn led to ASGOP's outperformance. Nevertheless, the time taken (in seconds) to find data clusters was seen less in (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) as they both used one measure to fragment data while ASGOP used combined measure. The combined measure hence needs more time to find the combination, and then fragment data in consequence (see <xref rid="fig13" ref-type="fig">Figure&#x000a0;13</xref>). Albeit the fact that ASGOP saved a computation time by applying the clustering algorithm directly on query set and eliminating the process of finding the numerical pattern of queries. Still, using double measures makes both works (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) significantly faster than ASGOP. This tradeoff is therefore seen unescapable between both works. In the sense that in ASGOP, we are looking to reduce TC so we chose fragments number minimization over the speed needed to find these fragments. The price is then reserved by the smaller number of highly-similar fragments produced by ASGOP which makes sense of using combined measure. In consequent, producing the minimum number of data fragments meant a less complexity and traffic are needed for fragments to be scattered over sites/clusters. This would then lead to gaining the minimum number of visits (less traffic over the network) taken by each distributed query over site(s)/cluster(s) just to be answered. That is one convincing reason for ASGOP supremacy.<fig id="fig13"><label>Figure&#x000a0;13</label><caption><p>The average of time taken (over all problems) to find number of clusters in each work.</p></caption><alt-text id="alttext0070">Figure&#x000a0;13</alt-text><graphic xlink:href="gr13"/></fig><fig id="fig14"><label>Figure&#x000a0;14</label><caption><p>Problem 1, Transmission costs without Site Clustering.</p></caption><alt-text id="alttext0075">Figure&#x000a0;14</alt-text><graphic xlink:href="gr14"/></fig><fig id="fig15"><label>Figure&#x000a0;15</label><caption><p>TC average for all problems, Transmission costs without Site Clustering.</p></caption><alt-text id="alttext0080">Figure&#x000a0;15</alt-text><graphic xlink:href="gr15"/></fig></p><p id="p0460">On the other hand, the second parameter which is the site clustering is implemented in (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) and ASGOP only. We already excluded (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>) from the further process due to its being inferior to (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>). The results showed that the clustering-based approach outperformed the non-clustering based approach for both works (see Figures&#x000a0;<xref rid="fig14" ref-type="fig">14</xref>, <xref rid="fig15" ref-type="fig">15</xref>, <xref rid="fig16" ref-type="fig">16</xref>, and <xref rid="fig17" ref-type="fig">17</xref>). To confirm these claims, this parameter is also examined on both works to oversee the performance with and without site clustering as given in Figures&#x000a0;<xref rid="fig14" ref-type="fig">14</xref>, <xref rid="fig15" ref-type="fig">15</xref>, <xref rid="fig16" ref-type="fig">16</xref>, and <xref rid="fig17" ref-type="fig">17</xref>.<fig id="fig16"><label>Figure&#x000a0;16</label><caption><p>Problem 1, Transmission costs with Site Clustering.</p></caption><alt-text id="alttext0085">Figure&#x000a0;16</alt-text><graphic xlink:href="gr16"/></fig><fig id="fig17"><label>Figure&#x000a0;17</label><caption><p>Average for all problems, Transmission costs with Site Clustering.</p></caption><alt-text id="alttext0090">Figure&#x000a0;17</alt-text><graphic xlink:href="gr17"/></fig></p><p id="p0465">From <xref rid="fig14" ref-type="fig">Figure&#x000a0;14</xref>, it is clear that even when sites were not clustered, ASGOP outperforms (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) slightly in both scenarios. ASGOP behaves better in Q2, Q3, Q6, and Q8 and in the average of all queries as well. Q1 and Q7 were assigned zero values in both works as it was executed locally which means no TC incurred. On the other hand, Q4 and Q5 were in favor of (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>). By following the same pattern of the experiment (1), we took the average of all experiments to surprisingly note that ASGOP still behaves better in both scenarios with 45% and 67% over (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) which recorded 44% and 56% for scenario (1) and scenario (2) respectively. For scenario (1), both works were so close from each other with a &#x0201c;1%&#x0201d; increase in TC minimization for ASGOP, though.</p><p id="p0470">Like <xref rid="fig14" ref-type="fig">Figure&#x000a0;14</xref>, <xref rid="fig15" ref-type="fig">Figure&#x000a0;15</xref> comes to confirm the fact that ASGOP still has the lead over (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) when sites are being clustered. ASGOP behaves much better in Q<sub>2</sub>, Q<sub>3</sub>, Q<sub>4</sub>, Q<sub>5</sub>, Q<sub>6</sub>, Q<sub>8,</sub> and in the average of all queries as well. For scenario 1, Q<sub>1</sub> and Q<sub>7</sub> were assigned zero value in (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) as it was executed locally which means no TC incurred. On the other hand, Q<sub>4</sub> and Q<sub>5</sub> were in favor of (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>). For scenario (2), except Q<sub>4</sub>, ASGOP was super effective in reducing TC. By following the same pattern of experiment (1), we took average of all experiments to amazingly see that ASGOP still behaves much better in both scenarios with 55% and 89% over (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) which recorded 49% and 62% for scenario (1) and scenario (2) respectively.</p><p id="p0475">Furthermore, it is observed that the clustering based ASGOP outweighs the non-clustering based ASGOP by 42% in the average over all problems. This fact comes in complete agreement with results drawn in (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>). It is also noted that site clustering has the greatest impact on DDBS performance as it contributes remarkably in promoting the overall DDBS performance. Figures&#x000a0;<xref rid="fig14" ref-type="fig">14</xref> and <xref rid="fig15" ref-type="fig">15</xref> show that both works behave closely to each other. However, Figures&#x000a0;<xref rid="fig16" ref-type="fig">16</xref> and <xref rid="fig17" ref-type="fig">17</xref> show that when the sites are being clustered, the difference in the performance of both works has been clearly marked with ASGOP being superior. This, in fact, could be attributed in one way or another to the use of both the aggregated similarity measure and the greedy base algorithm adopted in ASGOP to solve the DAP problem compared to the cost model used in (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>). As a matter of fact, as expected in terms of site clustering impact, these results agree entirely with results drawn in (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>) which previously determined the greatest impact of site clustering on DDBS performance.</p><p id="p0480">The third parameter is the data allocation which is already drawn in terms of the whole "building block" design of DDBS. We performed the whole design one time using the cost model of (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) and another time using the greedy based approach (ASGOP). According to results, which are already drawn above in Figures&#x000a0;<xref rid="fig6" ref-type="fig">6</xref>, <xref rid="fig7" ref-type="fig">7</xref>, <xref rid="fig8" ref-type="fig">8</xref>, <xref rid="fig9" ref-type="fig">9</xref>, <xref rid="fig10" ref-type="fig">10</xref>, <xref rid="fig11" ref-type="fig">11</xref>, and <xref rid="fig12" ref-type="fig">12</xref>; 16&#x02013;17, ASGOP outperforms (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) in all aspects. In some cases, however, both approaches showed to be close to each other specifically for the replication scenario. Hence, using the greedy based approach has been an obvious reason for ASGOP supremacy that led to ASGOP yielding minimum TC which is essentially the objective function of all works.</p><p id="p0485"><bold>Lastly but not least</bold>, based on the above concisely-drawn results and discussion, it can be confidently concluded that the data replication has a demoralizing impact on TC minimization, chiefly as update queries occupy the larger space of considered queries. The drawn results in Figures&#x000a0;<xref rid="fig6" ref-type="fig">6</xref>, <xref rid="fig8" ref-type="fig">8</xref>, and <xref rid="fig10" ref-type="fig">10</xref> revealed that the replication scenario is the best choice when retrieval queries rate is larger than the update rate as it was the case in (P<sub>1</sub>&#x02013;P<sub>3</sub>). However, this scenario started to negatively affect TC when update queries significantly grew as given in problems (P<sub>4</sub>&#x02013;P<sub>7</sub>). On the other hand, the non-replication scenario was recorded to be by far the best option specifically when update queries made the large percentage of considered queries (P<sub>4</sub>&#x02013;P<sub>7</sub>). This fact is reinforced when several problems were addressed for all considered works as shown in Figures&#x000a0;<xref rid="fig7" ref-type="fig">7</xref>, <xref rid="fig9" ref-type="fig">9</xref>, and <xref rid="fig11" ref-type="fig">11</xref>. Furthermore, these findings come to confirm the validity of the results of (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) in terms of both replication and non-replication scenarios. In addition to that, it is worth stressing that the results of ASGOP come in full consistency with (<xref rid="bib5" ref-type="bibr">Amer, 2018</xref>) with respect to the impact of data replication on DDBS performance.</p><p id="p0490">To sum up, from the drawn-above discussion, three points could be deduced as follows;<list list-type="simple" id="ulist0010"><list-item id="u0010"><label>-</label><p id="p0495">For the replication-based scenario, whenever sites, their relative clusters and considered queries are steadily growing with update queries being the larger space of all considered queries, TC is progressively maximized along with substantial degradation recorded for DDBS performance. These findings are supported by the drawn results of experiments conducted for the replication-based scenarios of both works ASGOP and (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>).</p></list-item><list-item id="u0015"><label>-</label><p id="p0500">For the non-replication-based scenario, whenever sites, their relative clusters and considered queries are steadily swelling, whether update queries occupy a larger space of all considered queries or not, TC is imperceptibly maximized along with slight degradation observed at DDBS performance. These findings are supported by the drawn results of experiments conducted for both non-replication based scenarios of both ASGOP and (<xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>). Moreover, the non-replicated data allocation scenario of ASGOP has been proven to be the most effective scenario in all circumstances due to the greedy-nature algorithm of ASGOP. Consequently, this scenario can be selected to be incorporated in DDBS design specifically as update queries are significantly increased.</p></list-item><list-item id="u0020"><label>-</label><p id="p0505">Theoretically and empirically, compared to (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>), ASGOP used an aggregated similarity measure to: (1) reinforce the latent similarity between queries, (2) eliminate the need to QACM-producing process which led to reduce the computation time. Consequently, AHC was applied directly on the distance matrix which obtained using the proposed aggregated similarity measure. Instead of direct use of cost model to solve the data allocation, ASGOP pursued to solve the model itself using dynamic programming and it is proven practically effective. Lastly, according to the evaluation section, ASGOP has been successful at securing significantly better results than its peers. Most importantly, while both (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) used <bold>two</bold> cost models to perform fragmentation and allocation, ASGOP leveraged <bold>one</bold> cost model to solve the data allocation using a greedy algorithm.</p></list-item></list></p></sec><sec id="sec6"><label>6</label><title>Conclusions and future work</title><p id="p0510">This work comes with the main task embedded at presenting a well-articulated solution for DDBS design. It was primarily proposed with the key aim of highly reducing communication cost among network sites. An aggregated similarity-based hierarchical clustering algorithm for queries was developed to fragment data. The presented fragmentation procedure was set to be used in the context of the relational database, at the initial and later stages of DDBS design. The aggregated similarity struggled to find and reinforce the exact match between the considered queries so as to each cluster would contain only those highly-related queries. Then, to allocate fragmented data, a greedy-driven data allocation process was evolved. For the site clustering process, it was accomplished in the manner that ensures using the hierarchical clustering along with utilizing the concept of LDV proposed in (<xref rid="bib4" ref-type="bibr">Amer et&#x000a0;al., 2017</xref>).</p><p id="p0515">On the other hand, for data allocation procedure, each fragment was decisively allocated into the site of minimum TC at each cluster on the basis of the Knapsack-inspired algorithm of greedy nature. In the sense that fragment would not be given to the targeted site unless it is guaranteed that no competitive site of minimum TC was found. That is, whenever the site of the lowest value of TC was identified; it was set to be the only container for that fragment within clusters individually. Two scenarios were considered for data allocation. In the first scenario, each fragment was allocated redundantly to all clusters and then to its best-fitting site in each relative cluster providing that objective function (TC) has been minimized. In the second scenario, in contrast, each fragment was assigned to one site (of the lowest TC value) among all sites of the network. Through this paper, several practical and empirical experiments have been conducted for the present work of this paper (ASGOP) and both (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>). The results were evaluated against each other in the purpose of verifying the mechanism of all works on the two data allocation scenarios under several circumstances. All the experimental results came in favor of ASGOP, specifically when the non-replication based scenario was adopted. The creativity of ASGOP lied in the proposed procedure of greedy-natured data allocation as each data fragment initially assigned to each site, the most-frequently-used queries then exposed on that site and concerned fragment at the same time. Consequently, among all sites of the network, that fragment was permanently given to the site of the lowest transmission costs (TC). According to the evaluation section, this step contributed remarkably at both decreasing TC and increasing DDBS performance as distributed queries processed were processed.</p><p id="p0520">Finally, all parameters (data fragmentation, data allocation, and site clustering) that contribute to building the whole design of DDBSs has been severally examined. The examination is dedicated to identifying the parameter of the greatest impact on DDBS performance. Surprisingly, according to the drawn-above concisely-made discussion, site clustering has been the parameter of greatest impact with reduction reach almost 89% in TC. Experiments have been conducted with and without using site clustering to assert this claim which is proven completely correct. The next parameter has been the whole building block (all parameters) and clearly reflected on the overall performance of DDBS. Data fragmentation has occupied the third order in terms of impact on DDBS performance with a 26% reduction in TC.</p><sec id="sec6.1"><label>6.1</label><title>Future work</title><p id="p0525">While doing this research paper, an important limitation has been noted. This limitation represented in the fact that neither ASGOP nor did (<xref rid="bib19" ref-type="bibr">Sewisy et&#x000a0;al., 2017</xref>; <xref rid="bib2" ref-type="bibr">Abdalla and Artoli, 2019</xref>) study the behavior of join-based queries. That is due to the fact that this type of query is of high-cost operations. In the follow-up work, in consequence, it is set to investigate the impact of such queries on DDBS performance. Moreover, the design of DDBS using K-means is going to be investigated and compared with the hierarchical clustering-based design.</p></sec></sec><sec id="sec7"><title>Declarations</title><sec id="sec7.1"><title>Author contribution statement</title><p id="p0530">Ali A. Amer: Conceived and designed the experiments; Performed the experiments; Analyzed and interpreted the data; Contributed reagents, materials, analysis tools or data; Wrote the paper.</p><p id="p0535">Marghny H. Mohamed: Performed the experiments; Contributed reagents, materials, analysis tools or data; Wrote the paper.</p><p id="p0540">Khaled Abdullah Al_Asri: Conceived idea; Analyzed and interpreted the data; Contributed reagents, materials, analysis tools or data.</p></sec><sec id="sec7.2"><title>Funding statement</title><p id="p0545">This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.</p></sec><sec id="sec7.3"><title>Competing interest statement</title><p id="p0550">The authors declare no conflict of interest.</p></sec><sec id="sec7.4"><title>Additional information</title><p id="p0555">No additional information is available for this paper.</p></sec></sec></body><back><ref-list id="cebib0010"><title>References</title><ref id="bib1"><element-citation publication-type="journal" id="sref1"><person-group person-group-type="author"><name><surname>Abdalla</surname><given-names>H.I.</given-names></name><name><surname>Amer</surname><given-names>A.A.</given-names></name><name><surname>Mathkour</surname><given-names>H.</given-names></name></person-group><article-title>Performance optimality enhancement algorithm in DDBS (POEA)</article-title><source>Comput. Hum. Behav.</source><volume>30</volume><year>2014</year><fpage>419</fpage><lpage>426</lpage></element-citation></ref><ref id="bib2"><element-citation publication-type="journal" id="sref2"><person-group person-group-type="author"><name><surname>Abdalla</surname><given-names>H.</given-names></name><name><surname>Artoli</surname><given-names>A.M.</given-names></name></person-group><article-title>Towards an efficient data fragmentation, allocation, and clustering approach in a distributed environment</article-title><source>Information</source><volume>10</volume><year>2019</year><fpage>112</fpage></element-citation></ref><ref id="bib4"><element-citation publication-type="journal" id="sref4"><person-group person-group-type="author"><name><surname>Amer</surname><given-names>A.A.</given-names></name><name><surname>Sewisy</surname><given-names>A.A.</given-names></name><name><surname>Elgendy</surname><given-names>T.M.</given-names></name></person-group><article-title>An optimized approach for simultaneous horizontal data fragmentation and allocation in Distributed Database Systems (DDBSs)</article-title><source>Heliyon</source><volume>3</volume><year>2017</year></element-citation></ref><ref id="bib5"><element-citation publication-type="book" id="sref5"><person-group person-group-type="author"><name><surname>Amer</surname><given-names>A.A.</given-names></name></person-group><chapter-title>Data Replication Impact on DDBS System Performance, Semantic Web Science and Real-World Applications Advances in Web Technologies and Engineering</chapter-title><year>2018</year><fpage>134</fpage><lpage>162</lpage></element-citation></ref><ref id="bib6"><element-citation publication-type="book" id="sref6"><person-group person-group-type="author"><name><surname>Amer</surname><given-names>A.A.</given-names></name><name><surname>Mohamed</surname><given-names>M.H.</given-names></name><name><surname>Sewisy</surname><given-names>A.A.</given-names></name><name><surname>Asri</surname><given-names>K.A.</given-names></name></person-group><chapter-title>An Aggregated Similarity Based Hierarchical Clustering Technique for Relational DDBS Design, 2018 Fifth International Conference on Parallel, Distributed and Grid Computing (PDGC)</chapter-title><year>2018</year></element-citation></ref><ref id="bib7"><element-citation publication-type="book" id="sref7"><person-group person-group-type="author"><name><surname>Amer</surname><given-names>A.A.</given-names></name><name><surname>Mohamed</surname><given-names>M.H.</given-names></name><name><surname>Al_Asri</surname><given-names>K.</given-names></name></person-group><chapter-title>On an effective hierarchical clustering based model for data fragmentation and allocation in relational DDBS</chapter-title><source>Proceedings of the 4th ACM International Conference of Computing for Engineering and Sciences on - ICCES18</source><year>2018</year></element-citation></ref><ref id="bib8"><element-citation publication-type="journal" id="sref8"><person-group person-group-type="author"><name><surname>Apers</surname><given-names>P.M.G.</given-names></name></person-group><article-title>Data allocation in distributed database systems</article-title><source>ACM Trans. Database Syst.</source><volume>13</volume><year>1988</year><fpage>263</fpage><lpage>304</lpage></element-citation></ref><ref id="bib9"><element-citation publication-type="book" id="sref9"><person-group person-group-type="author"><name><surname>Hamming</surname><given-names>R.W.H.W.</given-names></name></person-group><chapter-title>Error detecting and error correcting codes</chapter-title><source>The Bell System Technical Journal</source><edition>2nd ed.</edition><volume>29</volume><year>1950</year><fpage>147</fpage><lpage>160</lpage></element-citation></ref><ref id="bib10"><element-citation publication-type="book" id="sref10"><person-group person-group-type="author"><name><surname>Kamali</surname><given-names>S.</given-names></name><name><surname>Ghodsnia</surname><given-names>P.</given-names></name><name><surname>Daudjee</surname><given-names>K.</given-names></name></person-group><chapter-title>Dynamic Data Allocation with Replication in Distributed Systems, 30th IEEE International Performance Computing and Communications Conference</chapter-title><year>2011</year></element-citation></ref><ref id="bib11"><element-citation publication-type="book" id="sref11"><person-group person-group-type="author"><name><surname>Li</surname><given-names>S.P.</given-names></name><name><surname>Wong</surname><given-names>M.H.</given-names></name></person-group><chapter-title>Data Allocation in Scalable Distributed Database Systems Based on Time Series Forecasting, 2013 IEEE International Congress on Big Data</chapter-title><year>2013</year></element-citation></ref><ref id="bib12"><element-citation publication-type="book" id="sref12"><person-group person-group-type="author"><name><surname>Lotfi</surname><given-names>N.</given-names></name></person-group><chapter-title>Data Allocation in Distributed Database Systems: a Novel Hybrid Method Based on Differential Evolution and Variable Neighborhood Search</chapter-title><year>2019</year><publisher-name>SpringerLink</publisher-name><ext-link ext-link-type="uri" xlink:href="https://link.springer.com/article/10.1007/s42452-019-1787-3" id="intref0010">https://link.springer.com/article/10.1007/s42452-019-1787-3</ext-link></element-citation></ref><ref id="bib13"><element-citation publication-type="book" id="sref13"><person-group person-group-type="author"><name><surname>Luong</surname><given-names>V.N.</given-names></name><name><surname>Le</surname><given-names>V.S.</given-names></name><name><surname>Doan</surname><given-names>V.B.</given-names></name></person-group><chapter-title>Fragmentation in Distributed Database Design Based on KR Rough Clustering Technique, Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering Context-Aware Systems and Applications, and Nature of Computation and Communication</chapter-title><year>2018</year><fpage>166</fpage><lpage>172</lpage></element-citation></ref><ref id="bib14"><element-citation publication-type="journal" id="sref14"><person-group person-group-type="author"><name><surname>Mahi</surname><given-names>M.</given-names></name><name><surname>Baykan</surname><given-names>O.K.</given-names></name><name><surname>Kodaz</surname><given-names>H.</given-names></name></person-group><article-title>A&#x000a0;new approach based on particle swarm optimization algorithm for solving data allocation problem</article-title><source>Appl. Soft Comput.</source><volume>62</volume><year>2018</year><fpage>571</fpage><lpage>578</lpage></element-citation></ref><ref id="bib15"><element-citation publication-type="journal" id="sref15"><person-group person-group-type="author"><name><surname>Mukherjee</surname><given-names>N.</given-names></name></person-group><article-title>Synthesis of non-replicated dynamic fragment allocation algorithm in distributed database systems</article-title><source>Int. J. Inform. Technol.</source><volume>V. 01</volume><year>2011</year><comment>No. 01</comment><ext-link ext-link-type="uri" xlink:href="http://searchdl.org/public/journals/2011/IJIT/1/1/98.pdf" id="intref0015">http://searchdl.org/public/journals/2011/IJIT/1/1/98.pdf</ext-link></element-citation></ref><ref id="bib16"><element-citation publication-type="journal" id="sref16"><person-group person-group-type="author"><name><surname>Nashat</surname><given-names>D.</given-names></name><name><surname>Amer</surname><given-names>A.A.</given-names></name></person-group><article-title>A&#x000a0;comprehensive taxonomy of fragmentation and allocation techniques in distributed database design</article-title><source>ACM Comput. Surv.</source><volume>51</volume><year>2018</year><fpage>1</fpage><lpage>25</lpage></element-citation></ref><ref id="bib17"><element-citation publication-type="book" id="sref17"><person-group person-group-type="author"><name><surname>Rahmani</surname><given-names>S.</given-names></name><name><surname>Torkzaban</surname><given-names>V.</given-names></name><name><surname>Haghighat</surname><given-names>A.T.</given-names></name></person-group><chapter-title>A&#x000a0;New Method of Genetic Algorithm for Data Allocation in Distributed Database Systems, 2009 First International Workshop on Education Technology and Computer Science</chapter-title><year>2009</year></element-citation></ref><ref id="bib18"><element-citation publication-type="journal" id="sref18"><person-group person-group-type="author"><name><surname>Raouf</surname><given-names>A.E.A.</given-names></name><name><surname>Badr</surname><given-names>N.L.</given-names></name><name><surname>Tolba</surname><given-names>M.F.</given-names></name></person-group><article-title>Dynamic data reallocation and replication over a cloud environment</article-title><source>Concurrency Comput. Pract. Ex.</source><volume>30</volume><year>2018</year></element-citation></ref><ref id="bib19"><element-citation publication-type="journal" id="sref19"><person-group person-group-type="author"><name><surname>Sewisy</surname><given-names>A.A.</given-names></name><name><surname>Amer</surname><given-names>A.A.</given-names></name><name><surname>Abdalla</surname><given-names>H.I.</given-names></name></person-group><article-title>A&#x000a0;novel query-driven clustering-based technique for vertical fragmentation and allocation in distributed database systems</article-title><source>Int. J. Semantic Web Inf. Syst.</source><volume>13</volume><year>2017</year><fpage>27</fpage><lpage>54</lpage></element-citation></ref><ref id="bib20"><element-citation publication-type="book" id="sref20"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>A.</given-names></name></person-group><chapter-title>Empirical evaluation of threshold and time constraint algorithm for non-replicated dynamic data allocation in distributed database systems</chapter-title><source>Proceedings of the International Congress on Information and Communication Technology Advances in Intelligent Systems and Computing</source><year>2016</year><fpage>131</fpage><lpage>138</lpage></element-citation></ref><ref id="bib21"><element-citation publication-type="book" id="sref21"><person-group person-group-type="author"><name><surname>Tonini</surname><given-names>G.</given-names></name><name><surname>Siqueira</surname><given-names>F.</given-names></name></person-group><chapter-title>A&#x000a0;distributed data allocation algorithm for biological databases</chapter-title><source>IEEE 16th International Conference on Computational Science and Engineering. (2013)</source><year>2013</year></element-citation></ref><ref id="bib22"><element-citation publication-type="journal" id="sref22"><person-group person-group-type="author"><name><surname>Wiese</surname><given-names>L.</given-names></name><name><surname>Waage</surname><given-names>T.</given-names></name><name><surname>Bollwein</surname><given-names>F.</given-names></name></person-group><article-title>A&#x000a0;replication scheme for multiple fragmentations with overlapping fragments</article-title><source>Comput. J.</source><year>2016</year></element-citation></ref><ref id="bib23"><element-citation publication-type="journal" id="sref23"><person-group person-group-type="author"><name><surname>Wolfson</surname><given-names>O.</given-names></name><name><surname>Jajodia</surname><given-names>S.</given-names></name><name><surname>Huang</surname><given-names>Y.</given-names></name></person-group><article-title>An adaptive data replication algorithm</article-title><source>ACM Trans. Database Syst.</source><volume>22</volume><year>1997</year><fpage>255</fpage><lpage>314</lpage></element-citation></ref></ref-list><ack id="ack0010"><title>Acknowledgements</title><p>The authors would like to heartily express their sincere appreciation to both HELIYON Team (Editors, in particular) along with those respected unknown reviewers for their invaluable guidance, comments, and suggestions that otherwise this research paper would not be improved and released.</p></ack></back></article>