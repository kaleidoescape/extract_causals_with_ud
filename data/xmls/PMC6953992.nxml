<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?properties manuscript?><front><journal-meta><journal-id journal-id-type="nlm-journal-id">101122185</journal-id><journal-id journal-id-type="pubmed-jr-id">42963</journal-id><journal-id journal-id-type="nlm-ta">Acta Acust United Acust</journal-id><journal-id journal-id-type="iso-abbrev">Acta Acust United Acust</journal-id><journal-title-group><journal-title>Acta acustica united with acustica : the journal of the European Acoustics Association (EEIG)</journal-title></journal-title-group><issn pub-type="ppub">1610-1928</issn><issn pub-type="epub">1861-9959</issn></journal-meta><article-meta><article-id pub-id-type="pmid">31929768</article-id><article-id pub-id-type="pmc">6953992</article-id><article-id pub-id-type="doi">10.3813/AAA.919279</article-id><article-id pub-id-type="manuscript">NIHMS1015866</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A Model for Statistical Regularity Extraction from Dynamic Sounds</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Skerritt-Davis</surname><given-names>Benjamin</given-names></name></contrib><contrib contrib-type="author"><name><surname>Elhilali</surname><given-names>Mounya</given-names></name></contrib><aff id="A1">Johns Hopkins University, Baltimore, Maryland, United States. <email>mounya@jhu.edu</email></aff></contrib-group><pub-date pub-type="nihms-submitted"><day>27</day><month>3</month><year>2019</year></pub-date><pub-date pub-type="epub"><day>7</day><month>12</month><year>2018</year></pub-date><pub-date pub-type="ppub"><season>Jan-Feb</season><year>2019</year></pub-date><pub-date pub-type="pmc-release"><day>10</day><month>1</month><year>2020</year></pub-date><volume>105</volume><issue>1</issue><fpage>1</fpage><lpage>4</lpage><!--elocation-id from pubmed: 10.3813/AAA.919279--><permissions><license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article under the terms of the Creative Commons Attribution (CC BY 4.0) license.</license-p></license></permissions><abstract id="ABS1"><title>Summary</title><p id="P1">To understand our surroundings, we effortlessly parse our sound environment into sound sources, extracting invariant information&#x02014;or regularities&#x02014;over time to build an internal representation of the world around us. Previous experimental work has shown the brain is sensitive to many types of regularities in sound, but theoretical models that capture underlying principles of regularity tracking across diverse sequence structures have been few and far between. Existing efforts often focus on sound patterns rather the stochastic nature of sequences. In the current study, we employ a perceptual model for regularity extraction based on a Bayesian framework that posits the brain collects statistical information over time. We show this model can be used to simulate various results from the literature with stimuli exhibiting a wide range of predictability. This model can provide a useful tool for both interpreting existing experimental results under a unified model and providing predictions for new ones using more complex stimuli.</p></abstract></article-meta></front><body><sec id="S1"><label>1.</label><title>Introduction</title><p id="P2">Regularity extraction is an essential aspect of auditory object perception, in which the brain extracts useful information from sounds over time to interpret our surroundings [<xref rid="R1" ref-type="bibr">1</xref>]. This ability is often studied in the literature using deviance detection experiments, where listeners are presented with a sequence of sounds exhibiting some regularity and responses are compared between the members of the regularity and deviations from the regularity for signs of detection in the brain [<xref rid="R2" ref-type="bibr">2</xref>]. Behavioral and neural evidence has shown the brain is sensitive to a variety of regularities, with the mismatch negativity (MMN) as a typical marker of deviance detection in electroencephalography (EEG) and magnetoencephalography (MEG) [<xref rid="R3" ref-type="bibr">3</xref>].</p><p id="P3">The manner in which these regularities are represented in the brain is unknown. A repeating pattern could be represented explicitly as a &#x0201c;template&#x0201d;, but this mechanism would be computationally inefficient to represent the vast richness of natural sounds in the brain. It is more plausible that the brain employs a statistical description of sounds that incorporates uncertainty to robustly abstract out invariant information. Existing models are limited in scope and generalizability, either representing only repeating patterns [<xref rid="R5" ref-type="bibr">5</xref>] or computationally constrained to a small set of discrete symbols [<xref rid="R6" ref-type="bibr">6</xref>], rather than sounds that vary along a continuum.</p><p id="P4">We use a perceptual model that embodies Bayesian theories of perception, collecting statistical representations of sounds [<xref rid="R7" ref-type="bibr">7</xref>, <xref rid="R8" ref-type="bibr">8</xref>]. To demonstrate its utility, we show this model accounts for many findings in the literature from the regularity extraction canon, re-casting existing results in terms of <italic>statistical regularity extraction.</italic></p></sec><sec id="S2"><label>2.</label><title>Model Description</title><p id="P5">We use the Dynamic Regularity Extraction (D-REX) model<sup><xref ref-type="fn" rid="FN1">1</xref></sup> presented in [<xref rid="R9" ref-type="bibr">9</xref>] to simulate findings in the literature. This model is based on a Bayesian inference framework designed to perform sequential predictions in dynamic sequences containing unknown changes in underlying statistical structure [<xref rid="R10" ref-type="bibr">10</xref>, <xref rid="R11" ref-type="bibr">11</xref>].</p><p id="P6">The input to the model is a sequence of observations <italic>{x</italic><sub><italic>t</italic></sub><italic>}</italic> assumed to be distributed according to a probability distribution with unknown parameters <italic>&#x003b8;</italic>; presently, observations are limited to a sequence of tone frequencies from a single sound source. The model sequentially builds a predictive distribution for the next observation at time <italic>t +</italic> 1 using sufficient statistics <inline-formula><mml:math display="inline" id="M1" overflow="scroll"><mml:mover accent="true"><mml:mi>&#x003b8;</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> collected over the observed sequence: <inline-formula><mml:math display="inline" id="M2" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mover accent="true"><mml:mi>&#x003b8;</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula></p><p id="P7">The underlying distribution is assumed to be a D-variate Gaussian, where the dimensionality <italic>D</italic> specifies the amount of temporal covariance collected by the model; for example, a model with <italic>D</italic> = 1 collects marginal statistics (mean and variance), while a model with <italic>D</italic> = 3 additionally collects joint statistics (covariances) between <italic>x</italic><sub><italic>t</italic></sub><italic>, x</italic><sub><italic>t</italic>-1</sub>, and <italic>x</italic><sub><italic>t</italic>-2</sub>.</p><p id="P8">The model assumes the parameters <italic>&#x003b8;</italic> change at un-known changepoint times. All following observations are then independent of those preceding the change, thus limiting the context window of observations relevant for the parameter estimates <inline-formula><mml:math display="inline" id="M3" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>&#x003b8;</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> Because changepoints must be inferred from the observations, the model maintains multiple hypotheses across different contexts and then &#x0201c;integrates out&#x0201d; the context to build a prediction that adapts to un-known changes:
<disp-formula id="FD1"><label>(1)</label><mml:math display="block" id="M4" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mi>P</mml:mi></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P9">In the sum, the first term is the prediction given the context <italic>c</italic><sub><italic>t</italic></sub> (which only depends on observations <italic>within</italic> the context window); this is weighted by the second term, the model belief that the current context <italic>is c</italic><sub><italic>t</italic></sub>. With each incoming observation, the sufficient statistics for each context <italic>c</italic><sub><italic>t</italic></sub>, as well as the beliefs, are updated incrementally (see [<xref rid="R9" ref-type="bibr">9</xref>] for details).</p><sec id="S3"><label>2.1.</label><title>Perceptual parameters</title><p id="P10">As described thus far, the model makes Bayes-optimal predictions in the presence of changepoints [<xref rid="R10" ref-type="bibr">10</xref>]. To introduce more perceptual plausibility, we impose two constraints on the model. First, a memory parameter (<bold><italic>M</italic></bold>) represents finite working memory capacity, limiting how many past observations can be used to build predictions and, by extension, the number of context windows that can be maintained. Second, an observation noise parameter (<bold><italic>N</italic></bold>) sets a lower bound on prediction uncertainty. These parameters represent variabilities in perceptual abilities across individual listeners and allow for a range of behaviors from the model.</p></sec><sec id="S4"><label>2.2.</label><title>Surprisal response</title><p id="P11">With each observation, the model outputs prediction error, or <italic>surprisal: <inline-formula><mml:math display="inline" id="M5" overflow="scroll"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>log</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula></italic>where <italic>X</italic><sub>t+1</sub> is the observation at time <italic>t +</italic> 1. Note that an observation with low predictive probability has high surprisal and vice versa. In the Results section, we compare this surprisal response from the model to deviance responses in neural results from the literature.</p></sec></sec><sec id="S5"><label>3.</label><title>Results</title><p id="P12">We collected surprisal responses from the D-REX model to stimuli found in the deviance and change detection literature. Stimuli range in predictability to show the capacity of the model to capture a variety of phenomena under a single framework. Using different sets of statistics in the model (via the dimensionality <italic>D</italic>), we can ascertain the statistics that are sufficient&#x02014;the &#x0201c;simplest explanation&#x0201d;&#x02014; for responses observed in the brain.</p><p id="P13">In Figures <xref rid="F1" ref-type="fig">1</xref> and <xref rid="F2" ref-type="fig">2</xref>, neural results directly from the literature are presented alongside model results for comparison (e.g., MMN amplitude vs. surprisal), with example stimuli shown above each result. Trends shared between neural and model results are indicated by red arrows. To facilitate visual comparison, the surprisal axis is occasionally inverted to align higher surprisal in the model results with lower predictability in the neural results. Figures from the literature are reproduced in their original form, where possible.</p><sec id="S6"><title>Oddball.</title><p id="P14">Dating back to 1978, N&#x000e4;&#x000e4;t&#x000e4;nen and colleagues have used the oddball paradigm to elicit neural markers of deviance from a detected regularity [<xref rid="R3" ref-type="bibr">3</xref>, <xref rid="R4" ref-type="bibr">4</xref>]. The paradigm includes a <italic>standard</italic> stimulus exhibiting some regularity and <italic>deviant</italic> stimuli breaking the regularity; if the brain is sensitive to the regularity, the mismatch negativity (MMN) appears around 100&#x02013;200 ms after onset in the deviant&#x02019;s Event-Related Potential (ERP) response relative to the standard. This negativity increases with frequency distance between the deviant and standard [<xref rid="R12" ref-type="bibr">12</xref>]. The D-REX model with <italic>D =</italic> 1, or marginal statistics, similarly shows an increase in surprisal to the deviant as frequency distance increases (see <xref rid="F1" ref-type="fig">Figure 1a</xref>).</p></sec><sec id="S7"><title>Roving oddball.</title><p id="P15">The oddball paradigm has been extended using a standard that changes over time, where each deviant becomes the new standard. As the number of standards increases, ERP response to the <italic>standard</italic> increases in the MMN window (80&#x02013;180 ms), while response to the <italic>deviant</italic> stay relatively the same [<xref rid="R13" ref-type="bibr">13</xref>]; similarly, as the number of standards increases, model surprisal with <italic>D</italic> = 1 decreases (<italic>F</italic><sub>2</sub>,<sub>147</sub> = 108.1,<italic>p</italic> &#x0003c; 0.0001), while surprisal to deviants stays the same (<italic>F</italic><sub>2</sub>,<sub>147</sub> = 1.18,<italic>p</italic> &#x0003e; 0.1) (see <xref rid="F1" ref-type="fig">Figure 1b</xref>, surprisal axis flipped for visual comparison).</p></sec><sec id="S8"><title>Pattern oddball.</title><p id="P16">Tone-patterns can also serve as standards in the oddball paradigm. In [<xref rid="R14" ref-type="bibr">14</xref>], an MMN response to the first tone of the deviant pattern (BBAA) relative to the first tone of the standard pattern (AABB) indicates the brain is sensitive to the 4-tone pattern. In the model&#x02019;s surprisal response, this is replicated with dimensionality <italic>D &#x0003e;</italic> 2 (<italic>t</italic><sub>74</sub> = 15.1,<italic>p</italic> &#x0003c; 0.0001), indicating the minimal statistics necessary to detect the deviant is actually over a shorter window than the pattern itself; deviance can be detected by the entire 4-tone pattern or by three repetitions of the same tone (see <xref rid="F1" ref-type="fig">Figure 1c</xref>).</p></sec><sec id="S9"><title>High- &#x00026; low-predictability oddball.</title><p id="P17">Top-down attentional affects have been measured in the MMN response. In [<xref rid="R15" ref-type="bibr">15</xref>], the MMN response was measured in two conditions: a high-predictability condition where the number of standards preceding a deviant was usually 4 (AAAAB), and a low-predictability condition where the number of standards was uniformly distributed between 2 and 6. Listeners were tasked with detecting every deviant (B). ERP evidence shows a significant MMN response to deviants but <italic>no difference</italic> in MMN magnitude between predictability conditions; this null result is replicated by differential surprisal betweeen deviant and standard from the model with <italic>D</italic> = 1 collecting only marginal statistics (<italic>t</italic><sub>23</sub> = 1.27<italic>,p &#x0003e;</italic> 0.1) (see <xref rid="F1" ref-type="fig">Figure 1d</xref>).</p><p id="P18">By contrast, a model with <italic>D</italic> = 6 collects temporal covariances that cover the entire AAAAB pattern and no longer finds the final B tone &#x0201c;surprising&#x0201d; (see <xref rid="F1" ref-type="fig">Figure 1d</xref>-right). This mirrors a similar study where listeners were tasked with listening for the entire pattern and exhibited no MMN response to the deviant tone [<xref rid="R19" ref-type="bibr">19</xref>]. These top-down effects can be described in terms of the statistics being collected&#x02014;when attending to the B tone only, listeners collect marginal statistics; when attending to the entire AAAAB pattern, listeners collect long-range temporal statistics.</p></sec><sec id="S10"><title>Statistical oddball biased toward large or small changes.</title><p id="P19">Context effects have been observed in the MMN response by manipulating the relative probabilities of deviants, biasing them toward small- or large-change deviants [<xref rid="R16" ref-type="bibr">16</xref>]. Effects due to spectral change (between deviant and standard) and statistical context are observed in N1 amplitude: magnitude increases with spectral change and is augmented by the small-change context, where large changes are less probable. An ANOVA applied to model surprisal (with <italic>D</italic> = 1) shows the same significant effects for spectral change (<italic>F</italic><sub>2</sub>,<sub>477</sub> = 668.66,<italic>p</italic> &#x0003c; 0.0001) and statistical context (<italic>F</italic><sub>1,477</sub> = 221.14,<italic>p</italic> &#x0003c; 0.0001) (see <xref rid="F2" ref-type="fig">Figure 2a</xref>).</p></sec><sec id="S11"><title>Gaussian sequences differing in variance.</title><p id="P20">Context effects have also been observed using random stimuli drawn from a Gaussian distribution with different variances [<xref rid="R17" ref-type="bibr">17</xref>]. Responses to deviants (presented 2 octaves above the mean) show a negative peak around 120 ms that is larger for narrow relative to broad statistical context. Additionally, there is evidence of adaptation effects in the broad context when comparing deviant responses based on the number of preceding tones <italic>(N</italic><sub><italic>a</italic></sub><italic>)</italic> falling outside a fre- quencyregion (&#x00394;<italic>F</italic><sub><italic>a</italic></sub>) (see [<xref rid="R17" ref-type="bibr">17</xref>] for details). The model with <italic>D</italic> = 1 replicates these results (see <xref rid="F2" ref-type="fig">Figure 2b</xref>).</p></sec><sec id="S12"><title>Regular vs. random sequences.</title><p id="P21">Repeating patterns are another class of stimuli used to explore regularity extraction in the brain. In particular, RMS power in MEG has been shown to increase with decreasing entropy in the stimulus [<xref rid="R18" ref-type="bibr">18</xref>]: RMS power <italic>increases gradually</italic> when the stimulus transitions from random to repeating pattern (RAND-REG), while RMS power <italic>decreases abruptly</italic> for the opposite transition (REG-RAND). The model replicates both of these phenomena in the time-course of sur- prisal, with <italic>D</italic> greater than the pattern length (see <xref rid="F2" ref-type="fig">Figure 2c</xref>). Additionally, the model replicates effects of pattern length on RMS power [<xref rid="R18" ref-type="bibr">18</xref>], again reflecting differences in entropy (see <xref rid="F2" ref-type="fig">Figure 2d</xref>).</p></sec></sec><sec id="S13"><label>4.</label><title>Conclusion</title><p id="P22">The D-REX model utilizes statistical descriptions of sound sequences to replicate findings across a wide swath of the regularity extraction literature. While these statistical descriptions may not be <italic>necessary</italic> to replicate these findings, the model provides a unified interpretation that is more generalizable toward natural sounds, where randomness and noise abound. Beyond retrospective intepreta-tion of existing results, the D-REX model can be used to guide future experiments probing the temporal processing of more complex sounds. Moreover, since the model employs a Bayesian framework that is agnostic to probability distributions and underlying statistics, the D-REX model offers a generalized platform to explore sufficient statistics underlying regularity tracking in the auditory system, as well as contrast different interpretations of behavioral and neurophysiological results for parsing complex sound sequences.</p></sec></body><back><fn-group><fn id="FN1"><label>1</label><p id="P23">code available at <ext-link ext-link-type="uri" xlink:href="https://engineering.jhu.edu/lcap/software">https://engineering.jhu.edu/lcap/software</ext-link></p></fn></fn-group><ref-list><title>References</title><ref id="R1"><label>[1]</label><mixed-citation publication-type="journal"><name><surname>Winkler</surname><given-names>I</given-names></name>, <name><surname>Denham</surname><given-names>S</given-names></name>, <name><surname>Nelken</surname><given-names>I</given-names></name>: <article-title>Modeling the auditory scene: predictive regularity representations and perceptual objects</article-title>. <source>Trends in Cognitive Sciences</source>
<volume>13</volume> (<year>2009</year>) <fpage>532</fpage>&#x02013;<lpage>540</lpage>.<pub-id pub-id-type="pmid">19828357</pub-id></mixed-citation></ref><ref id="R2"><label>[2]</label><mixed-citation publication-type="journal"><name><surname>Bendixen</surname><given-names>A</given-names></name>, <name><surname>San Miguel</surname><given-names>I</given-names></name>, <name><surname>Schroger</surname><given-names>E</given-names></name>: <article-title>Early electro-physiological indicators for predictive processing in audi-tion: A review</article-title>. <source>Psychophysiology</source>
<volume>83</volume> (<year>2012</year>) <fpage>120</fpage>&#x02013;<lpage>131</lpage>.</mixed-citation></ref><ref id="R3"><label>[3]</label><mixed-citation publication-type="journal"><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name>, <name><surname>Paavilainen</surname><given-names>P</given-names></name>, <name><surname>Rinne</surname><given-names>T</given-names></name>, <name><surname>Alho</surname><given-names>K</given-names></name>: <article-title>The mismatch negativity (MMN) in basic research of central auditory processing: A review</article-title>. <source>Clinical Neurophysiology</source>
<volume>118</volume> (<year>2007</year>) <fpage>2544</fpage>&#x02013;<lpage>2590</lpage>.<pub-id pub-id-type="pmid">17931964</pub-id></mixed-citation></ref><ref id="R4"><label>[4]</label><mixed-citation publication-type="journal"><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name>, <name><surname>Gaillard</surname><given-names>A</given-names></name>, <name><surname>M&#x000e4;ntysalo</surname><given-names>S</given-names></name>: <article-title>Early selective-attention effect on evoked potential reinterpreted</article-title>. <source>Acta Psy- chologica</source>
<volume>42</volume> (<year>1978</year>) <fpage>313</fpage>&#x02013;<lpage>329</lpage>.</mixed-citation></ref><ref id="R5"><label>[5]</label><mixed-citation publication-type="journal"><name><surname>Mill</surname><given-names>R</given-names></name>, <name><surname>Bohm</surname><given-names>T</given-names></name>, <name><surname>Bendixen</surname><given-names>A</given-names></name>, <name><surname>Winkler</surname><given-names>I</given-names></name>, <name><surname>Denham</surname><given-names>S</given-names></name>: <article-title>Modelling the Emergence and Dynamics of Perceptual Organisation in Auditory Streaming</article-title>. <source>PLoS Computational Biology</source>
<volume>9</volume>(<year>2013</year>)<fpage>e1002925</fpage>.<pub-id pub-id-type="pmid">23516340</pub-id></mixed-citation></ref><ref id="R6"><label>[6]</label><mixed-citation publication-type="journal"><name><surname>Pearce</surname><given-names>M</given-names></name>: <source>The Construction and Evaluation of Statistical Models of Melodic Structure in Music Perception and Composition</source>. <year>2005</year>, p. <fpage>267</fpage>.</mixed-citation></ref><ref id="R7"><label>[7]</label><mixed-citation publication-type="journal"><name><surname>Friston</surname><given-names>K</given-names></name>, <name><surname>Kilner</surname><given-names>J</given-names></name>, <name><surname>Harrison</surname><given-names>L</given-names></name>: <article-title>A free energy principle for the brain</article-title>. <source>Journal of Physiology Paris</source>
<volume>100</volume> (<year>2006</year>) <fpage>70</fpage>&#x02013;<lpage>87</lpage>.</mixed-citation></ref><ref id="R8"><label>[8]</label><mixed-citation publication-type="journal"><name><surname>Knill</surname><given-names>D</given-names></name>, <name><surname>Pouget</surname><given-names>A</given-names></name>: <article-title>The Bayesian brain: The role of un-certainty in neural coding and computation</article-title>. <source>Trends in Neurosciences</source>
<volume>27</volume> (<year>2004</year>) <fpage>712</fpage>&#x02013;<lpage>719</lpage>.<pub-id pub-id-type="pmid">15541511</pub-id></mixed-citation></ref><ref id="R9"><label>[9]</label><mixed-citation publication-type="journal"><name><surname>Skerritt-Davis</surname><given-names>B</given-names></name>, <name><surname>Elhilali</surname><given-names>M</given-names></name>: <article-title>Detecting change in stochastic sound sequences</article-title>. <source>PloS Computational Biology</source>
<volume>14</volume> (<year>2018</year>)<fpage>e1006162</fpage>.<pub-id pub-id-type="pmid">29813049</pub-id></mixed-citation></ref><ref id="R10"><label>[10]</label><mixed-citation publication-type="book"><name><surname>Adams</surname><given-names>R</given-names></name>, <name><surname>MacKay</surname><given-names>D</given-names></name>: <source>Bayesian Online Changepoint Detection. Technical report</source>, <publisher-name>University of Cambridge</publisher-name>, <publisher-loc>Cambridge, UK</publisher-loc>, <year>2007</year>.</mixed-citation></ref><ref id="R11"><label>[11]</label><mixed-citation publication-type="journal"><name><surname>Nassar</surname><given-names>M</given-names></name>, <name><surname>Wilson</surname><given-names>R</given-names></name>, <name><surname>Heasly</surname><given-names>B</given-names></name>, <name><surname>Gold</surname><given-names>J</given-names></name>: <article-title>An Approximately Bayesian Delta-Rule Model Explains the Dynamics of Belief Updating in a Changing Environment</article-title>. <source>Journal of Neuroscience</source>
<volume>30</volume> (<year>2010</year>) <fpage>12366</fpage>&#x02013;<lpage>12378</lpage>.<pub-id pub-id-type="pmid">20844132</pub-id></mixed-citation></ref><ref id="R12"><label>[12]</label><mixed-citation publication-type="journal"><name><surname>Sams</surname><given-names>M</given-names></name>, <name><surname>Paavilainen</surname><given-names>P</given-names></name>, <name><surname>Alho</surname><given-names>K</given-names></name>, <name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name>: <article-title>Auditory frequency discrimination and event-related potentials</article-title>. <source>Electroencephalography and Clinical Neurophysiology/Evoked Potentials</source>
<volume>62</volume> (<year>1985</year>) <fpage>437</fpage>&#x02013;<lpage>448</lpage>.<pub-id pub-id-type="pmid">2415340</pub-id></mixed-citation></ref><ref id="R13"><label>[13]</label><mixed-citation publication-type="journal"><name><surname>Haenschel</surname><given-names>C</given-names></name>: <article-title>Event-Related Brain Potential Correlates of Human Auditory Sensory Memory-Trace Formation</article-title>. <source>Journal of Neuroscience</source>
<volume>25</volume> (<year>2005</year>) <fpage>10494</fpage>&#x02013;<lpage>10501</lpage>.<pub-id pub-id-type="pmid">16280587</pub-id></mixed-citation></ref><ref id="R14"><label>[14]</label><mixed-citation publication-type="journal"><name><surname>Miller</surname><given-names>T</given-names></name>, <name><surname>Chen</surname><given-names>S</given-names></name>, <name><surname>Lee</surname><given-names>W</given-names></name>, <name><surname>Sussman</surname><given-names>E</given-names></name>: <article-title>Multitasking: Effects of processing multiple auditory feature patterns</article-title>. <source>Psychophysiology</source>
<volume>52</volume> (<year>2015</year>) <fpage>1140</fpage>&#x02013;<lpage>1148</lpage>.<pub-id pub-id-type="pmid">25939456</pub-id></mixed-citation></ref><ref id="R15"><label>[15]</label><mixed-citation publication-type="journal"><name><surname>Ruhnau</surname><given-names>P</given-names></name>, <name><surname>Schr&#x000f6;ger</surname><given-names>E</given-names></name>, <name><surname>Sussman</surname><given-names>E</given-names></name>: <article-title>Implicit expectations influence target detection in children and adults</article-title>. <source>Developmental Science</source>
<volume>20</volume> (<year>2017</year>).</mixed-citation></ref><ref id="R16"><label>[16]</label><mixed-citation publication-type="journal"><name><surname>Herrmann</surname><given-names>B</given-names></name>, <name><surname>Henry</surname><given-names>M</given-names></name>, <name><surname>Fromboluti</surname><given-names>E</given-names></name>, <name><surname>McAuley</surname><given-names>J</given-names></name>, <name><surname>Obleser</surname><given-names>J</given-names></name>: <article-title>Statistical context shapes stimulus-specific adaptation in human auditory cortex</article-title>. <source>Journal of Neurophysiology</source>
<volume>113</volume> (<year>2015</year>) <fpage>2582</fpage>&#x02013;<lpage>2591</lpage>.<pub-id pub-id-type="pmid">25652920</pub-id></mixed-citation></ref><ref id="R17"><label>[17]</label><mixed-citation publication-type="journal"><name><surname>Garrido</surname><given-names>M</given-names></name>, <name><surname>Sahani</surname><given-names>M</given-names></name>, <name><surname>Dolan</surname><given-names>R</given-names></name>: <article-title>Outlier Responses Reflect Sensitivity to Statistical Structure in the Human Brain</article-title>. <source>PLoS Computational Biology</source>
<volume>9</volume> (<year>2013</year>) <fpage>e1002999</fpage>&#x02013;<lpage>10</lpage>.<pub-id pub-id-type="pmid">23555230</pub-id></mixed-citation></ref><ref id="R18"><label>[18]</label><mixed-citation publication-type="journal"><name><surname>Barascud</surname><given-names>N</given-names></name>, <name><surname>Pearce</surname><given-names>M</given-names></name>, <name><surname>Griffiths</surname><given-names>T</given-names></name>, <name><surname>Friston</surname><given-names>K</given-names></name>, <name><surname>Chait</surname><given-names>M</given-names></name>: <article-title>Brain responses in humans reveal ideal observer-like sensitivity to complex acoustic patterns</article-title>. <source>Proceedings of the National Academy of Sciences</source>
<volume>113</volume> (<year>2016</year>) <fpage>E616</fpage>&#x02013;<lpage>E625</lpage>.</mixed-citation></ref><ref id="R19"><label>[19]</label><mixed-citation publication-type="journal"><name><surname>Sussman</surname><given-names>E</given-names></name>, <name><surname>Winkler</surname><given-names>I</given-names></name>, <name><surname>Huotilainen</surname><given-names>M</given-names></name>, <name><surname>Ritter</surname><given-names>W</given-names></name>, <name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name>: <article-title>Top-down effects can modify the initially stimulus-driven auditory organization</article-title>. <source>Cognitive Brain Research</source>
<volume>13</volume> (<year>2002</year>) <fpage>393</fpage>&#x02013;<lpage>405</lpage>.<pub-id pub-id-type="pmid">11919003</pub-id></mixed-citation></ref></ref-list></back><floats-group><fig id="F1" orientation="portrait" position="float"><label>Figure 1.</label><caption><p id="P24">(Colour online) Neural results from the literature (left) are compared to surprisal responses from the D-REX model (right) to the same stimuli (above): a) [<xref rid="R12" ref-type="bibr">12</xref>], b) [<xref rid="R13" ref-type="bibr">13</xref>], c) [<xref rid="R14" ref-type="bibr">14</xref>], d)[<xref rid="R15" ref-type="bibr">15</xref>]. Arrows indicate replicated trends. Surprisal axis is occasionally inverted to facilitate visual comparison. Experimental figures reproduced with permission from the publishers. In b), experimental figure generated from Table 1 in [<xref rid="R13" ref-type="bibr">13</xref>].</p></caption><graphic xlink:href="nihms-1015866-f0001"/></fig><fig id="F2" orientation="portrait" position="float"><label>Figure 2.</label><caption><p id="P25">(Colour online) Comparison of neural and model results, continued. a) [<xref rid="R16" ref-type="bibr">16</xref>], b) [<xref rid="R17" ref-type="bibr">17</xref>], c) and d) [<xref rid="R18" ref-type="bibr">18</xref>]. Arrows indicate replicated effects. Surprisal axis is occasionally inverted to facilitate visual comparison. Experimental figures reproduced with permission from the publishers.</p></caption><graphic xlink:href="nihms-1015866-f0002"/></fig></floats-group></article>